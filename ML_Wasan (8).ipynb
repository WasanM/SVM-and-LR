{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viDuQA-anfNa"
      },
      "source": [
        "Problem 1 [50%]: Software defects datasets contain information about bugs in software modules (functions). Each dataset represents one software project with multiple modules. There are some datasets that are different releases for the same project. The features in the datasets describe the static code metrics in software modules where the output will be binary variable called defect (1= defected, 0=none-defected)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynh15kyvHNNk"
      },
      "outputs": [],
      "source": [
        "!pip install collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9HVZiwys2nxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.svm import SVC # search library of svm time smaal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection  import SelectKBest \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter\n",
        "from imblearn import over_sampling ,under_sampling\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "99MlDpWW2kUY"
      },
      "outputs": [],
      "source": [
        "Data_1= pd.read_csv('ar1.csv')\n",
        "Data_2= pd.read_csv('ar3.csv')\n",
        "Data_3= pd.read_csv('ar4.csv')\n",
        "Data_4= pd.read_csv('ar5.csv')\n",
        "Data_5= pd.read_csv('ar6.csv')\n",
        "Data_6= pd.read_csv('cm1.csv')\n",
        "Data_7= pd.read_csv('pc1.csv')\n",
        "Data_8= pd.read_csv('pc2.csv')\n",
        "Data_9= pd.read_csv('pc3.csv')\n",
        "Data_10= pd.read_csv('pc4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bGMZCDyQpvR"
      },
      "source": [
        "### QUE 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fisNTK3Qzeg1"
      },
      "outputs": [],
      "source": [
        "def SVM(Data):\n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "\n",
        "    #KFold k=10\n",
        "    folds=KFold(n_splits=10, shuffle=False) #10 Folds CV\n",
        "\n",
        "    for train_index, test_index in folds.split(x):\n",
        "      X_train=x.iloc[train_index]\n",
        "      X_test=x.iloc[test_index]\n",
        "      y_train=y.iloc[train_index]\n",
        "      y_test=y.iloc[test_index]\n",
        "      sc=StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train_std=sc.transform(X_train)\n",
        "      X_test_std=sc.transform(X_test)\n",
        "      svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "      # Instantiate the GridSearchCV object and run the search\n",
        "      parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "      searcher = GridSearchCV(svm, parameters)\n",
        "      s = searcher.fit(X_train_std, y_train)\n",
        "      \n",
        "      # Report the best parameters and the corresponding score\n",
        "      # print(\"Best CV params\", searcher.best_params_)\n",
        "      # print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "      # # Report the test accuracy using these best parameters\n",
        "    y_hat =s.predict(X_test_std) \n",
        "    print(y_hat.shape) \n",
        "    #print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "    #print(\"Test accuracy of best grid search hypers:\", searcher.score(y_testy_hat, ))\n",
        "\n",
        "    # summarize results\n",
        "    print(\"\\n**** Best: %f using %s ****\\n\" % (s.best_score_, searcher.best_params_))\n",
        "    # Evaluating the accuracy of the model using the sklearn functions\n",
        "    accuracy = accuracy_score(y_test,y_hat )*100\n",
        "    confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "\n",
        "    # Printing the results\n",
        "    print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "    print( \"Classification report for %s\" % s)\n",
        "\n",
        "    print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "    print( metrics.confusion_matrix(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsI2Z-P8vR7"
      },
      "outputs": [],
      "source": [
        "def LogReg(Data): \n",
        "    col = list(Data.columns)[-1]\n",
        "    # x= Data.loc[:, Data.columns != col]\n",
        "    # y= Data.iloc[:,-1]\n",
        "    # x=Data.drop([col], axis=1)\n",
        "    # y=Data_1[col]\n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "    #KFold k=10\n",
        "    folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "    for train_index, test_index in folds.split(x):\n",
        "      X_train=x.iloc[train_index]\n",
        "      X_test=x.iloc[test_index]\n",
        "      #X_test=x.loc[test_index]\n",
        "      y_train=y.iloc[train_index]\n",
        "      y_test=y.iloc[test_index]\n",
        "      logreg = LogisticRegression()\n",
        "      # Create the hyperparameter grid\n",
        "      \n",
        "      c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "      param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "      logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "      # Fit it to the training data\n",
        "      l=logreg_cv.fit(X_train,y_train)\n",
        " \n",
        "      # # Report the test accuracy using these best parameters\n",
        "    y_hat =l.predict(X_test) \n",
        "    print(y_hat.shape) \n",
        "\n",
        "\n",
        "    # summarize results\n",
        "    print(\"\\n**** Best: %f using %s ****\\n\" % (l.best_score_, l.best_params_))\n",
        "    # Evaluating the accuracy of the model using the sklearn functions\n",
        "    accuracy = accuracy_score(y_test,y_hat )*100\n",
        "    confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "\n",
        "    # Printing the results\n",
        "    print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print( \"Classification report for %s\" % l)\n",
        "\n",
        "    print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "    print( metrics.confusion_matrix(y_test,y_hat ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7vXK6pMC1dG",
        "outputId": "4b961359-82e0-49e4-ce8b-551cb636e7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Data 2\n",
            "Support Vector Classifier \n",
            "(6,)\n",
            "\n",
            "**** Best: 0.930303 using {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'} ****\n",
            "\n",
            "Accuracy for SVM is: 66.66666666666666\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.60      1.00      0.75         3\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.80      0.67      0.62         6\n",
            "weighted avg       0.80      0.67      0.62         6\n",
            "\n",
            "[[3 0]\n",
            " [2 1]]\n",
            "Logistic Regression\n",
            "(6,)\n",
            "\n",
            "**** Best: 0.898485 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00         5\n",
            "        True       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "[[5 0]\n",
            " [0 1]]\n",
            "\n",
            " Data 3\n",
            "Support Vector Classifier \n",
            "(10,)\n",
            "\n",
            "**** Best: 0.876842 using {'C': 1, 'gamma': 0.1, 'kernel': 'poly'} ****\n",
            "\n",
            "Accuracy for SVM is: 90.0\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95         9\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.45      0.50      0.47        10\n",
            "weighted avg       0.81      0.90      0.85        10\n",
            "\n",
            "[[9 0]\n",
            " [1 0]]\n",
            "Logistic Regression\n",
            "(10,)\n",
            "\n",
            "**** Best: 0.866316 using {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "[[10]]\n",
            "\n",
            " Data 4\n",
            "Support Vector Classifier \n",
            "(3,)\n",
            "\n",
            "**** Best: 0.938095 using {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'} ****\n",
            "\n",
            "Accuracy for SVM is: 33.33333333333333\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.33      1.00      0.50         1\n",
            "        True       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "[[1 0]\n",
            " [2 0]]\n",
            "Logistic Regression\n",
            "(3,)\n",
            "\n",
            "**** Best: 0.900000 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "[[3]]\n",
            "\n",
            " Data 5\n",
            "Support Vector Classifier \n",
            "(10,)\n",
            "\n",
            "**** Best: 0.901754 using {'C': 1, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 100.0\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "[[10]]\n",
            "Logistic Regression\n",
            "(10,)\n",
            "\n",
            "**** Best: 0.890643 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} ****\n",
            "\n",
            "Accuracy for Logistic is: 80.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.88      0.88         8\n",
            "        True       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.80        10\n",
            "   macro avg       0.69      0.69      0.69        10\n",
            "weighted avg       0.80      0.80      0.80        10\n",
            "\n",
            "[[7 1]\n",
            " [1 1]]\n",
            "\n",
            " Data 6\n",
            "Support Vector Classifier \n",
            "(49,)\n",
            "\n",
            "**** Best: nan using {'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 2.0408163265306123\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.02      1.00      0.04         1\n",
            "        True       0.00      0.00      0.00        48\n",
            "\n",
            "    accuracy                           0.02        49\n",
            "   macro avg       0.01      0.50      0.02        49\n",
            "weighted avg       0.00      0.02      0.00        49\n",
            "\n",
            "[[ 1  0]\n",
            " [48  0]]\n",
            "Logistic Regression\n",
            "(49,)\n",
            "\n",
            "**** Best: 0.899775 using {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 91.83673469387756\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      1.00      0.96        45\n",
            "        True       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.92        49\n",
            "   macro avg       0.46      0.50      0.48        49\n",
            "weighted avg       0.84      0.92      0.88        49\n",
            "\n",
            "[[45  0]\n",
            " [ 4  0]]\n",
            "\n",
            " Data 7\n",
            "Support Vector Classifier \n",
            "(92,)\n",
            "\n",
            "**** Best: 0.996386 using {'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 98.91304347826086\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      0.99        91\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        92\n",
            "   macro avg       0.49      0.50      0.50        92\n",
            "weighted avg       0.98      0.99      0.98        92\n",
            "\n",
            "[[91  0]\n",
            " [ 1  0]]\n",
            "Logistic Regression\n",
            "(92,)\n",
            "\n",
            "**** Best: 0.996378 using {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 98.91304347826086\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      0.99        91\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        92\n",
            "   macro avg       0.49      0.50      0.50        92\n",
            "weighted avg       0.98      0.99      0.98        92\n",
            "\n",
            "[[91  0]\n",
            " [ 1  0]]\n",
            "\n",
            " Data 8\n",
            "Support Vector Classifier \n"
          ]
        }
      ],
      "source": [
        "Datasets=[Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]\n",
        "c = 2\n",
        "for i in Datastes:\n",
        " \n",
        "  print(f\"\\n Data {c}\")\n",
        "  print(\"Support Vector Classifier \")\n",
        "  SVM(i)\n",
        "  print(\"Logistic Regression\")\n",
        "  LogReg(i)\n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIsC6yHaoPfE"
      },
      "outputs": [],
      "source": [
        "SVM(Data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uasTD_Rq9ISP",
        "outputId": "d15b6004-eb75-4553-d23c-668d8c690856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12,)\n",
            "\n",
            "**** Best: 0.945022 using {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'} ****\n",
            "\n",
            "Accuracy for SVM is: 75.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'sag', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.75      1.00      0.86         9\n",
            "        True       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.75        12\n",
            "   macro avg       0.38      0.50      0.43        12\n",
            "weighted avg       0.56      0.75      0.64        12\n",
            "\n",
            "[[9 0]\n",
            " [3 0]]\n"
          ]
        }
      ],
      "source": [
        "LogReg(Data_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9wZkMplOeYn"
      },
      "source": [
        "# *Problem 1*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9r-rzEeIqD9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.svm import SVC # search library of svm time smaal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection  import SelectKBest \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfjGU1yKIbNR"
      },
      "outputs": [],
      "source": [
        "# Problem 1 [50%]: Software defects datasets contain information about bugs in software\n",
        "# modules (functions). Each dataset represents one software project with multiple modules.\n",
        "# There are some datasets that are different releases for the same project. The features in\n",
        "# the datasets describe the static code metrics in software modules where the output will\n",
        "# be binary variable called defect (1= defected, 0=none-defected)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oePvsbEzKYgt"
      },
      "source": [
        "# Que 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8RZ6YzpndUN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjR_Cb-SItbl"
      },
      "outputs": [],
      "source": [
        "Data_1= pd.read_csv('ar1.csv')\n",
        "Data_2= pd.read_csv('ar3.csv')\n",
        "Data_3= pd.read_csv('ar4.csv')\n",
        "Data_4= pd.read_csv('ar5.csv')\n",
        "Data_5= pd.read_csv('ar6.csv')\n",
        "Data_6= pd.read_csv('cm1.csv')\n",
        "Data_7= pd.read_csv('pc1.csv')\n",
        "Data_8= pd.read_csv('pc2.csv')\n",
        "Data_9= pd.read_csv('pc3.csv')\n",
        "Data_10= pd.read_csv('pc4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXdWKjj8EcoU"
      },
      "outputs": [],
      "source": [
        "col = list(Data_1.columns)[-1]\n",
        "x= Data_1.loc[:, Data_1.columns != col]\n",
        "y= Data_1.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60NBuOUYFNy5",
        "outputId": "8524c0cb-e22b-48a6-cb00-f87a64cab5b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 29)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G9a4Ce6FPOb",
        "outputId": "9287e987-5231-4118-d4d2-5585f50d85e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121,)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tadXCcoMJrTn",
        "outputId": "7f0089ce-5831-4771-d03f-f188360378d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      True\n",
              "1     False\n",
              "2     False\n",
              "3     False\n",
              "4     False\n",
              "      ...  \n",
              "58     True\n",
              "59    False\n",
              "60    False\n",
              "61    False\n",
              "62     True\n",
              "Name: defects, Length: 63, dtype: bool"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3G5XnOc32bFN",
        "outputId": "a86ab9b5-8ddf-4d15-b9fb-89be56caea39"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.47</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>33</td>\n",
              "      <td>56</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>44</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>58</td>\n",
              "      <td>91</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0            7          0            4                     0               3   \n",
              "1            9          0            1                     0               8   \n",
              "2           21          0           14                     1               7   \n",
              "3           30          0           11                     0              19   \n",
              "4            8          0            2                     0               6   \n",
              "..         ...        ...          ...                   ...             ...   \n",
              "116         32          0            5                     0              27   \n",
              "117          6          0            0                     0               6   \n",
              "118          6          0            0                     0               6   \n",
              "119         27          0            3                     0              24   \n",
              "120         51          2           12                     0              37   \n",
              "\n",
              "     unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0                  8                 6              10               12   \n",
              "1                  7                 8              15               20   \n",
              "2                 15                12              21               36   \n",
              "3                 16                18              50               70   \n",
              "4                  4                 5               5               10   \n",
              "..               ...               ...             ...              ...   \n",
              "116               16                11              33               56   \n",
              "117                3                 5               5               11   \n",
              "118                6                 6               6               11   \n",
              "119               16                 9              26               44   \n",
              "120               29                17              58               91   \n",
              "\n",
              "     halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "0                     14  ...           0                0   \n",
              "1                     15  ...           0                0   \n",
              "2                     27  ...           1                4   \n",
              "3                     34  ...           1                9   \n",
              "4                      9  ...           1                1   \n",
              "..                   ...  ...         ...              ...   \n",
              "116                   27  ...           0                9   \n",
              "117                    8  ...           0                2   \n",
              "118                   12  ...           1                2   \n",
              "119                   25  ...           1                8   \n",
              "120                   46  ...           4               17   \n",
              "\n",
              "     multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "0                           0                      1                0.33   \n",
              "1                           0                      2                0.25   \n",
              "2                           1                      4                0.57   \n",
              "3                           2                      9                0.47   \n",
              "4                           0                      2                0.33   \n",
              "..                        ...                    ...                 ...   \n",
              "116                         1                      8                0.30   \n",
              "117                         0                      3                0.50   \n",
              "118                         1                      2                0.33   \n",
              "119                         3                      6                0.25   \n",
              "120                         3                     14                0.38   \n",
              "\n",
              "     decision_density  design_complexity  design_density  \\\n",
              "0                0.00                  0            0.00   \n",
              "1                0.00                  0            0.00   \n",
              "2                1.00                  1            0.25   \n",
              "3                1.11                  1            0.11   \n",
              "4                1.00                  1            0.50   \n",
              "..                ...                ...             ...   \n",
              "116              1.00                  0            0.00   \n",
              "117              1.00                  0            0.00   \n",
              "118              1.00                  1            0.50   \n",
              "119              1.00                  1            0.17   \n",
              "120              1.00                  4            0.29   \n",
              "\n",
              "     normalized_cyclomatic_complexity  formal_parameters  \n",
              "0                                0.14                  0  \n",
              "1                                0.22                  0  \n",
              "2                                0.19                  0  \n",
              "3                                0.30                  0  \n",
              "4                                0.25                  0  \n",
              "..                                ...                ...  \n",
              "116                              0.25                  0  \n",
              "117                              0.50                  0  \n",
              "118                              0.33                  0  \n",
              "119                              0.22                  0  \n",
              "120                              0.27                  1  \n",
              "\n",
              "[121 rows x 29 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col = list(Data_1.columns)[-1]\n",
        "x= Data_1.loc[:, Data_1.columns != col]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c40cTu7zJpNB"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance of Support Vector Classifier and Logistic Regression, using\n",
        "# 10-Folds cross validation on each single dataset? Describe the best parameters for both\n",
        "# algorithms and what is the impact of other parameters? Do all datasets share the same\n",
        "# configuration settings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwyvvZL21-9z"
      },
      "outputs": [],
      "source": [
        "# Paramerter C:\n",
        "\n",
        "# Large Value of parameter C => small margin\n",
        "\n",
        "# Small Value of paramerter C => Large margin\n",
        "\n",
        "# Gamma:\n",
        "\n",
        "# Gamma high means more curvature.\n",
        "\n",
        "# Gamma low means less curvature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I-sWWCOmIpy"
      },
      "source": [
        "## Data 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzwMWM9xqUvb"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCpl7ZmfmM_c",
        "outputId": "d6c22453-ce0f-4ddd-f4fc-0bebad2db576"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPh33dBTmTNo",
        "outputId": "29ac04b5-82a8-48e5-e248-847fa99789c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           0\n",
              "blank_loc                           0\n",
              "comment_loc                         0\n",
              "code_and_comment_loc                0\n",
              "executable_loc                      0\n",
              "unique_operands                     0\n",
              "unique_operators                    0\n",
              "total_operands                      0\n",
              "total_operators                     0\n",
              "halstead_vocabulary                 0\n",
              "halstead_length                     0\n",
              "halstead_volume                     0\n",
              "halstead_level                      0\n",
              "halstead_difficulty                 0\n",
              "halstead_effort                     0\n",
              "halstead_error                      0\n",
              "halstead_time                       0\n",
              "branch_count                        0\n",
              "decision_count                      0\n",
              "call_pairs                          0\n",
              "condition_count                     0\n",
              "multiple_condition_count            0\n",
              "cyclomatic_complexity               0\n",
              "cyclomatic_density                  0\n",
              "decision_density                    0\n",
              "design_complexity                   0\n",
              "design_density                      0\n",
              "normalized_cyclomatic_complexity    0\n",
              "formal_parameters                   0\n",
              "defects                             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4ATBk2lm9UX",
        "outputId": "adf83b33-2f5c-4a5a-9e68-b3171910a886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           False\n",
              "blank_loc                           False\n",
              "comment_loc                         False\n",
              "code_and_comment_loc                False\n",
              "executable_loc                      False\n",
              "unique_operands                     False\n",
              "unique_operators                    False\n",
              "total_operands                      False\n",
              "total_operators                     False\n",
              "halstead_vocabulary                 False\n",
              "halstead_length                     False\n",
              "halstead_volume                     False\n",
              "halstead_level                      False\n",
              "halstead_difficulty                 False\n",
              "halstead_effort                     False\n",
              "halstead_error                      False\n",
              "halstead_time                       False\n",
              "branch_count                        False\n",
              "decision_count                      False\n",
              "call_pairs                          False\n",
              "condition_count                     False\n",
              "multiple_condition_count            False\n",
              "cyclomatic_complexity               False\n",
              "cyclomatic_density                  False\n",
              "decision_density                    False\n",
              "design_complexity                   False\n",
              "design_density                      False\n",
              "normalized_cyclomatic_complexity    False\n",
              "formal_parameters                   False\n",
              "defects                             False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_1.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB6faFtjnexW",
        "outputId": "73b56483-2c80-45e6-ecde-38ccaa30cea4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d959190b-ae8f-47fa-b307-1d78d2b65ff3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>121.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.388430</td>\n",
              "      <td>0.206612</td>\n",
              "      <td>4.760331</td>\n",
              "      <td>0.074380</td>\n",
              "      <td>15.421488</td>\n",
              "      <td>12.454545</td>\n",
              "      <td>8.330579</td>\n",
              "      <td>23.743802</td>\n",
              "      <td>36.876033</td>\n",
              "      <td>20.785124</td>\n",
              "      <td>...</td>\n",
              "      <td>2.239669</td>\n",
              "      <td>4.396694</td>\n",
              "      <td>0.991736</td>\n",
              "      <td>4.570248</td>\n",
              "      <td>0.312479</td>\n",
              "      <td>0.683140</td>\n",
              "      <td>2.239669</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.253554</td>\n",
              "      <td>0.330579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>19.601178</td>\n",
              "      <td>1.040171</td>\n",
              "      <td>6.114225</td>\n",
              "      <td>0.293408</td>\n",
              "      <td>15.262018</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.156097</td>\n",
              "      <td>24.096863</td>\n",
              "      <td>36.343631</td>\n",
              "      <td>13.453133</td>\n",
              "      <td>...</td>\n",
              "      <td>3.413270</td>\n",
              "      <td>6.527480</td>\n",
              "      <td>1.604659</td>\n",
              "      <td>4.857685</td>\n",
              "      <td>0.103773</td>\n",
              "      <td>0.581892</td>\n",
              "      <td>3.413270</td>\n",
              "      <td>1.205867</td>\n",
              "      <td>0.104018</td>\n",
              "      <td>0.568454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>95.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d959190b-ae8f-47fa-b307-1d78d2b65ff3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d959190b-ae8f-47fa-b307-1d78d2b65ff3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d959190b-ae8f-47fa-b307-1d78d2b65ff3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        total_loc   blank_loc  comment_loc  code_and_comment_loc  \\\n",
              "count  121.000000  121.000000   121.000000            121.000000   \n",
              "mean    20.388430    0.206612     4.760331              0.074380   \n",
              "std     19.601178    1.040171     6.114225              0.293408   \n",
              "min      2.000000    0.000000     0.000000              0.000000   \n",
              "25%      6.000000    0.000000     0.000000              0.000000   \n",
              "50%     12.000000    0.000000     3.000000              0.000000   \n",
              "75%     32.000000    0.000000     7.000000              0.000000   \n",
              "max     95.000000    9.000000    30.000000              2.000000   \n",
              "\n",
              "       executable_loc  unique_operands  unique_operators  total_operands  \\\n",
              "count      121.000000       121.000000        121.000000      121.000000   \n",
              "mean        15.421488        12.454545          8.330579       23.743802   \n",
              "std         15.262018        10.000000          4.156097       24.096863   \n",
              "min          2.000000         1.000000          2.000000        1.000000   \n",
              "25%          5.000000         5.000000          5.000000        6.000000   \n",
              "50%          8.000000         9.000000          8.000000       16.000000   \n",
              "75%         23.000000        17.000000         11.000000       35.000000   \n",
              "max         82.000000        47.000000         19.000000      118.000000   \n",
              "\n",
              "       total_operators  halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "count       121.000000           121.000000  ...  121.000000       121.000000   \n",
              "mean         36.876033            20.785124  ...    2.239669         4.396694   \n",
              "std          36.343631            13.453133  ...    3.413270         6.527480   \n",
              "min           3.000000             3.000000  ...    0.000000         0.000000   \n",
              "25%          11.000000            10.000000  ...    0.000000         0.000000   \n",
              "50%          25.000000            18.000000  ...    1.000000         2.000000   \n",
              "75%          56.000000            28.000000  ...    3.000000         8.000000   \n",
              "max         184.000000            62.000000  ...   19.000000        38.000000   \n",
              "\n",
              "       multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "count                121.000000             121.000000          121.000000   \n",
              "mean                   0.991736               4.570248            0.312479   \n",
              "std                    1.604659               4.857685            0.103773   \n",
              "min                    0.000000               1.000000            0.130000   \n",
              "25%                    0.000000               1.000000            0.250000   \n",
              "50%                    1.000000               3.000000            0.300000   \n",
              "75%                    1.000000               6.000000            0.330000   \n",
              "max                   10.000000              28.000000            0.600000   \n",
              "\n",
              "       decision_density  design_complexity  design_density  \\\n",
              "count        121.000000         121.000000      121.000000   \n",
              "mean           0.683140           2.239669        0.681818   \n",
              "std            0.581892           3.413270        1.205867   \n",
              "min            0.000000           0.000000        0.000000   \n",
              "25%            0.000000           0.000000        0.000000   \n",
              "50%            1.000000           1.000000        0.170000   \n",
              "75%            1.000000           3.000000        0.670000   \n",
              "max            2.000000          19.000000        6.000000   \n",
              "\n",
              "       normalized_cyclomatic_complexity  formal_parameters  \n",
              "count                        121.000000         121.000000  \n",
              "mean                           0.253554           0.330579  \n",
              "std                            0.104018           0.568454  \n",
              "min                            0.030000           0.000000  \n",
              "25%                            0.170000           0.000000  \n",
              "50%                            0.250000           0.000000  \n",
              "75%                            0.330000           1.000000  \n",
              "max                            0.500000           3.000000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4YhsvWYntEU",
        "outputId": "89ae26f8-a8b0-46fe-f34d-1d3c3a237d0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-19362203-fafe-4f8c-8ea0-39700638eb12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.47</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>33</td>\n",
              "      <td>56</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>44</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>58</td>\n",
              "      <td>91</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19362203-fafe-4f8c-8ea0-39700638eb12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19362203-fafe-4f8c-8ea0-39700638eb12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19362203-fafe-4f8c-8ea0-39700638eb12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0            7          0            4                     0               3   \n",
              "1            9          0            1                     0               8   \n",
              "2           21          0           14                     1               7   \n",
              "3           30          0           11                     0              19   \n",
              "4            8          0            2                     0               6   \n",
              "..         ...        ...          ...                   ...             ...   \n",
              "116         32          0            5                     0              27   \n",
              "117          6          0            0                     0               6   \n",
              "118          6          0            0                     0               6   \n",
              "119         27          0            3                     0              24   \n",
              "120         51          2           12                     0              37   \n",
              "\n",
              "     unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0                  8                 6              10               12   \n",
              "1                  7                 8              15               20   \n",
              "2                 15                12              21               36   \n",
              "3                 16                18              50               70   \n",
              "4                  4                 5               5               10   \n",
              "..               ...               ...             ...              ...   \n",
              "116               16                11              33               56   \n",
              "117                3                 5               5               11   \n",
              "118                6                 6               6               11   \n",
              "119               16                 9              26               44   \n",
              "120               29                17              58               91   \n",
              "\n",
              "     halstead_vocabulary  ...  condition_count  multiple_condition_count  \\\n",
              "0                     14  ...                0                         0   \n",
              "1                     15  ...                0                         0   \n",
              "2                     27  ...                4                         1   \n",
              "3                     34  ...                9                         2   \n",
              "4                      9  ...                1                         0   \n",
              "..                   ...  ...              ...                       ...   \n",
              "116                   27  ...                9                         1   \n",
              "117                    8  ...                2                         0   \n",
              "118                   12  ...                2                         1   \n",
              "119                   25  ...                8                         3   \n",
              "120                   46  ...               17                         3   \n",
              "\n",
              "     cyclomatic_complexity  cyclomatic_density  decision_density  \\\n",
              "0                        1                0.33              0.00   \n",
              "1                        2                0.25              0.00   \n",
              "2                        4                0.57              1.00   \n",
              "3                        9                0.47              1.11   \n",
              "4                        2                0.33              1.00   \n",
              "..                     ...                 ...               ...   \n",
              "116                      8                0.30              1.00   \n",
              "117                      3                0.50              1.00   \n",
              "118                      2                0.33              1.00   \n",
              "119                      6                0.25              1.00   \n",
              "120                     14                0.38              1.00   \n",
              "\n",
              "     design_complexity  design_density  normalized_cyclomatic_complexity  \\\n",
              "0                    0            0.00                              0.14   \n",
              "1                    0            0.00                              0.22   \n",
              "2                    1            0.25                              0.19   \n",
              "3                    1            0.11                              0.30   \n",
              "4                    1            0.50                              0.25   \n",
              "..                 ...             ...                               ...   \n",
              "116                  0            0.00                              0.25   \n",
              "117                  0            0.00                              0.50   \n",
              "118                  1            0.50                              0.33   \n",
              "119                  1            0.17                              0.22   \n",
              "120                  4            0.29                              0.27   \n",
              "\n",
              "     formal_parameters  defects  \n",
              "0                    0    False  \n",
              "1                    0    False  \n",
              "2                    0    False  \n",
              "3                    0     True  \n",
              "4                    0    False  \n",
              "..                 ...      ...  \n",
              "116                  0    False  \n",
              "117                  0    False  \n",
              "118                  0    False  \n",
              "119                  0    False  \n",
              "120                  1     True  \n",
              "\n",
              "[121 rows x 30 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aVpYCDMqeBi"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4IA-bpiedFV"
      },
      "source": [
        "#### test library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH1UFc0V7Onq"
      },
      "outputs": [],
      "source": [
        "!pip install -U libsvm-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USEpe_x757HH"
      },
      "outputs": [],
      "source": [
        "! pip3 install libsvm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCCvbFZ851xX"
      },
      "outputs": [],
      "source": [
        "from libsvm import svmutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gMLHIvFNZwL"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import NuSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zAEgOIKT17U"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import NuSVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhqMLTFXRAQc"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuF8l8dSZ37X"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDTnU96-ghKD",
        "outputId": "a06d3014-dba7-408e-befd-3d4971e2998a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlpack==3.4.2\n",
            "  Downloading mlpack-3.4.2-cp38-cp38-manylinux1_x86_64.whl (93.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mlpack==3.4.2) (1.3.5)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.8/dist-packages (from mlpack==3.4.2) (0.29.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mlpack==3.4.2) (1.24.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack==3.4.2) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack==3.4.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->mlpack==3.4.2) (1.15.0)\n",
            "Installing collected packages: mlpack\n",
            "  Attempting uninstall: mlpack\n",
            "    Found existing installation: mlpack 4.0.1\n",
            "    Uninstalling mlpack-4.0.1:\n",
            "      Successfully uninstalled mlpack-4.0.1\n",
            "Successfully installed mlpack-3.4.2\n"
          ]
        }
      ],
      "source": [
        "! pip install mlpack==3.4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "uFO_hy_xiEt7",
        "outputId": "099c220a-414b-4a2e-9f5e-3760f12a7c98"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6b8d05c34509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshogun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLibSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LibSVM' from 'shogun' (/usr/local/lib/python3.8/dist-packages/shogun/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from shogun import LibSVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeYyPCnfaqfT"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection as ms\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(Data_1)\n",
        "Data_1 = scaler.transform(Data_1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "yL10OlwfCRJv",
        "outputId": "3b6310e6-baca-4266-9fcb-a098b6577fae"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-4cb2c19db326>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    ernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma': [0.001, 0.0001] }# when choose kernal they need a lot of time\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "# Instantiate an RBF SVM\n",
        "svm = NuSVC()#SVC()\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "#param={'C':[1, 10, 100, 1000], 'k\n",
        "\n",
        "#kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma': [0.001, 0.0001] }# when choose kernal they need a lot of time\n",
        "parameters = {'C':[0.01 ,0.1,1, 10, 100],'kernel': ['rbf'],'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
        "searcher = GridSearchCV(svm, parameters)\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters and the corresponding score\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZtXgD69LRs2",
        "outputId": "f73fee85-8cbc-4a42-c24e-82c074a6354a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=inf, kernel='linear')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# #Hold Out Validation\n",
        "# x=Data_1.drop(['defects'], axis=1)\n",
        "# y=Data_1['defects']\n",
        "# X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "# # SVM Classifier model\n",
        "# svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
        "# svm_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJjk6ZUfZceU"
      },
      "outputs": [],
      "source": [
        "# There are several libraries that you can use to implement support vector machines (SVMs) with a kernel other than scikit-learn. Some examples include:\n",
        "\n",
        "# LIBSVM: A library for support vector machines that provides a C++ implementation of various SVM algorithms.\n",
        "# pySVM: A Python library for support vector machines that is built on top of LIBSVM.\n",
        "# Shogun: A machine learning toolbox that provides an efficient implementation of SVMs and other machine learning algorithms.\n",
        "# mlpack: A fast, flexible machine learning library that includes an implementation of SVMs.\n",
        "# Each of these libraries has its own strengths and weaknesses, and you should choose the one that best meets your needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLSCkQyQX8U8",
        "outputId": "a3ca92a3-0bd5-4309-957b-79b724ab0361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlpack\n",
            "  Downloading mlpack-4.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.21.6)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.8/dist-packages (from mlpack) (0.29.32)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->mlpack) (1.15.0)\n",
            "Installing collected packages: mlpack\n",
            "Successfully installed mlpack-4.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install mlpack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiJr-jQoaHk8",
        "outputId": "08c6f146-7284-49ca-8c11-a8cdc2a0978d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.24.1\n",
            "Uninstalling numpy-1.24.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.8\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy-1.24.1.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.24.1\n"
          ]
        }
      ],
      "source": [
        "! pip uninstall numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9solhfpaLia",
        "outputId": "7562f827-7956-4a12-c88c-d9e13660b7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.16.5\n",
            "  Downloading numpy-1.16.5.zip (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpy: filename=numpy-1.16.5-cp38-cp38-linux_x86_64.whl size=8261397 sha256=3d700a1a1c3e16fe5ca87cc953e9d1266cf000e19edddfd20eaa25b6886976a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/3f/d3/ac786baa3379136ed1069cf94478550de71616e0490b462e90\n",
            "Successfully built numpy\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.16.5 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.16.5 which is incompatible.\n",
            "tifffile 2022.10.10 requires numpy>=1.19.2, but you have numpy 1.16.5 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.16.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.5 which is incompatible.\n",
            "resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.16.5 which is incompatible.\n",
            "pywavelets 1.4.1 requires numpy>=1.17.3, but you have numpy 1.16.5 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.5 which is incompatible.\n",
            "pyarrow 9.0.0 requires numpy>=1.16.6, but you have numpy 1.16.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.16.5 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.5 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires numpy>=1.16.6, but you have numpy 1.16.5 which is incompatible.\n",
            "opencv-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.5 which is incompatible.\n",
            "opencv-python-headless 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.5 which is incompatible.\n",
            "opencv-contrib-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.5 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.16.5 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.16.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.16.5 which is incompatible.\n",
            "h5py 3.1.0 requires numpy>=1.17.5; python_version == \"3.8\", but you have numpy 1.16.5 which is incompatible.\n",
            "gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.16.5 which is incompatible.\n",
            "db-dtypes 1.0.5 requires numpy<2.0dev,>=1.16.6, but you have numpy 1.16.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.16.5 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.5 which is incompatible.\n",
            "aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.16.5 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.16.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.16.5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! pip install numpy==1.16.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLT9ERr0c2Te",
        "outputId": "b2c9e627-dee9-4ff1-fbb3-9f442e187376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement mlpack==3.0.2 (from versions: 3.2.2, 3.3.0, 3.3.1, 3.3.2, 3.4.1, 3.4.2, 4.0.0, 4.0.0.post1, 4.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mlpack==3.0.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install mlpack==3.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyU8WhbOd-4t",
        "outputId": "db3c6b93-9721-49d2-84fb-cd3c34175a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlpack in /usr/local/lib/python3.8/dist-packages (4.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.3.5)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.8/dist-packages (from mlpack) (0.29.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.16.5)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->mlpack) (1.15.0)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.16.5\n",
            "    Uninstalling numpy-1.16.5:\n",
            "      Successfully uninstalled numpy-1.16.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.1\n"
          ]
        }
      ],
      "source": [
        "! pip install mlpack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP0HOqCTfr4_",
        "outputId": "7d4c32ff-6dfd-4280-a965-e6ba8892cc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.16.6\n",
            "  Downloading numpy-1.16.6.zip (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpy: filename=numpy-1.16.6-cp38-cp38-linux_x86_64.whl size=8269415 sha256=ce89c83ce954e035b8f4a6c1e7187746a688e819e9c5c4a06e807739d5004df5\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6f/a6/069db0c95f9bb6b73e07da014891c58460fef1eb84f49576f0\n",
            "Successfully built numpy\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.1\n",
            "    Uninstalling numpy-1.24.1:\n",
            "      Successfully uninstalled numpy-1.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
            "tifffile 2022.10.10 requires numpy>=1.19.2, but you have numpy 1.16.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.6 which is incompatible.\n",
            "resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "pywavelets 1.4.1 requires numpy>=1.17.3, but you have numpy 1.16.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.16.6 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.6 which is incompatible.\n",
            "opencv-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.6 which is incompatible.\n",
            "opencv-python-headless 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.6 which is incompatible.\n",
            "opencv-contrib-python 4.6.0.66 requires numpy>=1.17.3; python_version >= \"3.8\", but you have numpy 1.16.6 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.6 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.16.6 which is incompatible.\n",
            "h5py 3.1.0 requires numpy>=1.17.5; python_version == \"3.8\", but you have numpy 1.16.6 which is incompatible.\n",
            "gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.16.6 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.16.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.16.6 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.16.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.16.6\n"
          ]
        }
      ],
      "source": [
        "pip install numpy==1.16.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKK5IC3WfuQw",
        "outputId": "4bdaab99-3a11-4fcd-c19e-410d0432d2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.16.6 in /usr/local/lib/python3.8/dist-packages (1.16.6)\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy==1.16.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "mBk-67OWc7Ug",
        "outputId": "2215b1bc-9f24-4fc1-85f6-711c2f2ab7d5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-edcb40cca368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mlpack/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImportWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapprox_kfn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_kfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbayesian_linear_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbayesian_linear_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmlpack/approx_kfn.pyx\u001b[0m in \u001b[0;36minit mlpack.approx_kfn\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject"
          ]
        }
      ],
      "source": [
        "import mlpack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ5OxDpdhttf",
        "outputId": "42b10f6e-1c91-481b-a8c9-6b3cebf26cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.1\n",
            "    Uninstalling numpy-1.24.1:\n",
            "      Successfully uninstalled numpy-1.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.20.3\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy==1.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOv5ICdihBF9",
        "outputId": "353f90ed-2ee9-4595-d33b-207f5e47919d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlpack in /usr/local/lib/python3.8/dist-packages (4.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.20.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.3.5)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.8/dist-packages (from mlpack) (0.29.32)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->mlpack) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install mlpack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "kVJkoqqEX22Z",
        "outputId": "492bf07c-2812-4470-b468-5b72b9ecde9d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-5e0087dc494c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mlpack/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madaboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madaboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapprox_kfn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_kfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbayesian_linear_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbayesian_linear_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmlpack/approx_kfn.pyx\u001b[0m in \u001b[0;36minit mlpack.approx_kfn\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject"
          ]
        }
      ],
      "source": [
        "import mlpack "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn7lPOohi_7u",
        "outputId": "2e5c9ff8-b018-4904-d34a-5a19dca86a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.20.3\n",
            "Uninstalling numpy-1.20.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.8\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy-1.20.3.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libgfortran-2e0d59d6.so.5.0.0\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libopenblasp-r0-5bebc122.3.13.dev.so\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libquadmath-2d0c479f.so.0.0.0\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy.libs/libz-eb09ad1d.so.1.2.3\n",
            "    /usr/local/lib/python3.8/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.20.3\n",
            "Found existing installation: mlpack 3.2.2\n",
            "Uninstalling mlpack-3.2.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.8/dist-packages/mlpack-3.2.2.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/mlpack/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled mlpack-3.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting mlpack\n",
            "  Using cached mlpack-4.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.4 MB)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.8/dist-packages (from mlpack) (0.29.32)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mlpack) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mlpack) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->mlpack) (1.15.0)\n",
            "Installing collected packages: numpy, mlpack\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mlpack-4.0.1 numpy-1.24.1\n"
          ]
        }
      ],
      "source": [
        "! pip uninstall numpy mlpack\n",
        "! pip install numpy mlpack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dAP0vVGhOKO",
        "outputId": "879a1182-5d7c-49b8-9618-cab3b6cb0f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'mlpack=3.4.2'\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "\n",
        "! pip install mlpack=3.4.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d27eXyOqqft",
        "outputId": "62a01e93-c278-4148-a763-9f990f565fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pip 22.0.4 from /usr/local/lib/python3.8/dist-packages/pip (python 3.8)\n"
          ]
        }
      ],
      "source": [
        "! pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZuDuy7PqxG8",
        "outputId": "b196a95f-f86a-4e1e-a675-6779503f2613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python3: No module named ensurepip\n"
          ]
        }
      ],
      "source": [
        "! python -m ensurepip --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSZxO8D3qORD",
        "outputId": "6b099945-04c3-4f19-c47f-b0f78a64cee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install shogun == 6.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "18hYeqSBsWgx",
        "outputId": "8427e6b1-1f38-427b-cf4b-4a9b9e810d3f"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-95858a27515c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshogun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLibSVMFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseRealFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMulticlassLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMulticlassLibSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSerializableHdf5File\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMulticlassAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LibSVMFile' from 'shogun' (/usr/local/lib/python3.8/dist-packages/shogun/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from shogun import (LibSVMFile, SparseRealFeatures, MulticlassLabels,MulticlassLibSVM, SerializableHdf5File,MulticlassAccuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "5CdDcnYfsuQE",
        "outputId": "0625bf82-227f-4510-e685-b7292525c43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shogun==0.0.1\n",
            "  Downloading shogun-0.0.1.tar.gz (13 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: shogun\n",
            "  Building wheel for shogun (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shogun: filename=shogun-0.0.1-py3-none-any.whl size=20828 sha256=264dc63d559bd45e42091d9eb109046015b366551a204e2289ea26a354129614\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/fe/6d/b4313c29fdf10d28169934550ea7526dc39e256a0057024334\n",
            "Successfully built shogun\n",
            "Installing collected packages: shogun\n",
            "  Attempting uninstall: shogun\n",
            "    Found existing installation: shogun 0.0.2\n",
            "    Uninstalling shogun-0.0.2:\n",
            "      Successfully uninstalled shogun-0.0.2\n",
            "Successfully installed shogun-0.0.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "shogun"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install shogun==0.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wucFS0TxrG9-",
        "outputId": "f41e2596-cf15-46ca-f1e9-56043a2ca147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shogun==0.0.2\n"
          ]
        }
      ],
      "source": [
        "! pip freeze | grep shogun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "yq8b2vYnrLhI",
        "outputId": "ba4e0e6e-d99c-44cb-f4f9-a78e4a45aa2b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-df390d4bce8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshogun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLibSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shogun.Classifier'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from shogun.Classifier import LibSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btYdcJYtucVE",
        "outputId": "161e2a18-801a-4985-8c19-48d4d177e882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: shogun in /usr/local/lib/python3.8/dist-packages (0.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install shogun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "LN8Eo28dsCmi",
        "outputId": "9373bd3c-16be-468f-9cc8-1e79f8e3475e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-df390d4bce8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshogun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLibSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shogun.Classifier'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from shogun.Classifier import LibSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjHEhYLPFlgl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m21CrEdYs4mX"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOtLOjhaFiXu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "\n",
        "# st= StandardScaler()\n",
        " \n",
        "\n",
        "# # standardization \n",
        "# scale = st.fit_transform(Data_1) \n",
        "# print(scale)\n",
        "# Data_1=scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjyVCJ-7F_rC"
      },
      "outputs": [],
      "source": [
        "# x= Data_1[:, 0:29]\n",
        "# y= Data_1[:,29]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMrhkwXqcs3W"
      },
      "outputs": [],
      "source": [
        "x= Data_1.iloc[:, 0:29]\n",
        "y= Data_1.iloc[:,29]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5OT3XQIJwKI",
        "outputId": "7d15fb84-0fa9-4c43-e345-452245f97c3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 29)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvEgVoF_J1M6",
        "outputId": "60b2e52f-a39c-403d-d901-34c7dc576f0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121,)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnYgAcGah3eu",
        "outputId": "47b05bbd-4aa8-4cea-cf7f-fc7c7d67f6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.945021645021645\n",
            "Test accuracy of best grid search hypers: 0.8461538461538461\n",
            "Best CV params {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.945021645021645\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Test accuracy of best grid search hypers: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x= Data_1.iloc[:, 0:29]\n",
        "y= Data_1.iloc[:,29]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8al5W1w6K8JO",
        "outputId": "ec485d7c-9892-4141-e1ed-ee0851276252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9264069264069263\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.945021645021645\n",
            "Test accuracy of best grid search hypers: 0.75\n",
            "Best CV params {'C': 0.01}\n",
            "Best CV accuracy 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.loc[train_index]\n",
        "  X_test=x.loc[test_index]\n",
        "  y_train=y[train_index]\n",
        "  y_test=y[test_index]\n",
        "  svm = SVC()\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100]} # 'kernel':['rbf'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#when gamma =0.001 accurcy reduced\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCRMQ7e3H0On",
        "outputId": "300b8ebf-847a-41a1-d245-0a89cbe3305c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when c = 0.01 accuracy 84.61538461538461\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 83.33333333333334\n",
            "when c = 0.01 accuracy 100.0\n",
            "when c = 0.01 accuracy 91.66666666666666\n",
            "when c = 0.01 accuracy 66.66666666666666\n",
            "when c = 0.1 accuracy 84.61538461538461\n",
            "when c = 0.1 accuracy 100.0\n",
            "when c = 0.1 accuracy 91.66666666666666\n",
            "when c = 0.1 accuracy 91.66666666666666\n",
            "when c = 0.1 accuracy 91.66666666666666\n",
            "when c = 0.1 accuracy 100.0\n",
            "when c = 0.1 accuracy 91.66666666666666\n",
            "when c = 0.1 accuracy 100.0\n",
            "when c = 0.1 accuracy 83.33333333333334\n",
            "when c = 0.1 accuracy 91.66666666666666\n",
            "when c = 1 accuracy 92.3076923076923\n",
            "when c = 1 accuracy 75.0\n",
            "when c = 1 accuracy 100.0\n",
            "when c = 1 accuracy 100.0\n",
            "when c = 1 accuracy 91.66666666666666\n",
            "when c = 1 accuracy 75.0\n",
            "when c = 1 accuracy 100.0\n",
            "when c = 1 accuracy 91.66666666666666\n",
            "when c = 1 accuracy 100.0\n",
            "when c = 1 accuracy 91.66666666666666\n",
            "when c = 10 accuracy 92.3076923076923\n",
            "when c = 10 accuracy 100.0\n",
            "when c = 10 accuracy 83.33333333333334\n",
            "when c = 10 accuracy 83.33333333333334\n",
            "when c = 10 accuracy 83.33333333333334\n",
            "when c = 10 accuracy 100.0\n",
            "when c = 10 accuracy 100.0\n",
            "when c = 10 accuracy 100.0\n",
            "when c = 10 accuracy 100.0\n",
            "when c = 10 accuracy 75.0\n",
            "when c = 100 accuracy 92.3076923076923\n",
            "when c = 100 accuracy 83.33333333333334\n",
            "when c = 100 accuracy 100.0\n",
            "when c = 100 accuracy 91.66666666666666\n",
            "when c = 100 accuracy 100.0\n",
            "when c = 100 accuracy 75.0\n",
            "when c = 100 accuracy 83.33333333333334\n",
            "when c = 100 accuracy 91.66666666666666\n",
            "when c = 100 accuracy 91.66666666666666\n",
            "when c = 100 accuracy 91.66666666666666\n"
          ]
        }
      ],
      "source": [
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "CList=[0.01 ,0.1,1, 10, 100]\n",
        "for i in CList:\n",
        "  for train_index, test_index in folds.split(x):\n",
        "    X_train=x.loc[train_index]\n",
        "    X_test=x.loc[test_index]\n",
        "    y_train=y[train_index]\n",
        "    y_test=y[test_index]\n",
        "  \n",
        "    svm = SVC(C=i)\n",
        "    svm.fit(X_train, y_train)\n",
        "    # Using the model to predict the labels of the test data\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Evaluating the accuracy of the model using the sklearn functions\n",
        "    accuracy = accuracy_score(y_test,y_pred)*100\n",
        "    print(\"when c =\",i, \"accuracy\",accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KujZNk7g40Zt"
      },
      "outputs": [],
      "source": [
        "#c = 1 and gamma = 0.0001 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEOA0bjuVz71"
      },
      "outputs": [],
      "source": [
        "# #KFold k=10\n",
        "\n",
        " \n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "# #folds=LeaveOneOut()\n",
        "# result=pd.DataFrame(columns=['actual', 'predictions'])\n",
        "# y_pred=np.array([])\n",
        "# y_actual=np.array([])\n",
        "# for train_index, test_index in folds.split(x):\n",
        "#   X_train=x.loc[train_index]\n",
        "#   X_test=x.loc[test_index]\n",
        "#   y_train=y[train_index]\n",
        "#   y_test=y[test_index]\n",
        "#   param={'penalty':['l1', 'l2', 'elasticnet'],'fit_intercept':[True, False],'C':[0.1,10,100]}\n",
        "#   clf=GridSearchCV(LogisticRegression,param)\n",
        "#   clf.fit(X_train,y_train)\n",
        "#   y_hat=clf.predict(X_test)\n",
        "#   y_pred=np.append(y_pred,y_hat)\n",
        "#   y_actual=np.append(y_actual,y_test)\n",
        "#   print('This iteration resulted: ', str(mean_absolute_error(y_test,y_hat)))\n",
        "\n",
        "# result['actual']=y_actual\n",
        "# result['predictions']=y_pred \n",
        "\n",
        "# mae=mean_absolute_error(y_actual, y_pred)\n",
        "# mse=mean_squared_error(y_actual, y_pred) \n",
        "# print(f'mae= {mae} and mse={mse}') \n",
        "# print(result)  \n",
        "# #print(train_index)\n",
        "# #print(test_index)#print('----------------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXG0dnxKP38O"
      },
      "outputs": [],
      "source": [
        "# # manual nested cross-validation for random forest on a classification dataset\n",
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from sklearn.datasets import make_classification\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# # create dataset\n",
        "# X, y = make_classification(n_samples=1000, n_features=20, random_state=1, n_informative=10, n_redundant=10)\n",
        "# # configure the cross-validation procedure\n",
        "# cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# # enumerate splits\n",
        "# outer_results = list()\n",
        "# for train_ix, test_ix in cv_outer.split(X):\n",
        "# \t# split data\n",
        "# \tX_train, X_test = X[train_ix, :], X[test_ix, :]\n",
        "# \ty_train, y_test = y[train_ix], y[test_ix]\n",
        "# \t# configure the cross-validation procedure\n",
        "# \tcv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
        "# \t# define the model\n",
        "# \tmodel = RandomForestClassifier(random_state=1)\n",
        "# \t# define search space\n",
        "# \tspace = dict()\n",
        "# \tspace['n_estimators'] = [10, 100, 500]\n",
        "# \tspace['max_features'] = [2, 4, 6]\n",
        "# \t# define search\n",
        "# \tsearch = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "# \t# execute search\n",
        "# \tresult = search.fit(X_train, y_train)\n",
        "# \t# get the best performing model fit on the whole training set\n",
        "# \tbest_model = result.best_estimator_\n",
        "# \t# evaluate model on the hold out dataset\n",
        "# \tyhat = best_model.predict(X_test)\n",
        "# \t# evaluate the model\n",
        "# \tacc = accuracy_score(y_test, yhat)\n",
        "# \t# store the result\n",
        "# \touter_results.append(acc)\n",
        "# \t# report progress\n",
        "# \tprint('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
        "# # summarize the estimated performance of the model\n",
        "# print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCV6UCctz0oC"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBBe7_QtKbqv"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSwIUC4-fVi0",
        "outputId": "85e6c178-e59a-4b26-b65f-128ae0a0e588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[2.03884298e+01 2.06611570e-01 4.76033058e+00 7.43801653e-02\n",
            " 1.54214876e+01 1.24545455e+01 8.33057851e+00 2.37438017e+01\n",
            " 3.68760331e+01 2.07851240e+01 6.06198347e+01 2.05132231e+02\n",
            " 2.57603306e-01 7.79801653e+00 2.86179636e+03 6.83471074e-02\n",
            " 1.58988264e+02 9.60330579e+00 4.80165289e+00 2.23966942e+00\n",
            " 4.39669421e+00 9.91735537e-01 4.57024793e+00 3.12479339e-01\n",
            " 6.83140496e-01 2.23966942e+00 6.81818182e-01 2.53553719e-01\n",
            " 3.30578512e-01 7.43801653e-02]\n",
            "[[-0.68588219 -0.19945821 -0.12487144 ... -1.09621185 -0.58395716\n",
            "  -0.28347335]\n",
            " [-0.58342324 -0.19945821 -0.61757069 ... -0.32391704 -0.58395716\n",
            "  -0.28347335]\n",
            " [ 0.03133042 -0.19945821  1.51745941 ... -0.61352759 -0.58395716\n",
            "  -0.28347335]\n",
            " ...\n",
            " [-0.73711166 -0.19945821 -0.78180378 ...  0.73798833 -0.58395716\n",
            "  -0.28347335]\n",
            " [ 0.33870725 -0.19945821 -0.28910452 ... -0.32391704 -0.58395716\n",
            "  -0.28347335]\n",
            " [ 1.56821458  1.73129726  1.18899324 ...  0.15876722  1.18251325\n",
            "   3.52766841]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_1))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_1))\n",
        "Data_1=scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNbB_XjdF-YJ",
        "outputId": "2a930fde-d27c-48e4-8227-b39053167c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9354978354978355\n",
            "Test accuracy of best grid search hypers: 0.8461538461538461\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9359307359307361\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9177489177489176\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9268398268398268\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Best CV params {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best CV accuracy 0.9268398268398268\n"
          ]
        }
      ],
      "source": [
        "x= Data_1.iloc[:, 0:29]\n",
        "y= Data_1.iloc[:,29]\n",
        "# x=Data_1.drop(['defects'], axis=1)\n",
        "# y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUP5lY8vjwN2"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XqBuLu6rsWF",
        "outputId": "77cf6383-97a5-4b23-bc23-fc3295684716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9173160173160173\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.8991341991341992\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.880952380952381\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9082251082251082\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9177489177489179\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9173160173160173\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9086580086580087\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.8991341991341992\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.9264069264069266\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2'}\n",
            "Tuned Logistic Regression Accuracy: 0.8900432900432902\n",
            "Test accuracy of best grid search hypers: 0.9166666666666666\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "  \n",
        "\n",
        "\n",
        "x= Data_1.iloc[:, 0:29]\n",
        "y= Data_1.iloc[:,29]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfh_8nN7rsx4"
      },
      "source": [
        "## Data 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxFKQxxcrsx5"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqvbvWRersx5",
        "outputId": "26d37b9a-a332-418d-aead-5601688efe65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63, 30)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVWbYybDrsx7",
        "outputId": "2ae64b60-76a3-4ffd-ea18-9acf8193e72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           0\n",
              "blank_loc                           0\n",
              "comment_loc                         0\n",
              "code_and_comment_loc                0\n",
              "executable_loc                      0\n",
              "unique_operands                     0\n",
              "unique_operators                    0\n",
              "total_operands                      0\n",
              "total_operators                     0\n",
              "halstead_vocabulary                 0\n",
              "halstead_length                     0\n",
              "halstead_volume                     0\n",
              "halstead_level                      0\n",
              "halstead_difficulty                 0\n",
              "halstead_effort                     0\n",
              "halstead_error                      0\n",
              "halstead_time                       0\n",
              "branch_count                        0\n",
              "decision_count                      0\n",
              "call_pairs                          0\n",
              "condition_count                     0\n",
              "multiple_condition_count            0\n",
              "cyclomatic_complexity               0\n",
              "cyclomatic_density                  0\n",
              "decision_density                    0\n",
              "design_complexity                   0\n",
              "design_density                      0\n",
              "normalized_cyclomatic_complexity    0\n",
              "formal_parameters                   0\n",
              "defects                             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xpno5Zcrsx7",
        "outputId": "60646c5b-df99-43a8-8bee-d50e988cc1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           False\n",
              "blank_loc                           False\n",
              "comment_loc                         False\n",
              "code_and_comment_loc                False\n",
              "executable_loc                      False\n",
              "unique_operands                     False\n",
              "unique_operators                    False\n",
              "total_operands                      False\n",
              "total_operators                     False\n",
              "halstead_vocabulary                 False\n",
              "halstead_length                     False\n",
              "halstead_volume                     False\n",
              "halstead_level                      False\n",
              "halstead_difficulty                 False\n",
              "halstead_effort                     False\n",
              "halstead_error                      False\n",
              "halstead_time                       False\n",
              "branch_count                        False\n",
              "decision_count                      False\n",
              "call_pairs                          False\n",
              "condition_count                     False\n",
              "multiple_condition_count            False\n",
              "cyclomatic_complexity               False\n",
              "cyclomatic_density                  False\n",
              "decision_density                    False\n",
              "design_complexity                   False\n",
              "design_density                      False\n",
              "normalized_cyclomatic_complexity    False\n",
              "formal_parameters                   False\n",
              "defects                             False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_2.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P18u9OB5rsx8",
        "outputId": "593d8579-b2b1-470c-8fb1-2dd434d2f7d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fdd0daef-5422-4ed8-9482-11b89f2b80e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>63.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>89.269841</td>\n",
              "      <td>23.412698</td>\n",
              "      <td>13.285714</td>\n",
              "      <td>1.984127</td>\n",
              "      <td>52.571429</td>\n",
              "      <td>37.301587</td>\n",
              "      <td>12.253968</td>\n",
              "      <td>103.222222</td>\n",
              "      <td>137.222222</td>\n",
              "      <td>49.555556</td>\n",
              "      <td>...</td>\n",
              "      <td>9.634921</td>\n",
              "      <td>16.603175</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>13.174603</td>\n",
              "      <td>0.255955</td>\n",
              "      <td>0.752384</td>\n",
              "      <td>9.634921</td>\n",
              "      <td>2.016278</td>\n",
              "      <td>0.159493</td>\n",
              "      <td>0.206349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>116.732007</td>\n",
              "      <td>27.499933</td>\n",
              "      <td>27.163441</td>\n",
              "      <td>4.390209</td>\n",
              "      <td>68.006099</td>\n",
              "      <td>32.739261</td>\n",
              "      <td>7.064149</td>\n",
              "      <td>117.403144</td>\n",
              "      <td>163.627177</td>\n",
              "      <td>38.434182</td>\n",
              "      <td>...</td>\n",
              "      <td>17.993997</td>\n",
              "      <td>25.240482</td>\n",
              "      <td>7.589709</td>\n",
              "      <td>17.917859</td>\n",
              "      <td>0.196274</td>\n",
              "      <td>0.559941</td>\n",
              "      <td>17.993997</td>\n",
              "      <td>3.921728</td>\n",
              "      <td>0.117447</td>\n",
              "      <td>0.513015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010989</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.143895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.083825</td>\n",
              "      <td>0.092330</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.215050</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.555560</td>\n",
              "      <td>0.126870</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>114.500000</td>\n",
              "      <td>31.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>166.500000</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>23.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>0.313395</td>\n",
              "      <td>1.005300</td>\n",
              "      <td>10.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>670.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>575.000000</td>\n",
              "      <td>817.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.285700</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdd0daef-5422-4ed8-9482-11b89f2b80e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdd0daef-5422-4ed8-9482-11b89f2b80e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdd0daef-5422-4ed8-9482-11b89f2b80e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        total_loc   blank_loc  comment_loc  code_and_comment_loc  \\\n",
              "count   63.000000   63.000000    63.000000             63.000000   \n",
              "mean    89.269841   23.412698    13.285714              1.984127   \n",
              "std    116.732007   27.499933    27.163441              4.390209   \n",
              "min      3.000000    0.000000     0.000000              0.000000   \n",
              "25%     18.000000    5.000000     0.000000              0.000000   \n",
              "50%     57.000000   10.000000     5.000000              0.000000   \n",
              "75%    114.500000   31.500000    15.500000              3.000000   \n",
              "max    670.000000  116.000000   195.000000             31.000000   \n",
              "\n",
              "       executable_loc  unique_operands  unique_operators  total_operands  \\\n",
              "count       63.000000        63.000000         63.000000       63.000000   \n",
              "mean        52.571429        37.301587         12.253968      103.222222   \n",
              "std         68.006099        32.739261          7.064149      117.403144   \n",
              "min          3.000000         4.000000          3.000000        5.000000   \n",
              "25%         11.500000        13.500000          6.000000       25.500000   \n",
              "50%         31.000000        25.000000         11.000000       58.000000   \n",
              "75%         62.500000        51.000000         16.000000      124.000000   \n",
              "max        394.000000       142.000000         31.000000      575.000000   \n",
              "\n",
              "       total_operators  halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "count        63.000000            63.000000  ...   63.000000        63.000000   \n",
              "mean        137.222222            49.555556  ...    9.634921        16.603175   \n",
              "std         163.627177            38.434182  ...   17.993997        25.240482   \n",
              "min           8.000000             8.000000  ...    0.000000         0.000000   \n",
              "25%          33.500000            23.000000  ...    1.000000         0.000000   \n",
              "50%          74.000000            34.000000  ...    2.000000         8.000000   \n",
              "75%         166.500000            67.500000  ...   10.500000        23.500000   \n",
              "max         817.000000           169.000000  ...  109.000000       122.000000   \n",
              "\n",
              "       multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "count                 63.000000              63.000000           63.000000   \n",
              "mean                   4.571429              13.174603            0.255955   \n",
              "std                    7.589709              17.917859            0.196274   \n",
              "min                    0.000000               1.000000            0.019231   \n",
              "25%                    0.000000               1.000000            0.143895   \n",
              "50%                    1.000000               5.000000            0.215050   \n",
              "75%                    6.000000              16.500000            0.313395   \n",
              "max                   33.000000              85.000000            1.285700   \n",
              "\n",
              "       decision_density  design_complexity  design_density  \\\n",
              "count         63.000000          63.000000       63.000000   \n",
              "mean           0.752384           9.634921        2.016278   \n",
              "std            0.559941          17.993997        3.921728   \n",
              "min            0.000000           0.000000        0.000000   \n",
              "25%            0.000000           1.000000        0.083825   \n",
              "50%            1.000000           2.000000        0.555560   \n",
              "75%            1.005300          10.500000        2.000000   \n",
              "max            2.000000         109.000000       24.000000   \n",
              "\n",
              "       normalized_cyclomatic_complexity  formal_parameters  \n",
              "count                         63.000000          63.000000  \n",
              "mean                           0.159493           0.206349  \n",
              "std                            0.117447           0.513015  \n",
              "min                            0.010989           0.000000  \n",
              "25%                            0.092330           0.000000  \n",
              "50%                            0.126870           0.000000  \n",
              "75%                            0.200000           0.000000  \n",
              "max                            0.700000           2.000000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjPcGIgGrsx9",
        "outputId": "73089379-94cc-4615-fe48-8fb1d1f12a68"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94fbfd7a-e4af-4f97-967a-994905c65ea0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>307</td>\n",
              "      <td>116</td>\n",
              "      <td>44</td>\n",
              "      <td>5</td>\n",
              "      <td>147</td>\n",
              "      <td>138</td>\n",
              "      <td>23</td>\n",
              "      <td>245</td>\n",
              "      <td>366</td>\n",
              "      <td>161</td>\n",
              "      <td>...</td>\n",
              "      <td>39</td>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>0.25170</td>\n",
              "      <td>1.2051</td>\n",
              "      <td>43</td>\n",
              "      <td>1.162200</td>\n",
              "      <td>0.120520</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333330</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>268</td>\n",
              "      <td>72</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>125</td>\n",
              "      <td>23</td>\n",
              "      <td>337</td>\n",
              "      <td>484</td>\n",
              "      <td>148</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.36782</td>\n",
              "      <td>1.0106</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238810</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.14286</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>173</td>\n",
              "      <td>59</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>92</td>\n",
              "      <td>77</td>\n",
              "      <td>31</td>\n",
              "      <td>277</td>\n",
              "      <td>352</td>\n",
              "      <td>108</td>\n",
              "      <td>...</td>\n",
              "      <td>53</td>\n",
              "      <td>14</td>\n",
              "      <td>40</td>\n",
              "      <td>0.43478</td>\n",
              "      <td>1.0189</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231210</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>114</td>\n",
              "      <td>32</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>46</td>\n",
              "      <td>23</td>\n",
              "      <td>134</td>\n",
              "      <td>180</td>\n",
              "      <td>69</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>0.31429</td>\n",
              "      <td>1.0370</td>\n",
              "      <td>1</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.192980</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>148</td>\n",
              "      <td>41</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>42</td>\n",
              "      <td>16</td>\n",
              "      <td>147</td>\n",
              "      <td>208</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>24</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>0.17647</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121620</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>18</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0.70000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.142860</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>333</td>\n",
              "      <td>94</td>\n",
              "      <td>53</td>\n",
              "      <td>9</td>\n",
              "      <td>186</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>352</td>\n",
              "      <td>469</td>\n",
              "      <td>74</td>\n",
              "      <td>...</td>\n",
              "      <td>56</td>\n",
              "      <td>15</td>\n",
              "      <td>40</td>\n",
              "      <td>0.21505</td>\n",
              "      <td>1.0179</td>\n",
              "      <td>23</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.120120</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94fbfd7a-e4af-4f97-967a-994905c65ea0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94fbfd7a-e4af-4f97-967a-994905c65ea0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94fbfd7a-e4af-4f97-967a-994905c65ea0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0         307        116           44                     5             147   \n",
              "1           3          0            0                     0               3   \n",
              "2         268         72           22                     0             174   \n",
              "3          11          2            0                     0               9   \n",
              "4           9          2            0                     0               7   \n",
              "..        ...        ...          ...                   ...             ...   \n",
              "58        173         59           22                     6              92   \n",
              "59        114         32           12                     3              70   \n",
              "60        148         41            5                     0             102   \n",
              "61         10          0            0                     0              10   \n",
              "62        333         94           53                     9             186   \n",
              "\n",
              "    unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0               138                23             245              366   \n",
              "1                 4                 6               6                8   \n",
              "2               125                23             337              484   \n",
              "3                10                 4              15               17   \n",
              "4                 7                 4              11               13   \n",
              "..              ...               ...             ...              ...   \n",
              "58               77                31             277              352   \n",
              "59               46                23             134              180   \n",
              "60               42                16             147              208   \n",
              "61               11                 7              30               38   \n",
              "62               56                18             352              469   \n",
              "\n",
              "    halstead_vocabulary  ...  condition_count  multiple_condition_count  \\\n",
              "0                   161  ...               39                        10   \n",
              "1                    10  ...                0                         0   \n",
              "2                   148  ...               94                        32   \n",
              "3                    14  ...                0                         0   \n",
              "4                    11  ...                0                         0   \n",
              "..                  ...  ...              ...                       ...   \n",
              "58                  108  ...               53                        14   \n",
              "59                   69  ...               27                         7   \n",
              "60                   58  ...               24                         7   \n",
              "61                   18  ...               12                         6   \n",
              "62                   74  ...               56                        15   \n",
              "\n",
              "    cyclomatic_complexity  cyclomatic_density  decision_density  \\\n",
              "0                      37             0.25170            1.2051   \n",
              "1                       1             0.33333            0.0000   \n",
              "2                      64             0.36782            1.0106   \n",
              "3                       1             0.11111            0.0000   \n",
              "4                       1             0.14286            0.0000   \n",
              "..                    ...                 ...               ...   \n",
              "58                     40             0.43478            1.0189   \n",
              "59                     22             0.31429            1.0370   \n",
              "60                     18             0.17647            1.0000   \n",
              "61                      7             0.70000            1.0000   \n",
              "62                     40             0.21505            1.0179   \n",
              "\n",
              "    design_complexity  design_density  normalized_cyclomatic_complexity  \\\n",
              "0                  43        1.162200                          0.120520   \n",
              "1                   0        0.000000                          0.333330   \n",
              "2                   0        0.000000                          0.238810   \n",
              "3                   2        2.000000                          0.090909   \n",
              "4                   1        1.000000                          0.111110   \n",
              "..                ...             ...                               ...   \n",
              "58                  0        0.000000                          0.231210   \n",
              "59                  1        0.045455                          0.192980   \n",
              "60                  0        0.000000                          0.121620   \n",
              "61                  1        0.142860                          0.700000   \n",
              "62                 23        0.575000                          0.120120   \n",
              "\n",
              "    formal_parameters  defects  \n",
              "0                   0     True  \n",
              "1                   0    False  \n",
              "2                   0    False  \n",
              "3                   0    False  \n",
              "4                   0    False  \n",
              "..                ...      ...  \n",
              "58                  0     True  \n",
              "59                  0    False  \n",
              "60                  0    False  \n",
              "61                  0    False  \n",
              "62                  0     True  \n",
              "\n",
              "[63 rows x 30 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RyrsDy3rsx-"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u4YOsDMrsx_",
        "outputId": "f60290a4-38bd-487f-9a5d-4f99bf43d909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9287878787878789\n",
            "Test accuracy of best grid search hypers: 0.8571428571428571\n",
            "Best CV params {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9287878787878787\n",
            "Test accuracy of best grid search hypers: 0.7142857142857143\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9303030303030303\n",
            "Test accuracy of best grid search hypers: 0.7142857142857143\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8954545454545455\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8969696969696971\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8969696969696969\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8954545454545455\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9136363636363637\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9318181818181819\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9136363636363637\n",
            "Test accuracy of best grid search hypers: 1.0\n"
          ]
        }
      ],
      "source": [
        "x= Data_2.iloc[:, 0:29]\n",
        "y= Data_2.iloc[:,29]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TEXujUxb5bD"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a11BLr8nb5b_",
        "outputId": "41fe1cb8-272e-4b33-a124-f16a98460165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[8.92698413e+01 2.34126984e+01 1.32857143e+01 1.98412698e+00\n",
            " 5.25714286e+01 3.73015873e+01 1.22539683e+01 1.03222222e+02\n",
            " 1.37222222e+02 4.95555556e+01 2.40444444e+02 1.03706349e+03\n",
            " 1.27439619e-01 1.68972270e+01 3.48581681e+04 3.45688265e-01\n",
            " 1.93656490e+03 3.41269841e+01 1.70634921e+01 9.63492063e+00\n",
            " 1.66031746e+01 4.57142857e+00 1.31746032e+01 2.55955349e-01\n",
            " 7.52384127e-01 9.63492063e+00 2.01627760e+00 1.59493048e-01\n",
            " 2.06349206e-01 1.26984127e-01]\n",
            "[[ 1.88019575  3.39386239  1.1398037  ... -0.33450173 -0.40545886\n",
            "   2.62202212]\n",
            " [-0.74497805 -0.85821139 -0.49303137 ...  1.49202498 -0.40545886\n",
            "  -0.38138504]\n",
            " [ 1.54341358  1.78100682  0.32338617 ...  0.68076938 -0.40545886\n",
            "  -0.38138504]\n",
            " ...\n",
            " [ 0.50716077  0.64467676 -0.30748193 ... -0.32506054 -0.40545886\n",
            "  -0.38138504]\n",
            " [-0.68452997 -0.85821139 -0.49303137 ...  4.6391165  -0.40545886\n",
            "  -0.38138504]\n",
            " [ 2.10471719  2.5874346   1.47379269 ... -0.33793489 -0.40545886\n",
            "   2.62202212]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_2))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQVSi14BcSQ-",
        "outputId": "09776f86-d23a-4a62-f809-cb699e19d4bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT7OG8F5b5cA",
        "outputId": "c6888032-f1af-46a4-ac64-defa31b66932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.9106060606060605\n",
            "Test accuracy of best grid search hypers: 0.8571428571428571\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8939393939393939\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.9303030303030303\n",
            "Test accuracy of best grid search hypers: 0.8571428571428571\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8984848484848484\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9318181818181819\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8984848484848484\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9318181818181819\n",
            "Test accuracy of best grid search hypers: 0.6666666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9318181818181819\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8984848484848484\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9\n",
            "Test accuracy of best grid search hypers: 0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_2.iloc[:, 0:29]\n",
        "y= Data_2.iloc[:,29]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62zq4uhGjs3u"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoLy5a2krx2F"
      },
      "source": [
        "## Data 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb96igfhrx2G"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmO7D91erx2G",
        "outputId": "acd186d1-c8ac-45ab-edf0-ae53eaabd5df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(107, 30)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffbfCC6hrx2G",
        "outputId": "e84f2f62-cc58-45f1-d468-6c6acf254f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           0\n",
              "blank_loc                           0\n",
              "comment_loc                         0\n",
              "code_and_comment_loc                0\n",
              "executable_loc                      0\n",
              "unique_operands                     0\n",
              "unique_operators                    0\n",
              "total_operands                      0\n",
              "total_operators                     0\n",
              "halstead_vocabulary                 0\n",
              "halstead_length                     0\n",
              "halstead_volume                     0\n",
              "halstead_level                      0\n",
              "halstead_difficulty                 0\n",
              "halstead_effort                     0\n",
              "halstead_error                      0\n",
              "halstead_time                       0\n",
              "branch_count                        0\n",
              "decision_count                      0\n",
              "call_pairs                          0\n",
              "condition_count                     0\n",
              "multiple_condition_count            0\n",
              "cyclomatic_complexity               0\n",
              "cyclomatic_density                  0\n",
              "decision_density                    0\n",
              "design_complexity                   0\n",
              "design_density                      0\n",
              "normalized_cyclomatic_complexity    0\n",
              "formal_parameters                   0\n",
              "defects                             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_3.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4qZfGrFrx2H",
        "outputId": "695e697f-b6c9-4a99-9625-390dc9f10cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           False\n",
              "blank_loc                           False\n",
              "comment_loc                         False\n",
              "code_and_comment_loc                False\n",
              "executable_loc                      False\n",
              "unique_operands                     False\n",
              "unique_operators                    False\n",
              "total_operands                      False\n",
              "total_operators                     False\n",
              "halstead_vocabulary                 False\n",
              "halstead_length                     False\n",
              "halstead_volume                     False\n",
              "halstead_level                      False\n",
              "halstead_difficulty                 False\n",
              "halstead_effort                     False\n",
              "halstead_error                      False\n",
              "halstead_time                       False\n",
              "branch_count                        False\n",
              "decision_count                      False\n",
              "call_pairs                          False\n",
              "condition_count                     False\n",
              "multiple_condition_count            False\n",
              "cyclomatic_complexity               False\n",
              "cyclomatic_density                  False\n",
              "decision_density                    False\n",
              "design_complexity                   False\n",
              "design_density                      False\n",
              "normalized_cyclomatic_complexity    False\n",
              "formal_parameters                   False\n",
              "defects                             False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_3.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_be5eu87rx2H",
        "outputId": "2f861432-5987-4f44-8ac1-aea1e5d5f099"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89295035-5309-440a-bac3-90ab0083b73f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.00000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>107.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>85.943925</td>\n",
              "      <td>35.495327</td>\n",
              "      <td>11.242991</td>\n",
              "      <td>0.411215</td>\n",
              "      <td>39.205607</td>\n",
              "      <td>25.037383</td>\n",
              "      <td>11.542056</td>\n",
              "      <td>61.056075</td>\n",
              "      <td>90.420561</td>\n",
              "      <td>36.579439</td>\n",
              "      <td>...</td>\n",
              "      <td>3.336449</td>\n",
              "      <td>9.738318</td>\n",
              "      <td>2.88785</td>\n",
              "      <td>8.093458</td>\n",
              "      <td>0.203087</td>\n",
              "      <td>0.854831</td>\n",
              "      <td>3.336449</td>\n",
              "      <td>0.555981</td>\n",
              "      <td>0.101639</td>\n",
              "      <td>0.308411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>113.609546</td>\n",
              "      <td>50.529531</td>\n",
              "      <td>24.727130</td>\n",
              "      <td>2.210410</td>\n",
              "      <td>45.118448</td>\n",
              "      <td>19.368777</td>\n",
              "      <td>5.369868</td>\n",
              "      <td>74.584362</td>\n",
              "      <td>111.248917</td>\n",
              "      <td>22.579017</td>\n",
              "      <td>...</td>\n",
              "      <td>6.876188</td>\n",
              "      <td>15.624326</td>\n",
              "      <td>5.23473</td>\n",
              "      <td>10.753264</td>\n",
              "      <td>0.077767</td>\n",
              "      <td>0.496992</td>\n",
              "      <td>6.876188</td>\n",
              "      <td>0.858192</td>\n",
              "      <td>0.047394</td>\n",
              "      <td>0.828857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005525</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.154705</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.205880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.099476</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>102.500000</td>\n",
              "      <td>39.500000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>73.500000</td>\n",
              "      <td>107.500000</td>\n",
              "      <td>44.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.50000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.251730</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.916665</td>\n",
              "      <td>0.123645</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>907.000000</td>\n",
              "      <td>395.000000</td>\n",
              "      <td>209.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>829.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>34.00000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.333300</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.260270</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89295035-5309-440a-bac3-90ab0083b73f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89295035-5309-440a-bac3-90ab0083b73f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89295035-5309-440a-bac3-90ab0083b73f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        total_loc   blank_loc  comment_loc  code_and_comment_loc  \\\n",
              "count  107.000000  107.000000   107.000000            107.000000   \n",
              "mean    85.943925   35.495327    11.242991              0.411215   \n",
              "std    113.609546   50.529531    24.727130              2.210410   \n",
              "min      6.000000    0.000000     0.000000              0.000000   \n",
              "25%     25.000000    8.500000     1.000000              0.000000   \n",
              "50%     54.000000   22.000000     4.000000              0.000000   \n",
              "75%    102.500000   39.500000    11.500000              0.000000   \n",
              "max    907.000000  395.000000   209.000000             16.000000   \n",
              "\n",
              "       executable_loc  unique_operands  unique_operators  total_operands  \\\n",
              "count      107.000000       107.000000        107.000000      107.000000   \n",
              "mean        39.205607        25.037383         11.542056       61.056075   \n",
              "std         45.118448        19.368777          5.369868       74.584362   \n",
              "min          3.000000         4.000000          4.000000        4.000000   \n",
              "25%         14.000000        12.000000          7.000000       20.500000   \n",
              "50%         24.000000        20.000000         11.000000       38.000000   \n",
              "75%         47.000000        31.000000         15.000000       73.500000   \n",
              "max        303.000000       112.000000         28.000000      560.000000   \n",
              "\n",
              "       total_operators  halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "count       107.000000           107.000000  ...  107.000000       107.000000   \n",
              "mean         90.420561            36.579439  ...    3.336449         9.738318   \n",
              "std         111.248917            22.579017  ...    6.876188        15.624326   \n",
              "min           7.000000             8.000000  ...    0.000000         0.000000   \n",
              "25%          31.000000            21.500000  ...    0.000000         1.000000   \n",
              "50%          57.000000            32.000000  ...    1.000000         4.000000   \n",
              "75%         107.500000            44.500000  ...    4.000000        12.000000   \n",
              "max         829.000000           132.000000  ...   54.000000       104.000000   \n",
              "\n",
              "       multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "count                 107.00000             107.000000          107.000000   \n",
              "mean                    2.88785               8.093458            0.203087   \n",
              "std                     5.23473              10.753264            0.077767   \n",
              "min                     0.00000               1.000000            0.020833   \n",
              "25%                     0.00000               2.000000            0.154705   \n",
              "50%                     1.00000               5.000000            0.205880   \n",
              "75%                     3.50000              10.000000            0.251730   \n",
              "max                    34.00000              75.000000            0.400000   \n",
              "\n",
              "       decision_density  design_complexity  design_density  \\\n",
              "count        107.000000         107.000000      107.000000   \n",
              "mean           0.854831           3.336449        0.555981   \n",
              "std            0.496992           6.876188        0.858192   \n",
              "min            0.000000           0.000000        0.000000   \n",
              "25%            1.000000           0.000000        0.000000   \n",
              "50%            1.000000           1.000000        0.250000   \n",
              "75%            1.000000           4.000000        0.916665   \n",
              "max            2.333300          54.000000        6.000000   \n",
              "\n",
              "       normalized_cyclomatic_complexity  formal_parameters  \n",
              "count                        107.000000         107.000000  \n",
              "mean                           0.101639           0.308411  \n",
              "std                            0.047394           0.828857  \n",
              "min                            0.005525           0.000000  \n",
              "25%                            0.076923           0.000000  \n",
              "50%                            0.099476           0.000000  \n",
              "75%                            0.123645           0.000000  \n",
              "max                            0.260270           4.000000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_3.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msYTHM5Wrx2H",
        "outputId": "2da7bea7-74dc-4be4-c3e3-ea9b7ffe701a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc832912-c4ab-470f-ac44-44a16fe501ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>103</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>81</td>\n",
              "      <td>111</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.20513</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.077670</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>38</td>\n",
              "      <td>54</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.19231</td>\n",
              "      <td>1.2000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.094340</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>42</td>\n",
              "      <td>58</td>\n",
              "      <td>26</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.14286</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>67</td>\n",
              "      <td>97</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>0.20930</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.123290</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>48</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0.25806</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.115940</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>71</td>\n",
              "      <td>27</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>53</td>\n",
              "      <td>80</td>\n",
              "      <td>35</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.17143</td>\n",
              "      <td>1.2000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.084507</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>79</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>23</td>\n",
              "      <td>10</td>\n",
              "      <td>52</td>\n",
              "      <td>79</td>\n",
              "      <td>33</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0.23529</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.101270</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.27273</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.157890</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>119</td>\n",
              "      <td>59</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>20</td>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>107</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0.21277</td>\n",
              "      <td>1.1000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.084034</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.28571</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.222220</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc832912-c4ab-470f-ac44-44a16fe501ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc832912-c4ab-470f-ac44-44a16fe501ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc832912-c4ab-470f-ac44-44a16fe501ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0          103         61            3                     0              39   \n",
              "1           53         22            5                     0              26   \n",
              "2           25         10            1                     0              14   \n",
              "3           73         22            8                     1              43   \n",
              "4           69         21           17                     0              31   \n",
              "..         ...        ...          ...                   ...             ...   \n",
              "102         71         27            9                     0              35   \n",
              "103         79         40            5                     0              34   \n",
              "104         19          8            0                     0              11   \n",
              "105        119         59           13                     0              47   \n",
              "106          9          2            0                     0               7   \n",
              "\n",
              "     unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0                 26                19              81              111   \n",
              "1                 18                16              38               54   \n",
              "2                 12                14              42               58   \n",
              "3                 25                12              67               97   \n",
              "4                 16                 9              28               48   \n",
              "..               ...               ...             ...              ...   \n",
              "102               19                16              53               80   \n",
              "103               23                10              52               79   \n",
              "104                8                14              19               29   \n",
              "105               20                23              68              107   \n",
              "106                5                 6               6               11   \n",
              "\n",
              "     halstead_vocabulary  ...  condition_count  multiple_condition_count  \\\n",
              "0                     45  ...                7                         1   \n",
              "1                     34  ...                5                         2   \n",
              "2                     26  ...                1                         0   \n",
              "3                     37  ...               15                         7   \n",
              "4                     25  ...               13                         6   \n",
              "..                   ...  ...              ...                       ...   \n",
              "102                   35  ...                5                         1   \n",
              "103                   33  ...                9                         2   \n",
              "104                   22  ...                1                         0   \n",
              "105                   43  ...               10                         2   \n",
              "106                   11  ...                1                         0   \n",
              "\n",
              "     cyclomatic_complexity  cyclomatic_density  decision_density  \\\n",
              "0                        8             0.20513            1.1429   \n",
              "1                        5             0.19231            1.2000   \n",
              "2                        2             0.14286            1.0000   \n",
              "3                        9             0.20930            1.0000   \n",
              "4                        8             0.25806            1.0000   \n",
              "..                     ...                 ...               ...   \n",
              "102                      6             0.17143            1.2000   \n",
              "103                      8             0.23529            1.0000   \n",
              "104                      3             0.27273            2.0000   \n",
              "105                     10             0.21277            1.1000   \n",
              "106                      2             0.28571            1.0000   \n",
              "\n",
              "     design_complexity  design_density  normalized_cyclomatic_complexity  \\\n",
              "0                    2            0.25                          0.077670   \n",
              "1                    0            0.00                          0.094340   \n",
              "2                    0            0.00                          0.080000   \n",
              "3                    0            0.00                          0.123290   \n",
              "4                    0            0.00                          0.115940   \n",
              "..                 ...             ...                               ...   \n",
              "102                  0            0.00                          0.084507   \n",
              "103                  2            0.25                          0.101270   \n",
              "104                  0            0.00                          0.157890   \n",
              "105                  2            0.20                          0.084034   \n",
              "106                  1            0.50                          0.222220   \n",
              "\n",
              "     formal_parameters  defects  \n",
              "0                    0    False  \n",
              "1                    1    False  \n",
              "2                    2    False  \n",
              "3                    0    False  \n",
              "4                    0    False  \n",
              "..                 ...      ...  \n",
              "102                  0    False  \n",
              "103                  0    False  \n",
              "104                  2    False  \n",
              "105                  0    False  \n",
              "106                  0    False  \n",
              "\n",
              "[107 rows x 30 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ndn1nuRrx2H"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HUQUlcarx2H",
        "outputId": "eaa9a1a8-b9ae-4094-b152-66f0db2006ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8757894736842106\n",
            "Test accuracy of best grid search hypers: 0.8181818181818182\n",
            "Best CV params {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.8647368421052631\n",
            "Test accuracy of best grid search hypers: 0.8181818181818182\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.875263157894737\n",
            "Test accuracy of best grid search hypers: 0.5454545454545454\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8542105263157895\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.8857894736842106\n",
            "Test accuracy of best grid search hypers: 0.7272727272727273\n",
            "Best CV params {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.8957894736842105\n",
            "Test accuracy of best grid search hypers: 0.7272727272727273\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8647368421052631\n",
            "Test accuracy of best grid search hypers: 0.9090909090909091\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8768421052631579\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8663157894736842\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8668421052631577\n",
            "Test accuracy of best grid search hypers: 0.9\n"
          ]
        }
      ],
      "source": [
        "x= Data_3.iloc[:, 0:29]\n",
        "y= Data_3.iloc[:,29]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FOrmp49dv6V"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-f4fhgRdv6V",
        "outputId": "1b183dcd-dcd9-4d97-eef3-0f92ce8b910a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[8.92698413e+01 2.34126984e+01 1.32857143e+01 1.98412698e+00\n",
            " 5.25714286e+01 3.73015873e+01 1.22539683e+01 1.03222222e+02\n",
            " 1.37222222e+02 4.95555556e+01 2.40444444e+02 1.03706349e+03\n",
            " 1.27439619e-01 1.68972270e+01 3.48581681e+04 3.45688265e-01\n",
            " 1.93656490e+03 3.41269841e+01 1.70634921e+01 9.63492063e+00\n",
            " 1.66031746e+01 4.57142857e+00 1.31746032e+01 2.55955349e-01\n",
            " 7.52384127e-01 9.63492063e+00 2.01627760e+00 1.59493048e-01\n",
            " 2.06349206e-01 1.26984127e-01]\n",
            "[[ 1.88019575  3.39386239  1.1398037  ... -0.33450173 -0.40545886\n",
            "   2.62202212]\n",
            " [-0.74497805 -0.85821139 -0.49303137 ...  1.49202498 -0.40545886\n",
            "  -0.38138504]\n",
            " [ 1.54341358  1.78100682  0.32338617 ...  0.68076938 -0.40545886\n",
            "  -0.38138504]\n",
            " ...\n",
            " [ 0.50716077  0.64467676 -0.30748193 ... -0.32506054 -0.40545886\n",
            "  -0.38138504]\n",
            " [-0.68452997 -0.85821139 -0.49303137 ...  4.6391165  -0.40545886\n",
            "  -0.38138504]\n",
            " [ 2.10471719  2.5874346   1.47379269 ... -0.33793489 -0.40545886\n",
            "   2.62202212]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_2))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvIHht7odv6W",
        "outputId": "6d8228ac-5e19-49eb-c6c5-ed3df97dcdfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8647368421052631\n",
            "Test accuracy of best grid search hypers: 0.9090909090909091\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8652631578947367\n",
            "Test accuracy of best grid search hypers: 0.9090909090909091\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8647368421052631\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8647368421052631\n",
            "Test accuracy of best grid search hypers: 0.9090909090909091\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.8963157894736842\n",
            "Test accuracy of best grid search hypers: 0.7272727272727273\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8652631578947367\n",
            "Test accuracy of best grid search hypers: 0.8181818181818182\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8752631578947367\n",
            "Test accuracy of best grid search hypers: 0.8181818181818182\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.8873684210526316\n",
            "Test accuracy of best grid search hypers: 0.7\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8668421052631577\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8457894736842105\n",
            "Test accuracy of best grid search hypers: 0.8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_3.iloc[:, 0:29]\n",
        "y= Data_3.iloc[:,29]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHNfAoPHjqAp"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ef9UGjItQyD"
      },
      "source": [
        "## Data 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZycVLlntQyE"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb6VqDH6tQyE",
        "outputId": "e67f7a06-53a1-4b02-a489-20a60b082691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36, 30)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S_zsuTItQyE",
        "outputId": "8ac5c83b-264d-4465-fa14-7b3fb80d5bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           0\n",
              "blank_loc                           0\n",
              "comment_loc                         0\n",
              "code_and_comment_loc                0\n",
              "executable_loc                      0\n",
              "unique_operands                     0\n",
              "unique_operators                    0\n",
              "total_operands                      0\n",
              "total_operators                     0\n",
              "halstead_vocabulary                 0\n",
              "halstead_length                     0\n",
              "halstead_volume                     0\n",
              "halstead_level                      0\n",
              "halstead_difficulty                 0\n",
              "halstead_effort                     0\n",
              "halstead_error                      0\n",
              "halstead_time                       0\n",
              "branch_count                        0\n",
              "decision_count                      0\n",
              "call_pairs                          0\n",
              "condition_count                     0\n",
              "multiple_condition_count            0\n",
              "cyclomatic_complexity               0\n",
              "cyclomatic_density                  0\n",
              "decision_density                    0\n",
              "design_complexity                   0\n",
              "design_density                      0\n",
              "normalized_cyclomatic_complexity    0\n",
              "formal_parameters                   0\n",
              "defects                             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_4.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TViopruptQyE",
        "outputId": "753ed549-0093-41b6-8998-618e98fc91b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           False\n",
              "blank_loc                           False\n",
              "comment_loc                         False\n",
              "code_and_comment_loc                False\n",
              "executable_loc                      False\n",
              "unique_operands                     False\n",
              "unique_operators                    False\n",
              "total_operands                      False\n",
              "total_operators                     False\n",
              "halstead_vocabulary                 False\n",
              "halstead_length                     False\n",
              "halstead_volume                     False\n",
              "halstead_level                      False\n",
              "halstead_difficulty                 False\n",
              "halstead_effort                     False\n",
              "halstead_error                      False\n",
              "halstead_time                       False\n",
              "branch_count                        False\n",
              "decision_count                      False\n",
              "call_pairs                          False\n",
              "condition_count                     False\n",
              "multiple_condition_count            False\n",
              "cyclomatic_complexity               False\n",
              "cyclomatic_density                  False\n",
              "decision_density                    False\n",
              "design_complexity                   False\n",
              "design_density                      False\n",
              "normalized_cyclomatic_complexity    False\n",
              "formal_parameters                   False\n",
              "defects                             False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_4.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lALLJbq6tQyE",
        "outputId": "8f6fc41b-393c-4e60-bd2c-000178d466e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f47c0053-5600-426c-af12-b7db6cacc400\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>75.888889</td>\n",
              "      <td>18.166667</td>\n",
              "      <td>8.861111</td>\n",
              "      <td>1.361111</td>\n",
              "      <td>48.861111</td>\n",
              "      <td>35.027778</td>\n",
              "      <td>12.583333</td>\n",
              "      <td>93.333333</td>\n",
              "      <td>127.472222</td>\n",
              "      <td>47.611111</td>\n",
              "      <td>...</td>\n",
              "      <td>4.083333</td>\n",
              "      <td>16.305556</td>\n",
              "      <td>4.027778</td>\n",
              "      <td>13.777778</td>\n",
              "      <td>0.249513</td>\n",
              "      <td>0.847175</td>\n",
              "      <td>4.083333</td>\n",
              "      <td>1.106278</td>\n",
              "      <td>0.169183</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>90.129677</td>\n",
              "      <td>20.507142</td>\n",
              "      <td>16.221948</td>\n",
              "      <td>1.914647</td>\n",
              "      <td>55.765403</td>\n",
              "      <td>29.867791</td>\n",
              "      <td>7.511420</td>\n",
              "      <td>98.826544</td>\n",
              "      <td>142.376059</td>\n",
              "      <td>35.981962</td>\n",
              "      <td>...</td>\n",
              "      <td>5.044799</td>\n",
              "      <td>23.549121</td>\n",
              "      <td>5.724564</td>\n",
              "      <td>18.206924</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>0.623000</td>\n",
              "      <td>5.044799</td>\n",
              "      <td>2.043274</td>\n",
              "      <td>0.098754</td>\n",
              "      <td>0.540429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.750000</td>\n",
              "      <td>14.750000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.750000</td>\n",
              "      <td>24.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>0.161145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.046467</td>\n",
              "      <td>0.114312</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>51.500000</td>\n",
              "      <td>58.500000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.233245</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.373980</td>\n",
              "      <td>0.171065</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>112.750000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>10.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>73.750000</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>153.250000</td>\n",
              "      <td>210.250000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.322937</td>\n",
              "      <td>1.050025</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.068175</td>\n",
              "      <td>0.195508</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>477.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>284.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>482.000000</td>\n",
              "      <td>699.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.727270</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.571430</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f47c0053-5600-426c-af12-b7db6cacc400')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f47c0053-5600-426c-af12-b7db6cacc400 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f47c0053-5600-426c-af12-b7db6cacc400');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        total_loc   blank_loc  comment_loc  code_and_comment_loc  \\\n",
              "count   36.000000   36.000000    36.000000             36.000000   \n",
              "mean    75.888889   18.166667     8.861111              1.361111   \n",
              "std     90.129677   20.507142    16.221948              1.914647   \n",
              "min      5.000000    0.000000     0.000000              0.000000   \n",
              "25%     20.500000    4.000000     0.000000              0.000000   \n",
              "50%     42.000000   12.500000     3.000000              0.000000   \n",
              "75%    112.750000   25.250000    10.250000              3.000000   \n",
              "max    477.000000  104.000000    89.000000              8.000000   \n",
              "\n",
              "       executable_loc  unique_operands  unique_operators  total_operands  \\\n",
              "count       36.000000        36.000000         36.000000       36.000000   \n",
              "mean        48.861111        35.027778         12.583333       93.333333   \n",
              "std         55.765403        29.867791          7.511420       98.826544   \n",
              "min          5.000000         5.000000          3.000000        5.000000   \n",
              "25%         11.750000        14.750000          6.000000       28.000000   \n",
              "50%         26.000000        26.500000         11.000000       51.500000   \n",
              "75%         73.750000        46.500000         16.250000      153.250000   \n",
              "max        284.000000       150.000000         29.000000      482.000000   \n",
              "\n",
              "       total_operators  halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "count        36.000000            36.000000  ...   36.000000        36.000000   \n",
              "mean        127.472222            47.611111  ...    4.083333        16.305556   \n",
              "std         142.376059            35.981962  ...    5.044799        23.549121   \n",
              "min           9.000000             8.000000  ...    0.000000         0.000000   \n",
              "25%          34.750000            24.750000  ...    1.000000         0.000000   \n",
              "50%          58.500000            35.500000  ...    2.000000         8.000000   \n",
              "75%         210.250000            64.000000  ...    4.500000        25.250000   \n",
              "max         699.000000           179.000000  ...   20.000000       116.000000   \n",
              "\n",
              "       multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "count                 36.000000              36.000000           36.000000   \n",
              "mean                   4.027778              13.777778            0.249513   \n",
              "std                    5.724564              18.206924            0.128539   \n",
              "min                    0.000000               1.000000            0.041667   \n",
              "25%                    0.000000               1.750000            0.161145   \n",
              "50%                    1.500000               7.000000            0.233245   \n",
              "75%                    6.000000              21.000000            0.322937   \n",
              "max                   25.000000              93.000000            0.727270   \n",
              "\n",
              "       decision_density  design_complexity  design_density  \\\n",
              "count         36.000000          36.000000       36.000000   \n",
              "mean           0.847175           4.083333        1.106278   \n",
              "std            0.623000           5.044799        2.043274   \n",
              "min            0.000000           0.000000        0.000000   \n",
              "25%            0.000000           1.000000        0.046467   \n",
              "50%            1.000000           2.000000        0.373980   \n",
              "75%            1.050025           4.500000        1.068175   \n",
              "max            2.500000          20.000000       10.000000   \n",
              "\n",
              "       normalized_cyclomatic_complexity  formal_parameters  \n",
              "count                         36.000000          36.000000  \n",
              "mean                           0.169183           0.222222  \n",
              "std                            0.098754           0.540429  \n",
              "min                            0.021277           0.000000  \n",
              "25%                            0.114312           0.000000  \n",
              "50%                            0.171065           0.000000  \n",
              "75%                            0.195508           0.000000  \n",
              "max                            0.571430           2.000000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_4.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32cBkDjvtQyF",
        "outputId": "82f9b22c-5410-4b0b-ebf6-8b67b218ebc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-defed974-8a71-4827-8053-27c01207c406\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>55</td>\n",
              "      <td>12</td>\n",
              "      <td>91</td>\n",
              "      <td>132</td>\n",
              "      <td>67</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.212770</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>20</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.121950</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>42</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166670</td>\n",
              "      <td>0.193550</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477</td>\n",
              "      <td>104</td>\n",
              "      <td>89</td>\n",
              "      <td>2</td>\n",
              "      <td>284</td>\n",
              "      <td>150</td>\n",
              "      <td>29</td>\n",
              "      <td>482</td>\n",
              "      <td>699</td>\n",
              "      <td>179</td>\n",
              "      <td>...</td>\n",
              "      <td>116</td>\n",
              "      <td>25</td>\n",
              "      <td>93</td>\n",
              "      <td>0.327460</td>\n",
              "      <td>1.0172</td>\n",
              "      <td>4</td>\n",
              "      <td>0.043011</td>\n",
              "      <td>0.194970</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.142860</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.111110</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>49</td>\n",
              "      <td>53</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.181820</td>\n",
              "      <td>1.3333</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.142860</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>41</td>\n",
              "      <td>44</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666670</td>\n",
              "      <td>0.115380</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>7</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>26</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.176470</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>7</td>\n",
              "      <td>2.333300</td>\n",
              "      <td>0.136360</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166670</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>43</td>\n",
              "      <td>58</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0.294120</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.217390</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>86</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>76</td>\n",
              "      <td>113</td>\n",
              "      <td>42</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0.160710</td>\n",
              "      <td>1.0909</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333330</td>\n",
              "      <td>0.104650</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>115</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>97</td>\n",
              "      <td>35</td>\n",
              "      <td>16</td>\n",
              "      <td>154</td>\n",
              "      <td>204</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>0.216490</td>\n",
              "      <td>1.0400</td>\n",
              "      <td>2</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.182610</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>150</td>\n",
              "      <td>43</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>79</td>\n",
              "      <td>16</td>\n",
              "      <td>184</td>\n",
              "      <td>229</td>\n",
              "      <td>95</td>\n",
              "      <td>...</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>0.176470</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>13</td>\n",
              "      <td>0.722220</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>47</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>45</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>52</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>35</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.142860</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>65</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>92</td>\n",
              "      <td>110</td>\n",
              "      <td>53</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.289470</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>14</td>\n",
              "      <td>1.272700</td>\n",
              "      <td>0.169230</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>55</td>\n",
              "      <td>57</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>10</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>42</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>65</td>\n",
              "      <td>85</td>\n",
              "      <td>41</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0.275860</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190480</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>34</td>\n",
              "      <td>43</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0.727270</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.571430</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>36</td>\n",
              "      <td>46</td>\n",
              "      <td>26</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.190480</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.137930</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>151</td>\n",
              "      <td>38</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>28</td>\n",
              "      <td>189</td>\n",
              "      <td>285</td>\n",
              "      <td>92</td>\n",
              "      <td>...</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>1.1034</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192050</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>40</td>\n",
              "      <td>59</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119050</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>208</td>\n",
              "      <td>38</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>142</td>\n",
              "      <td>70</td>\n",
              "      <td>17</td>\n",
              "      <td>259</td>\n",
              "      <td>371</td>\n",
              "      <td>87</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>12</td>\n",
              "      <td>41</td>\n",
              "      <td>0.288730</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>17</td>\n",
              "      <td>0.414630</td>\n",
              "      <td>0.197120</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>48</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>28</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>88</td>\n",
              "      <td>42</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0.387100</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>135</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>71</td>\n",
              "      <td>87</td>\n",
              "      <td>23</td>\n",
              "      <td>203</td>\n",
              "      <td>258</td>\n",
              "      <td>110</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>0.366200</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.153850</td>\n",
              "      <td>0.192590</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>125</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>88</td>\n",
              "      <td>62</td>\n",
              "      <td>27</td>\n",
              "      <td>153</td>\n",
              "      <td>229</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>0.329550</td>\n",
              "      <td>1.0606</td>\n",
              "      <td>9</td>\n",
              "      <td>0.310340</td>\n",
              "      <td>0.232000</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.416670</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.357140</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>147</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>105</td>\n",
              "      <td>46</td>\n",
              "      <td>17</td>\n",
              "      <td>165</td>\n",
              "      <td>247</td>\n",
              "      <td>63</td>\n",
              "      <td>...</td>\n",
              "      <td>46</td>\n",
              "      <td>8</td>\n",
              "      <td>38</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258500</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>214</td>\n",
              "      <td>55</td>\n",
              "      <td>38</td>\n",
              "      <td>8</td>\n",
              "      <td>121</td>\n",
              "      <td>71</td>\n",
              "      <td>23</td>\n",
              "      <td>221</td>\n",
              "      <td>309</td>\n",
              "      <td>94</td>\n",
              "      <td>...</td>\n",
              "      <td>54</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>0.305790</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.108110</td>\n",
              "      <td>0.172900</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>112</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>82</td>\n",
              "      <td>35</td>\n",
              "      <td>23</td>\n",
              "      <td>226</td>\n",
              "      <td>305</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>43</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>0.365850</td>\n",
              "      <td>1.0465</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.267860</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>110</td>\n",
              "      <td>29</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>48</td>\n",
              "      <td>23</td>\n",
              "      <td>135</td>\n",
              "      <td>182</td>\n",
              "      <td>71</td>\n",
              "      <td>...</td>\n",
              "      <td>26</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.0385</td>\n",
              "      <td>1</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.190910</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>49</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>53</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0.321430</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.183670</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-defed974-8a71-4827-8053-27c01207c406')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-defed974-8a71-4827-8053-27c01207c406 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-defed974-8a71-4827-8053-27c01207c406');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0          82         26            9                     0              47   \n",
              "1          16          6            2                     1               8   \n",
              "2          31         12            3                     2              16   \n",
              "3         477        104           89                     2             284   \n",
              "4          11          2            0                     0               9   \n",
              "5           9          2            0                     0               7   \n",
              "6          10          2            0                     0               8   \n",
              "7           5          0            0                     0               5   \n",
              "8          28          5            1                     0              22   \n",
              "9          26          6            0                     0              20   \n",
              "10         15          4            0                     0              11   \n",
              "11         22          4            1                     0              17   \n",
              "12         10          4            0                     0               6   \n",
              "13         23          5            1                     0              17   \n",
              "14         86         22            8                     3              56   \n",
              "15        115         17            1                     1              97   \n",
              "16        150         43            5                     1             102   \n",
              "17         47         14           17                     0              16   \n",
              "18         35         13           15                     0               7   \n",
              "19         65         18            9                     0              38   \n",
              "20         29          4            1                     0              24   \n",
              "21         42         13            0                     0              29   \n",
              "22         14          3            0                     0              11   \n",
              "23         29          8            0                     0              21   \n",
              "24        151         38           13                     4             100   \n",
              "25         42          8            3                     0              31   \n",
              "26        208         38           28                     4             142   \n",
              "27         48          9            8                     4              31   \n",
              "28        135         44           20                     2              71   \n",
              "29        125         25           12                     4              88   \n",
              "30         14          2            0                     0              12   \n",
              "31        147         32           10                     4             105   \n",
              "32        214         55           38                     8             121   \n",
              "33        112         23            7                     3              82   \n",
              "34        110         29           11                     3              70   \n",
              "35         49         14            7                     3              28   \n",
              "\n",
              "    unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0                55                12              91              132   \n",
              "1                13                 6              18               20   \n",
              "2                18                 9              31               42   \n",
              "3               150                29             482              699   \n",
              "4                10                 4              15               17   \n",
              "5                 7                 4              11               13   \n",
              "6                 7                 4              13               15   \n",
              "7                 5                 3               5                9   \n",
              "8                18                12              49               53   \n",
              "9                16                11              41               44   \n",
              "10               11                 5              19               22   \n",
              "11               17                 9              25               36   \n",
              "12                9                 6              24               23   \n",
              "13               15                10              43               58   \n",
              "14               31                11              76              113   \n",
              "15               35                16             154              204   \n",
              "16               79                16             184              229   \n",
              "17               45                 5              50               52   \n",
              "18               26                 4              29               31   \n",
              "19               43                10              92              110   \n",
              "20               27                 5              55               57   \n",
              "21               27                14              65               85   \n",
              "22               14                 7              34               43   \n",
              "23               18                 8              36               46   \n",
              "24               64                28             189              285   \n",
              "25               18                11              40               59   \n",
              "26               70                17             259              371   \n",
              "27               28                14              56               88   \n",
              "28               87                23             203              258   \n",
              "29               62                27             153              229   \n",
              "30               13                11              18               29   \n",
              "31               46                17             165              247   \n",
              "32               71                23             221              309   \n",
              "33               35                23             226              305   \n",
              "34               48                23             135              182   \n",
              "35               23                16              53               74   \n",
              "\n",
              "    halstead_vocabulary  ...  condition_count  multiple_condition_count  \\\n",
              "0                    67  ...                4                         1   \n",
              "1                    19  ...                0                         0   \n",
              "2                    27  ...                5                         0   \n",
              "3                   179  ...              116                        25   \n",
              "4                    14  ...                0                         0   \n",
              "5                    11  ...                0                         0   \n",
              "6                    11  ...                0                         0   \n",
              "7                     8  ...                0                         0   \n",
              "8                    30  ...                3                         1   \n",
              "9                    27  ...                1                         0   \n",
              "10                   16  ...                0                         0   \n",
              "11                   26  ...                1                         0   \n",
              "12                   15  ...                0                         0   \n",
              "13                   25  ...                8                         4   \n",
              "14                   42  ...               11                         4   \n",
              "15                   51  ...               25                         4   \n",
              "16                   95  ...               21                         7   \n",
              "17                   50  ...                0                         0   \n",
              "18                   30  ...                0                         0   \n",
              "19                   53  ...               10                         0   \n",
              "20                   32  ...                0                         0   \n",
              "21                   41  ...                8                         2   \n",
              "22                   21  ...               13                         6   \n",
              "23                   26  ...                4                         1   \n",
              "24                   92  ...               29                         3   \n",
              "25                   29  ...                8                         4   \n",
              "26                   87  ...               52                        12   \n",
              "27                   42  ...               16                         5   \n",
              "28                  110  ...               35                        10   \n",
              "29                   89  ...               33                         6   \n",
              "30                   24  ...                4                         0   \n",
              "31                   63  ...               46                         8   \n",
              "32                   94  ...               54                        17   \n",
              "33                   58  ...               43                        15   \n",
              "34                   71  ...               26                         7   \n",
              "35                   39  ...               11                         3   \n",
              "\n",
              "    cyclomatic_complexity  cyclomatic_density  decision_density  \\\n",
              "0                      10            0.212770            2.5000   \n",
              "1                       2            0.250000            0.0000   \n",
              "2                       6            0.375000            1.0000   \n",
              "3                      93            0.327460            1.0172   \n",
              "4                       1            0.111110            0.0000   \n",
              "5                       1            0.142860            0.0000   \n",
              "6                       1            0.125000            0.0000   \n",
              "7                       1            0.200000            0.0000   \n",
              "8                       4            0.181820            1.3333   \n",
              "9                       3            0.150000            2.0000   \n",
              "10                      1            0.090909            0.0000   \n",
              "11                      3            0.176470            2.0000   \n",
              "12                      1            0.166670            0.0000   \n",
              "13                      5            0.294120            1.0000   \n",
              "14                      9            0.160710            1.0909   \n",
              "15                     21            0.216490            1.0400   \n",
              "16                     18            0.176470            1.1429   \n",
              "17                      1            0.062500            0.0000   \n",
              "18                      1            0.142860            0.0000   \n",
              "19                     11            0.289470            1.0000   \n",
              "20                      1            0.041667            0.0000   \n",
              "21                      8            0.275860            1.1250   \n",
              "22                      8            0.727270            1.0000   \n",
              "23                      4            0.190480            1.0000   \n",
              "24                     29            0.290000            1.1034   \n",
              "25                      5            0.161290            1.0000   \n",
              "26                     41            0.288730            1.0000   \n",
              "27                     12            0.387100            1.0000   \n",
              "28                     26            0.366200            1.0000   \n",
              "29                     29            0.329550            1.0606   \n",
              "30                      5            0.416670            1.0000   \n",
              "31                     38            0.361900            1.0000   \n",
              "32                     37            0.305790            1.0000   \n",
              "33                     30            0.365850            1.0465   \n",
              "34                     21            0.300000            1.0385   \n",
              "35                      9            0.321430            1.0000   \n",
              "\n",
              "    design_complexity  design_density  normalized_cyclomatic_complexity  \\\n",
              "0                  20        2.000000                          0.121950   \n",
              "1                   1        0.500000                          0.125000   \n",
              "2                   1        0.166670                          0.193550   \n",
              "3                   4        0.043011                          0.194970   \n",
              "4                   2        2.000000                          0.090909   \n",
              "5                   1        1.000000                          0.111110   \n",
              "6                   2        2.000000                          0.100000   \n",
              "7                   3        3.000000                          0.200000   \n",
              "8                   2        0.500000                          0.142860   \n",
              "9                   2        0.666670                          0.115380   \n",
              "10                  7        7.000000                          0.066667   \n",
              "11                  7        2.333300                          0.136360   \n",
              "12                  3        3.000000                          0.100000   \n",
              "13                  4        0.800000                          0.217390   \n",
              "14                  3        0.333330                          0.104650   \n",
              "15                  2        0.095238                          0.182610   \n",
              "16                 13        0.722220                          0.120000   \n",
              "17                  0        0.000000                          0.021277   \n",
              "18                  0        0.000000                          0.028571   \n",
              "19                 14        1.272700                          0.169230   \n",
              "20                 10       10.000000                          0.034483   \n",
              "21                  0        0.000000                          0.190480   \n",
              "22                  1        0.125000                          0.571430   \n",
              "23                  2        0.500000                          0.137930   \n",
              "24                  0        0.000000                          0.192050   \n",
              "25                  0        0.000000                          0.119050   \n",
              "26                 17        0.414630                          0.197120   \n",
              "27                  6        0.500000                          0.250000   \n",
              "28                  4        0.153850                          0.192590   \n",
              "29                  9        0.310340                          0.232000   \n",
              "30                  1        0.200000                          0.357140   \n",
              "31                  0        0.000000                          0.258500   \n",
              "32                  4        0.108110                          0.172900   \n",
              "33                  1        0.033333                          0.267860   \n",
              "34                  1        0.047619                          0.190910   \n",
              "35                  0        0.000000                          0.183670   \n",
              "\n",
              "    formal_parameters  defects  \n",
              "0                   0    False  \n",
              "1                   1    False  \n",
              "2                   0    False  \n",
              "3                   0     True  \n",
              "4                   0    False  \n",
              "5                   0    False  \n",
              "6                   0    False  \n",
              "7                   0    False  \n",
              "8                   1    False  \n",
              "9                   0    False  \n",
              "10                  1    False  \n",
              "11                  2    False  \n",
              "12                  2    False  \n",
              "13                  1    False  \n",
              "14                  0    False  \n",
              "15                  0    False  \n",
              "16                  0     True  \n",
              "17                  0    False  \n",
              "18                  0    False  \n",
              "19                  0    False  \n",
              "20                  0    False  \n",
              "21                  0    False  \n",
              "22                  0    False  \n",
              "23                  0    False  \n",
              "24                  0    False  \n",
              "25                  0    False  \n",
              "26                  0     True  \n",
              "27                  0    False  \n",
              "28                  0     True  \n",
              "29                  0     True  \n",
              "30                  0    False  \n",
              "31                  0    False  \n",
              "32                  0     True  \n",
              "33                  0    False  \n",
              "34                  0     True  \n",
              "35                  0     True  \n",
              "\n",
              "[36 rows x 30 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyjDzza-tQyF"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAiqTmwOtQyF",
        "outputId": "86a666e5-fb60-4b32-f4fc-2706318de293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.8714285714285716\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8714285714285716\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9\n",
            "Test accuracy of best grid search hypers: 0.5\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8428571428571429\n",
            "Test accuracy of best grid search hypers: 0.25\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9047619047619048\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9\n",
            "Test accuracy of best grid search hypers: 0.5\n",
            "Best CV params {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.8333333333333334\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01, 'gamma': 1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8714285714285716\n",
            "Test accuracy of best grid search hypers: 0.3333333333333333\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9047619047619048\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8714285714285716\n",
            "Test accuracy of best grid search hypers: 1.0\n"
          ]
        }
      ],
      "source": [
        "x= Data_4.iloc[:, 0:29]\n",
        "y= Data_4.iloc[:,29]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZxAZuCId4AV"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ8dl0kkd4AW",
        "outputId": "92ef18e0-70d0-4c53-e649-cdb3424f3363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[8.92698413e+01 2.34126984e+01 1.32857143e+01 1.98412698e+00\n",
            " 5.25714286e+01 3.73015873e+01 1.22539683e+01 1.03222222e+02\n",
            " 1.37222222e+02 4.95555556e+01 2.40444444e+02 1.03706349e+03\n",
            " 1.27439619e-01 1.68972270e+01 3.48581681e+04 3.45688265e-01\n",
            " 1.93656490e+03 3.41269841e+01 1.70634921e+01 9.63492063e+00\n",
            " 1.66031746e+01 4.57142857e+00 1.31746032e+01 2.55955349e-01\n",
            " 7.52384127e-01 9.63492063e+00 2.01627760e+00 1.59493048e-01\n",
            " 2.06349206e-01 1.26984127e-01]\n",
            "[[ 1.88019575  3.39386239  1.1398037  ... -0.33450173 -0.40545886\n",
            "   2.62202212]\n",
            " [-0.74497805 -0.85821139 -0.49303137 ...  1.49202498 -0.40545886\n",
            "  -0.38138504]\n",
            " [ 1.54341358  1.78100682  0.32338617 ...  0.68076938 -0.40545886\n",
            "  -0.38138504]\n",
            " ...\n",
            " [ 0.50716077  0.64467676 -0.30748193 ... -0.32506054 -0.40545886\n",
            "  -0.38138504]\n",
            " [-0.68452997 -0.85821139 -0.49303137 ...  4.6391165  -0.40545886\n",
            "  -0.38138504]\n",
            " [ 2.10471719  2.5874346   1.47379269 ... -0.33793489 -0.40545886\n",
            "   2.62202212]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_2))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KU5bb4nd4AW",
        "outputId": "09776f86-d23a-4a62-f809-cb699e19d4bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KWZbRZod4AX",
        "outputId": "7a11e008-8ce9-4ea9-cf7c-125d1e65c32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9333333333333333\n",
            "Test accuracy of best grid search hypers: 0.75\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8714285714285716\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9333333333333333\n",
            "Test accuracy of best grid search hypers: 0.5\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9333333333333333\n",
            "Test accuracy of best grid search hypers: 0.75\n",
            "Tuned Logistic Regression Parameter: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8666666666666668\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9\n",
            "Test accuracy of best grid search hypers: 0.6666666666666666\n",
            "Tuned Logistic Regression Parameter: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8666666666666668\n",
            "Test accuracy of best grid search hypers: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_4.iloc[:, 0:29]\n",
        "y= Data_4.iloc[:,29]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kORqhrgKjmli"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvVVQr9UtRdY"
      },
      "source": [
        "## Data 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yB2l1eTtRda"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKl8dUwMtRdb",
        "outputId": "580c85da-7498-4631-9415-ef3d72bb6c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(101, 30)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybAU_x-htRdc",
        "outputId": "2cb530b5-f05d-4618-cdb7-dc16326f8654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           0\n",
              "blank_loc                           0\n",
              "comment_loc                         0\n",
              "code_and_comment_loc                0\n",
              "executable_loc                      0\n",
              "unique_operands                     0\n",
              "unique_operators                    0\n",
              "total_operands                      0\n",
              "total_operators                     0\n",
              "halstead_vocabulary                 0\n",
              "halstead_length                     0\n",
              "halstead_volume                     0\n",
              "halstead_level                      0\n",
              "halstead_difficulty                 0\n",
              "halstead_effort                     0\n",
              "halstead_error                      0\n",
              "halstead_time                       0\n",
              "branch_count                        0\n",
              "decision_count                      0\n",
              "call_pairs                          0\n",
              "condition_count                     0\n",
              "multiple_condition_count            0\n",
              "cyclomatic_complexity               0\n",
              "cyclomatic_density                  0\n",
              "decision_density                    0\n",
              "design_complexity                   0\n",
              "design_density                      0\n",
              "normalized_cyclomatic_complexity    0\n",
              "formal_parameters                   0\n",
              "defects                             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_5.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomJ9Ru_tRdd",
        "outputId": "44b8f200-8014-4e8b-d872-59fb60e1792c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "total_loc                           False\n",
              "blank_loc                           False\n",
              "comment_loc                         False\n",
              "code_and_comment_loc                False\n",
              "executable_loc                      False\n",
              "unique_operands                     False\n",
              "unique_operators                    False\n",
              "total_operands                      False\n",
              "total_operators                     False\n",
              "halstead_vocabulary                 False\n",
              "halstead_length                     False\n",
              "halstead_volume                     False\n",
              "halstead_level                      False\n",
              "halstead_difficulty                 False\n",
              "halstead_effort                     False\n",
              "halstead_error                      False\n",
              "halstead_time                       False\n",
              "branch_count                        False\n",
              "decision_count                      False\n",
              "call_pairs                          False\n",
              "condition_count                     False\n",
              "multiple_condition_count            False\n",
              "cyclomatic_complexity               False\n",
              "cyclomatic_density                  False\n",
              "decision_density                    False\n",
              "design_complexity                   False\n",
              "design_density                      False\n",
              "normalized_cyclomatic_complexity    False\n",
              "formal_parameters                   False\n",
              "defects                             False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_5.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgYn1OU1tRdd",
        "outputId": "b90a9e61-7418-4eb8-b8e2-bc2895086841"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d3980d2-fc12-4403-a9e6-8b4035579f20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>101.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.574257</td>\n",
              "      <td>1.079208</td>\n",
              "      <td>5.128713</td>\n",
              "      <td>0.277228</td>\n",
              "      <td>15.257426</td>\n",
              "      <td>13.524752</td>\n",
              "      <td>8.584158</td>\n",
              "      <td>24.405941</td>\n",
              "      <td>37.465347</td>\n",
              "      <td>22.821782</td>\n",
              "      <td>...</td>\n",
              "      <td>2.643564</td>\n",
              "      <td>3.277228</td>\n",
              "      <td>0.950495</td>\n",
              "      <td>3.841584</td>\n",
              "      <td>0.448317</td>\n",
              "      <td>0.671584</td>\n",
              "      <td>2.470396</td>\n",
              "      <td>0.850891</td>\n",
              "      <td>0.197030</td>\n",
              "      <td>0.261584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>19.888362</td>\n",
              "      <td>6.402629</td>\n",
              "      <td>6.486391</td>\n",
              "      <td>1.429117</td>\n",
              "      <td>15.313167</td>\n",
              "      <td>10.931234</td>\n",
              "      <td>4.421012</td>\n",
              "      <td>22.906409</td>\n",
              "      <td>34.849552</td>\n",
              "      <td>16.935404</td>\n",
              "      <td>...</td>\n",
              "      <td>3.598845</td>\n",
              "      <td>5.069751</td>\n",
              "      <td>1.802089</td>\n",
              "      <td>3.732915</td>\n",
              "      <td>1.299518</td>\n",
              "      <td>0.688139</td>\n",
              "      <td>3.443492</td>\n",
              "      <td>1.421071</td>\n",
              "      <td>0.079013</td>\n",
              "      <td>0.460186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d3980d2-fc12-4403-a9e6-8b4035579f20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d3980d2-fc12-4403-a9e6-8b4035579f20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d3980d2-fc12-4403-a9e6-8b4035579f20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        total_loc   blank_loc  comment_loc  code_and_comment_loc  \\\n",
              "count  101.000000  101.000000   101.000000            101.000000   \n",
              "mean    20.574257    1.079208     5.128713              0.277228   \n",
              "std     19.888362    6.402629     6.486391              1.429117   \n",
              "min      1.000000    0.000000     0.000000              0.000000   \n",
              "25%      7.000000    0.000000     0.000000              0.000000   \n",
              "50%     12.000000    0.000000     3.000000              0.000000   \n",
              "75%     28.000000    0.000000     7.000000              0.000000   \n",
              "max     98.000000   48.000000    31.000000             11.000000   \n",
              "\n",
              "       executable_loc  unique_operands  unique_operators  total_operands  \\\n",
              "count      101.000000       101.000000        101.000000      101.000000   \n",
              "mean        15.257426        13.524752          8.584158       24.405941   \n",
              "std         15.313167        10.931234          4.421012       22.906409   \n",
              "min          0.000000         1.000000          2.000000        1.000000   \n",
              "25%          5.000000         6.000000          5.000000        7.000000   \n",
              "50%         10.000000        10.000000          8.000000       15.000000   \n",
              "75%         19.000000        15.000000         12.000000       38.000000   \n",
              "max         89.000000        50.000000         21.000000      109.000000   \n",
              "\n",
              "       total_operators  halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "count       101.000000           101.000000  ...  101.000000       101.000000   \n",
              "mean         37.465347            22.821782  ...    2.643564         3.277228   \n",
              "std          34.849552            16.935404  ...    3.598845         5.069751   \n",
              "min           3.000000             3.000000  ...    0.000000         0.000000   \n",
              "25%          11.000000            10.000000  ...    0.000000         0.000000   \n",
              "50%          27.000000            18.000000  ...    1.000000         1.000000   \n",
              "75%          55.000000            28.000000  ...    4.000000         4.000000   \n",
              "max         160.000000            97.000000  ...   20.000000        24.000000   \n",
              "\n",
              "       multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "count                101.000000             101.000000          101.000000   \n",
              "mean                   0.950495               3.841584            0.448317   \n",
              "std                    1.802089               3.732915            1.299518   \n",
              "min                    0.000000               1.000000            0.090000   \n",
              "25%                    0.000000               1.000000            0.200000   \n",
              "50%                    0.000000               3.000000            0.250000   \n",
              "75%                    1.000000               5.000000            0.320000   \n",
              "max                    9.000000              19.000000           10.000000   \n",
              "\n",
              "       decision_density  design_complexity  design_density  \\\n",
              "count        101.000000         101.000000      101.000000   \n",
              "mean           0.671584           2.470396        0.850891   \n",
              "std            0.688139           3.443492        1.421071   \n",
              "min            0.000000           0.000000        0.000000   \n",
              "25%            0.000000           0.000000        0.000000   \n",
              "50%            1.000000           1.000000        0.330000   \n",
              "75%            1.000000           4.000000        1.000000   \n",
              "max            3.000000          20.000000        7.000000   \n",
              "\n",
              "       normalized_cyclomatic_complexity  formal_parameters  \n",
              "count                        101.000000         101.000000  \n",
              "mean                           0.197030           0.261584  \n",
              "std                            0.079013           0.460186  \n",
              "min                            0.000000           0.000000  \n",
              "25%                            0.140000           0.000000  \n",
              "50%                            0.200000           0.000000  \n",
              "75%                            0.250000           0.210000  \n",
              "max                            0.380000           2.000000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_5.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBbSe54ltRdd"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrDM-y9NtRdd",
        "outputId": "47bfad69-c37d-4933-bd3e-9bc10c83938b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9111111111111111\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9017543859649122\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9017543859649123\n",
            "Test accuracy of best grid search hypers: 0.7\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9345029239766081\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.8906432748538011\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9017543859649122\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.87953216374269\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.87953216374269\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.8906432748538011\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9128654970760234\n",
            "Test accuracy of best grid search hypers: 0.7\n"
          ]
        }
      ],
      "source": [
        "x= Data_5.iloc[:, 0:29]\n",
        "y= Data_5.iloc[:,29]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB36409HtRwi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m58qRJ6cd6lj"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JAYqVsmd6lk",
        "outputId": "92ef18e0-70d0-4c53-e649-cdb3424f3363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[8.92698413e+01 2.34126984e+01 1.32857143e+01 1.98412698e+00\n",
            " 5.25714286e+01 3.73015873e+01 1.22539683e+01 1.03222222e+02\n",
            " 1.37222222e+02 4.95555556e+01 2.40444444e+02 1.03706349e+03\n",
            " 1.27439619e-01 1.68972270e+01 3.48581681e+04 3.45688265e-01\n",
            " 1.93656490e+03 3.41269841e+01 1.70634921e+01 9.63492063e+00\n",
            " 1.66031746e+01 4.57142857e+00 1.31746032e+01 2.55955349e-01\n",
            " 7.52384127e-01 9.63492063e+00 2.01627760e+00 1.59493048e-01\n",
            " 2.06349206e-01 1.26984127e-01]\n",
            "[[ 1.88019575  3.39386239  1.1398037  ... -0.33450173 -0.40545886\n",
            "   2.62202212]\n",
            " [-0.74497805 -0.85821139 -0.49303137 ...  1.49202498 -0.40545886\n",
            "  -0.38138504]\n",
            " [ 1.54341358  1.78100682  0.32338617 ...  0.68076938 -0.40545886\n",
            "  -0.38138504]\n",
            " ...\n",
            " [ 0.50716077  0.64467676 -0.30748193 ... -0.32506054 -0.40545886\n",
            "  -0.38138504]\n",
            " [-0.68452997 -0.85821139 -0.49303137 ...  4.6391165  -0.40545886\n",
            "  -0.38138504]\n",
            " [ 2.10471719  2.5874346   1.47379269 ... -0.33793489 -0.40545886\n",
            "   2.62202212]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_2))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjs47HKOd6lm",
        "outputId": "09776f86-d23a-4a62-f809-cb699e19d4bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLPcJ5fAd6ln",
        "outputId": "5a965137-6f9b-4ed2-8f86-19221f7da45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8666666666666668\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8906432748538011\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8690058479532163\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.868421052631579\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.8690058479532163\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.868421052631579\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.87953216374269\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Tuned Logistic Regression Parameter: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9350877192982455\n",
            "Test accuracy of best grid search hypers: 0.6\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.868421052631579\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.87953216374269\n",
            "Test accuracy of best grid search hypers: 0.8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_5.iloc[:, 0:29]\n",
        "y= Data_5.iloc[:,29]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91Turn1EjjJT"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRkLHSXPtR3E"
      },
      "source": [
        "## Data 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDbT3vYvtR3F"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1N3MxURtR3F",
        "outputId": "c41336d6-f1a0-4f45-cbf4-1c1fc361b7c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(498, 22)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xQmOfJjtR3F",
        "outputId": "8cd8cd2f-3e70-4d01-abb9-97f316f32fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "loc                  0\n",
              "vg                   0\n",
              "evg                  0\n",
              "ivg                  0\n",
              "n                    0\n",
              "v                    0\n",
              "l                    0\n",
              "d                    0\n",
              "i                    0\n",
              "e                    0\n",
              "b                    0\n",
              "t                    0\n",
              "lOCode               0\n",
              "lOComment            0\n",
              "lOBlank              0\n",
              "locCodeAndComment    0\n",
              "uniq_Op              0\n",
              "uniq_Opnd            0\n",
              "total_Op             0\n",
              "total_Opnd           0\n",
              "branchCount          0\n",
              "defects              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_6.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wnc0ryntR3G",
        "outputId": "0cb9daaf-1f60-4815-b09c-3a4945ba6eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "loc                  False\n",
              "vg                   False\n",
              "evg                  False\n",
              "ivg                  False\n",
              "n                    False\n",
              "v                    False\n",
              "l                    False\n",
              "d                    False\n",
              "i                    False\n",
              "e                    False\n",
              "b                    False\n",
              "t                    False\n",
              "lOCode               False\n",
              "lOComment            False\n",
              "lOBlank              False\n",
              "locCodeAndComment    False\n",
              "uniq_Op              False\n",
              "uniq_Opnd            False\n",
              "total_Op             False\n",
              "total_Opnd           False\n",
              "branchCount          False\n",
              "defects              False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_6.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plF8-qz_tR3G",
        "outputId": "d118f77e-0e9c-4a90-9d29-1c3a50bd2291"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ebb5a35c-104b-4bbb-87b3-ade9ba4c4324\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>vg</th>\n",
              "      <th>evg</th>\n",
              "      <th>ivg</th>\n",
              "      <th>n</th>\n",
              "      <th>v</th>\n",
              "      <th>l</th>\n",
              "      <th>d</th>\n",
              "      <th>i</th>\n",
              "      <th>e</th>\n",
              "      <th>...</th>\n",
              "      <th>t</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>4.980000e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>498.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.644779</td>\n",
              "      <td>5.382329</td>\n",
              "      <td>2.490763</td>\n",
              "      <td>3.528916</td>\n",
              "      <td>143.956426</td>\n",
              "      <td>900.175823</td>\n",
              "      <td>0.146325</td>\n",
              "      <td>15.829378</td>\n",
              "      <td>38.455361</td>\n",
              "      <td>3.488493e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>1938.056124</td>\n",
              "      <td>3.787149</td>\n",
              "      <td>12.283133</td>\n",
              "      <td>11.534137</td>\n",
              "      <td>0.006024</td>\n",
              "      <td>15.199197</td>\n",
              "      <td>25.452209</td>\n",
              "      <td>88.389960</td>\n",
              "      <td>55.570683</td>\n",
              "      <td>9.348193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.753572</td>\n",
              "      <td>8.347359</td>\n",
              "      <td>3.658847</td>\n",
              "      <td>5.464398</td>\n",
              "      <td>221.049888</td>\n",
              "      <td>1690.814334</td>\n",
              "      <td>0.159337</td>\n",
              "      <td>15.330960</td>\n",
              "      <td>36.996297</td>\n",
              "      <td>1.341647e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>7453.591519</td>\n",
              "      <td>8.508658</td>\n",
              "      <td>25.828605</td>\n",
              "      <td>19.981476</td>\n",
              "      <td>0.100120</td>\n",
              "      <td>9.617815</td>\n",
              "      <td>33.925816</td>\n",
              "      <td>134.917513</td>\n",
              "      <td>86.969527</td>\n",
              "      <td>15.072219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>102.190000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>5.630000</td>\n",
              "      <td>16.210000</td>\n",
              "      <td>6.061700e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>33.672500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>329.820000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>11.640000</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>3.677620e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>204.310000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>151.750000</td>\n",
              "      <td>861.460000</td>\n",
              "      <td>0.177500</td>\n",
              "      <td>21.142500</td>\n",
              "      <td>46.900000</td>\n",
              "      <td>1.663334e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>924.075000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>94.750000</td>\n",
              "      <td>59.750000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>423.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>2075.000000</td>\n",
              "      <td>17124.280000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>125.770000</td>\n",
              "      <td>293.680000</td>\n",
              "      <td>2.153691e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>119649.480000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>339.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>1261.000000</td>\n",
              "      <td>814.000000</td>\n",
              "      <td>162.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb5a35c-104b-4bbb-87b3-ade9ba4c4324')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebb5a35c-104b-4bbb-87b3-ade9ba4c4324 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebb5a35c-104b-4bbb-87b3-ade9ba4c4324');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              loc          vg         evg         ivg            n  \\\n",
              "count  498.000000  498.000000  498.000000  498.000000   498.000000   \n",
              "mean    29.644779    5.382329    2.490763    3.528916   143.956426   \n",
              "std     42.753572    8.347359    3.658847    5.464398   221.049888   \n",
              "min      1.000000    1.000000    1.000000    1.000000     1.000000   \n",
              "25%      8.000000    1.000000    1.000000    1.000000    25.000000   \n",
              "50%     17.000000    3.000000    1.000000    2.000000    67.500000   \n",
              "75%     31.000000    6.000000    1.000000    4.000000   151.750000   \n",
              "max    423.000000   96.000000   30.000000   63.000000  2075.000000   \n",
              "\n",
              "                  v           l           d           i             e  ...  \\\n",
              "count    498.000000  498.000000  498.000000  498.000000  4.980000e+02  ...   \n",
              "mean     900.175823    0.146325   15.829378   38.455361  3.488493e+04  ...   \n",
              "std     1690.814334    0.159337   15.330960   36.996297  1.341647e+05  ...   \n",
              "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
              "25%      102.190000    0.050000    5.630000   16.210000  6.061700e+02  ...   \n",
              "50%      329.820000    0.090000   11.640000   27.400000  3.677620e+03  ...   \n",
              "75%      861.460000    0.177500   21.142500   46.900000  1.663334e+04  ...   \n",
              "max    17124.280000    1.300000  125.770000  293.680000  2.153691e+06  ...   \n",
              "\n",
              "                   t      lOCode   lOComment     lOBlank  locCodeAndComment  \\\n",
              "count     498.000000  498.000000  498.000000  498.000000         498.000000   \n",
              "mean     1938.056124    3.787149   12.283133   11.534137           0.006024   \n",
              "std      7453.591519    8.508658   25.828605   19.981476           0.100120   \n",
              "min         0.000000    0.000000    0.000000    0.000000           0.000000   \n",
              "25%        33.672500    0.000000    0.000000    1.000000           0.000000   \n",
              "50%       204.310000    1.000000    4.000000    5.000000           0.000000   \n",
              "75%       924.075000    4.000000   14.000000   13.000000           0.000000   \n",
              "max    119649.480000   80.000000  339.000000  164.000000           2.000000   \n",
              "\n",
              "          uniq_Op   uniq_Opnd     total_Op  total_Opnd  branchCount  \n",
              "count  498.000000  498.000000   498.000000  498.000000   498.000000  \n",
              "mean    15.199197   25.452209    88.389960   55.570683     9.348193  \n",
              "std      9.617815   33.925816   134.917513   86.969527    15.072219  \n",
              "min      1.000000    0.000000     1.000000    0.000000     1.000000  \n",
              "25%      9.000000    7.000000    15.000000   10.000000     1.000000  \n",
              "50%     14.000000   15.000000    42.000000   26.000000     5.000000  \n",
              "75%     20.000000   30.000000    94.750000   59.750000    11.000000  \n",
              "max     72.000000  314.000000  1261.000000  814.000000   162.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_6.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1zriuustR3H",
        "outputId": "4c747550-3ba1-4422-f844-342140ebf377"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-902948ac-62d4-455f-b366-fa3bacf42977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>vg</th>\n",
              "      <th>evg</th>\n",
              "      <th>ivg</th>\n",
              "      <th>n</th>\n",
              "      <th>v</th>\n",
              "      <th>l</th>\n",
              "      <th>d</th>\n",
              "      <th>i</th>\n",
              "      <th>e</th>\n",
              "      <th>...</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>309.13</td>\n",
              "      <td>0.11</td>\n",
              "      <td>9.50</td>\n",
              "      <td>32.54</td>\n",
              "      <td>2936.77</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>215.49</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.00</td>\n",
              "      <td>13.47</td>\n",
              "      <td>3447.89</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>346.13</td>\n",
              "      <td>0.06</td>\n",
              "      <td>17.33</td>\n",
              "      <td>19.97</td>\n",
              "      <td>5999.58</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>47.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1563.78</td>\n",
              "      <td>0.04</td>\n",
              "      <td>28.00</td>\n",
              "      <td>55.85</td>\n",
              "      <td>43785.90</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>587.63</td>\n",
              "      <td>0.05</td>\n",
              "      <td>19.13</td>\n",
              "      <td>30.72</td>\n",
              "      <td>11241.58</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>82.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>3155.83</td>\n",
              "      <td>0.02</td>\n",
              "      <td>44.71</td>\n",
              "      <td>70.59</td>\n",
              "      <td>141084.24</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>59</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>150.41</td>\n",
              "      <td>0.15</td>\n",
              "      <td>6.50</td>\n",
              "      <td>23.14</td>\n",
              "      <td>977.69</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>28.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>564.33</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.09</td>\n",
              "      <td>35.08</td>\n",
              "      <td>9078.38</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-902948ac-62d4-455f-b366-fa3bacf42977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-902948ac-62d4-455f-b366-fa3bacf42977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-902948ac-62d4-455f-b366-fa3bacf42977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      loc    vg  evg   ivg      n        v     l      d      i          e  \\\n",
              "0     1.1   1.4  1.4   1.4    1.3     1.30  1.30   1.30   1.30       1.30   \n",
              "1     1.0   1.0  1.0   1.0    1.0     1.00  1.00   1.00   1.00       1.00   \n",
              "2    24.0   5.0  1.0   3.0   63.0   309.13  0.11   9.50  32.54    2936.77   \n",
              "3    20.0   4.0  4.0   2.0   47.0   215.49  0.06  16.00  13.47    3447.89   \n",
              "4    24.0   6.0  6.0   2.0   72.0   346.13  0.06  17.33  19.97    5999.58   \n",
              "..    ...   ...  ...   ...    ...      ...   ...    ...    ...        ...   \n",
              "493  47.0   3.0  1.0   3.0  256.0  1563.78  0.04  28.00  55.85   43785.90   \n",
              "494  24.0   4.0  3.0   3.0  107.0   587.63  0.05  19.13  30.72   11241.58   \n",
              "495  82.0  11.0  3.0  10.0  475.0  3155.83  0.02  44.71  70.59  141084.24   \n",
              "496  10.0   2.0  1.0   1.0   32.0   150.41  0.15   6.50  23.14     977.69   \n",
              "497  28.0   6.0  5.0   5.0  104.0   564.33  0.06  16.09  35.08    9078.38   \n",
              "\n",
              "     ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
              "0    ...       2          2        2                  2      1.2        1.2   \n",
              "1    ...       1          1        1                  1      1.0        1.0   \n",
              "2    ...       1          0        6                  0     15.0       15.0   \n",
              "3    ...       0          0        3                  0     16.0        8.0   \n",
              "4    ...       0          0        3                  0     16.0       12.0   \n",
              "..   ...     ...        ...      ...                ...      ...        ...   \n",
              "493  ...       2         13        2                  0     23.0       46.0   \n",
              "494  ...       1          7        4                  0     22.0       23.0   \n",
              "495  ...       9         59       35                  0     32.0       68.0   \n",
              "496  ...       1         12        4                  0     13.0       13.0   \n",
              "497  ...       2          7        0                  0     20.0       23.0   \n",
              "\n",
              "     total_Op  total_Opnd  branchCount  defects  \n",
              "0         1.2         1.2          1.4    False  \n",
              "1         1.0         1.0          1.0     True  \n",
              "2        44.0        19.0          9.0    False  \n",
              "3        31.0        16.0          7.0    False  \n",
              "4        46.0        26.0         11.0    False  \n",
              "..        ...         ...          ...      ...  \n",
              "493     144.0       112.0          5.0     True  \n",
              "494      67.0        40.0          7.0     True  \n",
              "495     285.0       190.0         21.0     True  \n",
              "496      19.0        13.0          3.0     True  \n",
              "497      67.0        37.0         11.0     True  \n",
              "\n",
              "[498 rows x 22 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8x4aXCJtR3H"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Gkl29ca5Ul",
        "outputId": "ffec757b-4217-4526-ba5e-6a9994ca86c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(498, 22)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miJ1TjUWtR3H",
        "outputId": "67dc27e4-7690-4582-9cbc-c9dac4b0f07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9151810237203495\n",
            "Test accuracy of best grid search hypers: 0.8\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.8995505617977528\n",
            "Test accuracy of best grid search hypers: 0.94\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9084893882646691\n",
            "Test accuracy of best grid search hypers: 0.88\n",
            "Best CV params {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9017727840199751\n",
            "Test accuracy of best grid search hypers: 0.92\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9040199750312109\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9040199750312109\n",
            "Test accuracy of best grid search hypers: 0.9\n",
            "Best CV params {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.904019975031211\n",
            "Test accuracy of best grid search hypers: 0.88\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9017977528089887\n",
            "Test accuracy of best grid search hypers: 0.94\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.8997752808988764\n",
            "Test accuracy of best grid search hypers: 0.9183673469387755\n",
            "Best CV params {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9019975031210986\n",
            "Test accuracy of best grid search hypers: 0.8979591836734694\n"
          ]
        }
      ],
      "source": [
        "x= Data_6.iloc[:, 0:21]\n",
        "y= Data_6.iloc[:,21]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvcYNsWkd9g7"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzDgRfnpd9g8",
        "outputId": "92ef18e0-70d0-4c53-e649-cdb3424f3363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardScaler()\n",
            "[8.92698413e+01 2.34126984e+01 1.32857143e+01 1.98412698e+00\n",
            " 5.25714286e+01 3.73015873e+01 1.22539683e+01 1.03222222e+02\n",
            " 1.37222222e+02 4.95555556e+01 2.40444444e+02 1.03706349e+03\n",
            " 1.27439619e-01 1.68972270e+01 3.48581681e+04 3.45688265e-01\n",
            " 1.93656490e+03 3.41269841e+01 1.70634921e+01 9.63492063e+00\n",
            " 1.66031746e+01 4.57142857e+00 1.31746032e+01 2.55955349e-01\n",
            " 7.52384127e-01 9.63492063e+00 2.01627760e+00 1.59493048e-01\n",
            " 2.06349206e-01 1.26984127e-01]\n",
            "[[ 1.88019575  3.39386239  1.1398037  ... -0.33450173 -0.40545886\n",
            "   2.62202212]\n",
            " [-0.74497805 -0.85821139 -0.49303137 ...  1.49202498 -0.40545886\n",
            "  -0.38138504]\n",
            " [ 1.54341358  1.78100682  0.32338617 ...  0.68076938 -0.40545886\n",
            "  -0.38138504]\n",
            " ...\n",
            " [ 0.50716077  0.64467676 -0.30748193 ... -0.32506054 -0.40545886\n",
            "  -0.38138504]\n",
            " [-0.68452997 -0.85821139 -0.49303137 ...  4.6391165  -0.40545886\n",
            "  -0.38138504]\n",
            " [ 2.10471719  2.5874346   1.47379269 ... -0.33793489 -0.40545886\n",
            "   2.62202212]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit(Data_2))\n",
        "StandardScaler()\n",
        "print(scaler.mean_)\n",
        "print(scaler.transform(Data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOQTs-G2d9g9",
        "outputId": "ce2b624f-af2a-4a52-bc33-9e418ec48a4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1036, 22)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_7.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdfTld2Pd9g-",
        "outputId": "88842c37-ddba-478d-a103-2ec96b7f0190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9334713357483755\n",
            "Test accuracy of best grid search hypers: 0.8846153846153846\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.930262779598643\n",
            "Test accuracy of best grid search hypers: 0.875\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9270427232476568\n",
            "Test accuracy of best grid search hypers: 0.9038461538461539\n",
            "Tuned Logistic Regression Parameter: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9281064918636076\n",
            "Test accuracy of best grid search hypers: 0.9423076923076923\n",
            "Tuned Logistic Regression Parameter: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9281007417629809\n",
            "Test accuracy of best grid search hypers: 0.9326923076923077\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9248979357138749\n",
            "Test accuracy of best grid search hypers: 0.9423076923076923\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9271059743545512\n",
            "Test accuracy of best grid search hypers: 0.9514563106796117\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9271002242539245\n",
            "Test accuracy of best grid search hypers: 0.9514563106796117\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9335288367546433\n",
            "Test accuracy of best grid search hypers: 0.912621359223301\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.924972687022023\n",
            "Test accuracy of best grid search hypers: 0.9320388349514563\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_7.iloc[:, 0:21]\n",
        "y= Data_7.iloc[:,21]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyd7I1eHjgGn"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1M6tPgmtSNo"
      },
      "source": [
        "## Data 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnLmhNbqtSNo"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7509ewBtSNp",
        "outputId": "4e2416ba-71b3-45ac-b6e4-f55b7807db30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1036, 22)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_7.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHZGPHmOtSNp",
        "outputId": "4702ea13-3f37-4476-fffe-bccfe7cd0897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "loc                  0\n",
              "vg                   0\n",
              "evg                  0\n",
              "ivg                  0\n",
              "N                    0\n",
              "V                    0\n",
              "L                    0\n",
              "D                    0\n",
              "I                    0\n",
              "E                    0\n",
              "B                    0\n",
              "T                    0\n",
              "lOCode               0\n",
              "lOComment            0\n",
              "locCodeAndComment    0\n",
              "lOBlank              0\n",
              "uniq_Op              0\n",
              "uniq_Opnd            0\n",
              "total_Op             0\n",
              "total_Opnd           0\n",
              "branchCount          0\n",
              "defects              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_7.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpuA6QHjtSNp",
        "outputId": "0823ff11-c0b8-4996-9402-1815c68e880c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "loc                  False\n",
              "vg                   False\n",
              "evg                  False\n",
              "ivg                  False\n",
              "N                    False\n",
              "V                    False\n",
              "L                    False\n",
              "D                    False\n",
              "I                    False\n",
              "E                    False\n",
              "B                    False\n",
              "T                    False\n",
              "lOCode               False\n",
              "lOComment            False\n",
              "locCodeAndComment    False\n",
              "lOBlank              False\n",
              "uniq_Op              False\n",
              "uniq_Opnd            False\n",
              "total_Op             False\n",
              "total_Opnd           False\n",
              "branchCount          False\n",
              "defects              False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_7.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y263KpRtSNq",
        "outputId": "a8229594-7bf9-42fb-c90d-b49c8930255c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1c76430-fa21-451b-b367-fa23fb5fa60a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>vg</th>\n",
              "      <th>evg</th>\n",
              "      <th>ivg</th>\n",
              "      <th>N</th>\n",
              "      <th>V</th>\n",
              "      <th>L</th>\n",
              "      <th>D</th>\n",
              "      <th>I</th>\n",
              "      <th>E</th>\n",
              "      <th>...</th>\n",
              "      <th>T</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1.036000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "      <td>1036.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.909363</td>\n",
              "      <td>5.494595</td>\n",
              "      <td>2.718533</td>\n",
              "      <td>3.354633</td>\n",
              "      <td>119.618050</td>\n",
              "      <td>715.777983</td>\n",
              "      <td>0.130849</td>\n",
              "      <td>15.168919</td>\n",
              "      <td>33.800965</td>\n",
              "      <td>2.949623e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>1638.681380</td>\n",
              "      <td>22.923745</td>\n",
              "      <td>5.005792</td>\n",
              "      <td>0.989382</td>\n",
              "      <td>7.116795</td>\n",
              "      <td>13.245367</td>\n",
              "      <td>21.385328</td>\n",
              "      <td>67.651737</td>\n",
              "      <td>51.968340</td>\n",
              "      <td>9.530309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36.186993</td>\n",
              "      <td>9.120213</td>\n",
              "      <td>5.673779</td>\n",
              "      <td>6.567323</td>\n",
              "      <td>201.713758</td>\n",
              "      <td>1546.990784</td>\n",
              "      <td>0.148560</td>\n",
              "      <td>16.179181</td>\n",
              "      <td>36.199712</td>\n",
              "      <td>1.756978e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>9760.989648</td>\n",
              "      <td>34.433819</td>\n",
              "      <td>10.812140</td>\n",
              "      <td>3.444085</td>\n",
              "      <td>12.638598</td>\n",
              "      <td>8.227964</td>\n",
              "      <td>29.696780</td>\n",
              "      <td>114.143551</td>\n",
              "      <td>88.257285</td>\n",
              "      <td>16.820778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>97.670000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>5.597500</td>\n",
              "      <td>14.407500</td>\n",
              "      <td>5.498875e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>30.550000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>284.790000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>25.080000</td>\n",
              "      <td>3.200990e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>177.835000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>129.250000</td>\n",
              "      <td>691.920000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>20.215000</td>\n",
              "      <td>42.835000</td>\n",
              "      <td>1.240243e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>689.020000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>602.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>2785.000000</td>\n",
              "      <td>25942.690000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>270.660000</td>\n",
              "      <td>598.330000</td>\n",
              "      <td>4.279633e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>237757.400000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>538.000000</td>\n",
              "      <td>1641.000000</td>\n",
              "      <td>1144.000000</td>\n",
              "      <td>236.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1c76430-fa21-451b-b367-fa23fb5fa60a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1c76430-fa21-451b-b367-fa23fb5fa60a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1c76430-fa21-451b-b367-fa23fb5fa60a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               loc           vg          evg          ivg            N  \\\n",
              "count  1036.000000  1036.000000  1036.000000  1036.000000  1036.000000   \n",
              "mean     23.909363     5.494595     2.718533     3.354633   119.618050   \n",
              "std      36.186993     9.120213     5.673779     6.567323   201.713758   \n",
              "min       0.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "25%       7.000000     1.000000     1.000000     1.000000    25.000000   \n",
              "50%      13.000000     3.000000     1.000000     2.000000    60.000000   \n",
              "75%      27.000000     6.000000     3.000000     3.000000   129.250000   \n",
              "max     602.000000   136.000000   123.000000   123.000000  2785.000000   \n",
              "\n",
              "                  V            L            D            I             E  ...  \\\n",
              "count   1036.000000  1036.000000  1036.000000  1036.000000  1.036000e+03  ...   \n",
              "mean     715.777983     0.130849    15.168919    33.800965  2.949623e+04  ...   \n",
              "std     1546.990784     0.148560    16.179181    36.199712  1.756978e+05  ...   \n",
              "min        0.000000     0.000000     0.000000     0.000000  0.000000e+00  ...   \n",
              "25%       97.670000     0.050000     5.597500    14.407500  5.498875e+02  ...   \n",
              "50%      284.790000     0.080000    11.500000    25.080000  3.200990e+03  ...   \n",
              "75%      691.920000     0.160000    20.215000    42.835000  1.240243e+04  ...   \n",
              "max    25942.690000     2.000000   270.660000   598.330000  4.279633e+06  ...   \n",
              "\n",
              "                   T       lOCode    lOComment  locCodeAndComment  \\\n",
              "count    1036.000000  1036.000000  1036.000000        1036.000000   \n",
              "mean     1638.681380    22.923745     5.005792           0.989382   \n",
              "std      9760.989648    34.433819    10.812140           3.444085   \n",
              "min         0.000000     0.000000     0.000000           0.000000   \n",
              "25%        30.550000     7.000000     0.000000           0.000000   \n",
              "50%       177.835000    13.000000     0.000000           0.000000   \n",
              "75%       689.020000    26.000000     6.000000           1.000000   \n",
              "max    237757.400000   600.000000   159.000000          48.000000   \n",
              "\n",
              "           lOBlank      uniq_Op    uniq_Opnd     total_Op   total_Opnd  \\\n",
              "count  1036.000000  1036.000000  1036.000000  1036.000000  1036.000000   \n",
              "mean      7.116795    13.245367    21.385328    67.651737    51.968340   \n",
              "std      12.638598     8.227964    29.696780   114.143551    88.257285   \n",
              "min       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
              "25%       1.000000     7.000000     6.000000    15.000000    10.000000   \n",
              "50%       3.000000    12.000000    12.500000    34.000000    25.000000   \n",
              "75%       9.000000    17.000000    26.000000    73.000000    56.000000   \n",
              "max     225.000000    99.000000   538.000000  1641.000000  1144.000000   \n",
              "\n",
              "       branchCount  \n",
              "count  1036.000000  \n",
              "mean      9.530309  \n",
              "std      16.820778  \n",
              "min       1.000000  \n",
              "25%       1.000000  \n",
              "50%       5.000000  \n",
              "75%      11.000000  \n",
              "max     236.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_7.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2w7AV2DtSNq",
        "outputId": "46b0f847-d51d-4a42-e681-1fd1be4d5cd4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80ad84b1-42a2-477e-b1b4-4cf5a165acf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>vg</th>\n",
              "      <th>evg</th>\n",
              "      <th>ivg</th>\n",
              "      <th>N</th>\n",
              "      <th>V</th>\n",
              "      <th>L</th>\n",
              "      <th>D</th>\n",
              "      <th>I</th>\n",
              "      <th>E</th>\n",
              "      <th>...</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>2089.21</td>\n",
              "      <td>0.04</td>\n",
              "      <td>27.68</td>\n",
              "      <td>75.47</td>\n",
              "      <td>57833.24</td>\n",
              "      <td>...</td>\n",
              "      <td>80</td>\n",
              "      <td>44</td>\n",
              "      <td>11</td>\n",
              "      <td>31</td>\n",
              "      <td>29.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>109.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>2547.56</td>\n",
              "      <td>0.04</td>\n",
              "      <td>28.37</td>\n",
              "      <td>89.79</td>\n",
              "      <td>72282.68</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>41</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>28.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>505.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2339.0</td>\n",
              "      <td>20696.93</td>\n",
              "      <td>0.01</td>\n",
              "      <td>75.93</td>\n",
              "      <td>272.58</td>\n",
              "      <td>1571506.88</td>\n",
              "      <td>...</td>\n",
              "      <td>457</td>\n",
              "      <td>71</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>64.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>1397.0</td>\n",
              "      <td>942.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1031</th>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>567.27</td>\n",
              "      <td>0.03</td>\n",
              "      <td>32.88</td>\n",
              "      <td>17.25</td>\n",
              "      <td>18654.39</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1032</th>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>267.57</td>\n",
              "      <td>0.04</td>\n",
              "      <td>24.00</td>\n",
              "      <td>11.15</td>\n",
              "      <td>6421.58</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>292.57</td>\n",
              "      <td>0.07</td>\n",
              "      <td>14.34</td>\n",
              "      <td>20.40</td>\n",
              "      <td>4196.62</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>171.67</td>\n",
              "      <td>0.05</td>\n",
              "      <td>20.40</td>\n",
              "      <td>8.42</td>\n",
              "      <td>3502.14</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>379.57</td>\n",
              "      <td>0.05</td>\n",
              "      <td>20.67</td>\n",
              "      <td>18.37</td>\n",
              "      <td>7844.38</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1036 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ad84b1-42a2-477e-b1b4-4cf5a165acf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80ad84b1-42a2-477e-b1b4-4cf5a165acf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80ad84b1-42a2-477e-b1b4-4cf5a165acf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        loc     vg   evg   ivg       N         V     L      D       I  \\\n",
              "0       1.1    1.4   1.4   1.4     1.3      1.30  1.30   1.30    1.30   \n",
              "1       1.0    1.0   1.0   1.0     1.0      1.00  1.00   1.00    1.00   \n",
              "2      91.0    9.0   3.0   2.0   318.0   2089.21  0.04  27.68   75.47   \n",
              "3     109.0   21.0   5.0  18.0   381.0   2547.56  0.04  28.37   89.79   \n",
              "4     505.0  106.0  41.0  82.0  2339.0  20696.93  0.01  75.93  272.58   \n",
              "...     ...    ...   ...   ...     ...       ...   ...    ...     ...   \n",
              "1031   12.0   10.0   1.0   9.0   118.0    567.27  0.03  32.88   17.25   \n",
              "1032   11.0    8.0   7.0   1.0    60.0    267.57  0.04  24.00   11.15   \n",
              "1033   21.0    5.0   1.0   4.0    58.0    292.57  0.07  14.34   20.40   \n",
              "1034   11.0    5.0   5.0   1.0    42.0    171.67  0.05  20.40    8.42   \n",
              "1035   17.0    8.0   3.0   2.0    74.0    379.57  0.05  20.67   18.37   \n",
              "\n",
              "               E  ...  lOCode  lOComment  locCodeAndComment  lOBlank  uniq_Op  \\\n",
              "0           1.30  ...       2          2                  2        2      1.2   \n",
              "1           1.00  ...       1          1                  1        1      1.0   \n",
              "2       57833.24  ...      80         44                 11       31     29.0   \n",
              "3       72282.68  ...      97         41                 12       24     28.0   \n",
              "4     1571506.88  ...     457         71                 48       49     64.0   \n",
              "...          ...  ...     ...        ...                ...      ...      ...   \n",
              "1031    18654.39  ...      12          0                  0        4     15.0   \n",
              "1032     6421.58  ...      11          0                  0        2     16.0   \n",
              "1033     4196.62  ...      20         24                  1        6     17.0   \n",
              "1034     3502.14  ...      11          0                  0        1     12.0   \n",
              "1035     7844.38  ...      17          3                  0        3     20.0   \n",
              "\n",
              "      uniq_Opnd  total_Op  total_Opnd  branchCount  defects  \n",
              "0           1.2       1.2         1.2          1.4    False  \n",
              "1           1.0       1.0         1.0          1.0     True  \n",
              "2          66.0     192.0       126.0         17.0     True  \n",
              "3          75.0     229.0       152.0         38.0     True  \n",
              "4         397.0    1397.0       942.0        178.0     True  \n",
              "...         ...       ...         ...          ...      ...  \n",
              "1031       13.0      61.0        57.0         19.0    False  \n",
              "1032        6.0      42.0        18.0         15.0    False  \n",
              "1033       16.0      31.0        27.0          9.0    False  \n",
              "1034        5.0      25.0        17.0          9.0    False  \n",
              "1035       15.0      43.0        31.0         13.0    False  \n",
              "\n",
              "[1036 rows x 22 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4eC6ZKiuJq6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuEouHmrtSNq"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9OhH-ZZbHOh",
        "outputId": "055c0508-838c-4488-a89e-db5487a91aef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1036, 22)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_7.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQpZi1YotSNr",
        "outputId": "f4e3bdcc-5602-4d80-889c-134bae7ef5e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.930262779598643\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 10, 'gamma': 100, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9399286987522281\n",
            "Test accuracy of best grid search hypers: 0.8846153846153846\n",
            "Best CV params {'C': 10, 'gamma': 100, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9345638548674602\n",
            "Test accuracy of best grid search hypers: 0.8846153846153846\n",
            "Best CV params {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9302685296992698\n",
            "Test accuracy of best grid search hypers: 0.9326923076923077\n",
            "Best CV params {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n",
            "Best CV accuracy 0.9281064918636076\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 10, 'gamma': 100, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9334828359496292\n",
            "Test accuracy of best grid search hypers: 0.9134615384615384\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9314127997239952\n",
            "Test accuracy of best grid search hypers: 0.9029126213592233\n",
            "Best CV params {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9293025127939739\n",
            "Test accuracy of best grid search hypers: 0.941747572815534\n",
            "Best CV params {'C': 10, 'gamma': 100, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9282272439767695\n",
            "Test accuracy of best grid search hypers: 0.970873786407767\n",
            "Best CV params {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.927157725260192\n",
            "Test accuracy of best grid search hypers: 0.9514563106796117\n"
          ]
        }
      ],
      "source": [
        "x= Data_7.iloc[:, 0:21]\n",
        "y= Data_7.iloc[:,21]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU4R9gOTm8hC"
      },
      "source": [
        "46 min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgMKSkvgvAtK"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FES4BMNUvEn2",
        "outputId": "5a1302be-f6e3-4fb9-fd6a-1c33bc3b3a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9302570294980163\n",
            "Test accuracy of best grid search hypers: 0.9326923076923077\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9334655856477487\n",
            "Test accuracy of best grid search hypers: 0.9134615384615384\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9248921856132482\n",
            "Test accuracy of best grid search hypers: 0.9326923076923077\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9302512793973895\n",
            "Test accuracy of best grid search hypers: 0.9134615384615384\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9291875107814386\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9291817606808118\n",
            "Test accuracy of best grid search hypers: 0.9326923076923077\n",
            "Tuned Logistic Regression Parameter: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9324765683399459\n",
            "Test accuracy of best grid search hypers: 0.912621359223301\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9313955494221148\n",
            "Test accuracy of best grid search hypers: 0.912621359223301\n",
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9249669369213962\n",
            "Test accuracy of best grid search hypers: 0.9514563106796117\n",
            "Tuned Logistic Regression Parameter: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Tuned Logistic Regression Accuracy: 0.9303260307055373\n",
            "Test accuracy of best grid search hypers: 0.9223300970873787\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_7.iloc[:, 0:21]\n",
        "y= Data_7.iloc[:,21]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llVtORRKjdHo"
      },
      "outputs": [],
      "source": [
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVxYq4gVtSk-"
      },
      "source": [
        "## Data 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHlKIlU8tSk-"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrHH5dbztSk_",
        "outputId": "b924756f-8915-45ee-cee3-31d911bd3672"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(920, 37)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB0maznotSk_",
        "outputId": "4576a049-5572-468b-c99a-a999cbe2c4c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BRANCH_COUNT                       0\n",
              "CALL_PAIRS                         0\n",
              "LOC_CODE_AND_COMMENT               0\n",
              "LOC_COMMENTS                       0\n",
              "CONDITION_COUNT                    0\n",
              "CYCLOMATIC_COMPLEXITY              0\n",
              "CYCLOMATIC_DENSITY                 0\n",
              "DECISION_COUNT                     0\n",
              "DECISION_DENSITY                   0\n",
              "DESIGN_COMPLEXITY                  0\n",
              "DESIGN_DENSITY                     0\n",
              "EDGE_COUNT                         0\n",
              "ESSENTIAL_COMPLEXITY               0\n",
              "ESSENTIAL_DENSITY                  0\n",
              "LOC_EXECUTABLE                     0\n",
              "PARAMETER_COUNT                    0\n",
              "HALSTEAD_CONTENT                   0\n",
              "HALSTEAD_DIFFICULTY                0\n",
              "HALSTEAD_EFFORT                    0\n",
              "HALSTEAD_ERROR_EST                 0\n",
              "HALSTEAD_LENGTH                    0\n",
              "HALSTEAD_LEVEL                     0\n",
              "HALSTEAD_PROG_TIME                 0\n",
              "HALSTEAD_VOLUME                    0\n",
              "MAINTENANCE_SEVERITY               0\n",
              "MODIFIED_CONDITION_COUNT           0\n",
              "MULTIPLE_CONDITION_COUNT           0\n",
              "NODE_COUNT                         0\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    0\n",
              "NUM_OPERANDS                       0\n",
              "NUM_OPERATORS                      0\n",
              "NUM_UNIQUE_OPERANDS                0\n",
              "NUM_UNIQUE_OPERATORS               0\n",
              "NUMBER_OF_LINES                    0\n",
              "PERCENT_COMMENTS                   0\n",
              "LOC_TOTAL                          0\n",
              "defects                            0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_8.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJ4FqEHtSlB",
        "outputId": "c00f5e1e-104c-4f3a-d0bd-0b431cbc5ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BRANCH_COUNT                       False\n",
              "CALL_PAIRS                         False\n",
              "LOC_CODE_AND_COMMENT               False\n",
              "LOC_COMMENTS                       False\n",
              "CONDITION_COUNT                    False\n",
              "CYCLOMATIC_COMPLEXITY              False\n",
              "CYCLOMATIC_DENSITY                 False\n",
              "DECISION_COUNT                     False\n",
              "DECISION_DENSITY                   False\n",
              "DESIGN_COMPLEXITY                  False\n",
              "DESIGN_DENSITY                     False\n",
              "EDGE_COUNT                         False\n",
              "ESSENTIAL_COMPLEXITY               False\n",
              "ESSENTIAL_DENSITY                  False\n",
              "LOC_EXECUTABLE                     False\n",
              "PARAMETER_COUNT                    False\n",
              "HALSTEAD_CONTENT                   False\n",
              "HALSTEAD_DIFFICULTY                False\n",
              "HALSTEAD_EFFORT                    False\n",
              "HALSTEAD_ERROR_EST                 False\n",
              "HALSTEAD_LENGTH                    False\n",
              "HALSTEAD_LEVEL                     False\n",
              "HALSTEAD_PROG_TIME                 False\n",
              "HALSTEAD_VOLUME                    False\n",
              "MAINTENANCE_SEVERITY               False\n",
              "MODIFIED_CONDITION_COUNT           False\n",
              "MULTIPLE_CONDITION_COUNT           False\n",
              "NODE_COUNT                         False\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    False\n",
              "NUM_OPERANDS                       False\n",
              "NUM_OPERATORS                      False\n",
              "NUM_UNIQUE_OPERANDS                False\n",
              "NUM_UNIQUE_OPERATORS               False\n",
              "NUMBER_OF_LINES                    False\n",
              "PERCENT_COMMENTS                   False\n",
              "LOC_TOTAL                          False\n",
              "defects                            False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_8.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg98uVogtSlC",
        "outputId": "5a541813-f111-4c9c-b652-c83b49f57b79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8b9401e-e27b-4dfc-9040-2aa3074fd537\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>DESIGN_COMPLEXITY</th>\n",
              "      <th>...</th>\n",
              "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>920.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.332609</td>\n",
              "      <td>1.223913</td>\n",
              "      <td>3.554348</td>\n",
              "      <td>1.065217</td>\n",
              "      <td>2.365217</td>\n",
              "      <td>1.723913</td>\n",
              "      <td>0.588804</td>\n",
              "      <td>1.108696</td>\n",
              "      <td>0.622837</td>\n",
              "      <td>1.48913</td>\n",
              "      <td>...</td>\n",
              "      <td>1.183696</td>\n",
              "      <td>5.560870</td>\n",
              "      <td>0.391793</td>\n",
              "      <td>8.461957</td>\n",
              "      <td>13.307609</td>\n",
              "      <td>4.242391</td>\n",
              "      <td>6.048913</td>\n",
              "      <td>7.729348</td>\n",
              "      <td>48.172033</td>\n",
              "      <td>4.656522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.243438</td>\n",
              "      <td>1.783089</td>\n",
              "      <td>12.069498</td>\n",
              "      <td>5.374555</td>\n",
              "      <td>5.396699</td>\n",
              "      <td>3.168444</td>\n",
              "      <td>0.290467</td>\n",
              "      <td>2.459051</td>\n",
              "      <td>0.996756</td>\n",
              "      <td>2.76026</td>\n",
              "      <td>...</td>\n",
              "      <td>2.702104</td>\n",
              "      <td>8.433997</td>\n",
              "      <td>0.332130</td>\n",
              "      <td>23.897693</td>\n",
              "      <td>36.165469</td>\n",
              "      <td>6.988172</td>\n",
              "      <td>4.976200</td>\n",
              "      <td>16.108703</td>\n",
              "      <td>30.980561</td>\n",
              "      <td>12.763841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.395000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>89.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>77.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>748.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>318.000000</td>\n",
              "      <td>98.620000</td>\n",
              "      <td>294.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b9401e-e27b-4dfc-9040-2aa3074fd537')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8b9401e-e27b-4dfc-9040-2aa3074fd537 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8b9401e-e27b-4dfc-9040-2aa3074fd537');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
              "count    920.000000  920.000000            920.000000    920.000000   \n",
              "mean       2.332609    1.223913              3.554348      1.065217   \n",
              "std        4.243438    1.783089             12.069498      5.374555   \n",
              "min        1.000000    0.000000              0.000000      0.000000   \n",
              "25%        1.000000    0.000000              0.000000      0.000000   \n",
              "50%        1.000000    1.000000              1.000000      0.000000   \n",
              "75%        3.000000    2.000000              2.000000      0.000000   \n",
              "max       89.000000   17.000000            285.000000     91.000000   \n",
              "\n",
              "       CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  \\\n",
              "count       920.000000             920.000000          920.000000   \n",
              "mean          2.365217               1.723913            0.588804   \n",
              "std           5.396699               3.168444            0.290467   \n",
              "min           0.000000               1.000000            0.010000   \n",
              "25%           0.000000               1.000000            0.395000   \n",
              "50%           0.000000               1.000000            0.500000   \n",
              "75%           4.000000               2.000000            1.000000   \n",
              "max          86.000000              84.000000            2.000000   \n",
              "\n",
              "       DECISION_COUNT  DECISION_DENSITY  DESIGN_COMPLEXITY  ...  \\\n",
              "count      920.000000        920.000000          920.00000  ...   \n",
              "mean         1.108696          0.622837            1.48913  ...   \n",
              "std          2.459051          0.996756            2.76026  ...   \n",
              "min          0.000000          0.000000            1.00000  ...   \n",
              "25%          0.000000          0.000000            1.00000  ...   \n",
              "50%          0.000000          0.000000            1.00000  ...   \n",
              "75%          2.000000          2.000000            1.00000  ...   \n",
              "max         34.000000          4.000000           77.00000  ...   \n",
              "\n",
              "       MULTIPLE_CONDITION_COUNT  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
              "count                920.000000  920.000000                       920.000000   \n",
              "mean                   1.183696    5.560870                         0.391793   \n",
              "std                    2.702104    8.433997                         0.332130   \n",
              "min                    0.000000    2.000000                         0.010000   \n",
              "25%                    0.000000    2.000000                         0.200000   \n",
              "50%                    0.000000    3.000000                         0.250000   \n",
              "75%                    2.000000    6.000000                         0.400000   \n",
              "max                   43.000000  112.000000                         3.000000   \n",
              "\n",
              "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
              "count    920.000000     920.000000           920.000000            920.000000   \n",
              "mean       8.461957      13.307609             4.242391              6.048913   \n",
              "std       23.897693      36.165469             6.988172              4.976200   \n",
              "min        0.000000       0.000000             0.000000              0.000000   \n",
              "25%        1.000000       3.000000             1.000000              3.000000   \n",
              "50%        3.000000       6.000000             2.000000              5.000000   \n",
              "75%        6.000000      10.000000             5.000000              8.000000   \n",
              "max      380.000000     748.000000           129.000000             88.000000   \n",
              "\n",
              "       NUMBER_OF_LINES  PERCENT_COMMENTS   LOC_TOTAL  \n",
              "count       920.000000        920.000000  920.000000  \n",
              "mean          7.729348         48.172033    4.656522  \n",
              "std          16.108703         30.980561   12.763841  \n",
              "min           1.000000          0.000000    0.000000  \n",
              "25%           3.000000          0.000000    1.000000  \n",
              "50%           4.000000         50.000000    2.000000  \n",
              "75%           7.000000         75.000000    4.000000  \n",
              "max         318.000000         98.620000  294.000000  \n",
              "\n",
              "[8 rows x 36 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_8.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kIdyEZqtSlD",
        "outputId": "99715525-4242-4c44-dd2e-2abdce523a87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be1fd0e4-7b03-415b-98cc-ae4ce9bf11f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>DESIGN_COMPLEXITY</th>\n",
              "      <th>...</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.03</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>96.88</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.06</td>\n",
              "      <td>29</td>\n",
              "      <td>48</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>93.33</td>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.33</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.29</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>75.00</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>50.00</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>50.00</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>920 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be1fd0e4-7b03-415b-98cc-ae4ce9bf11f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be1fd0e4-7b03-415b-98cc-ae4ce9bf11f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be1fd0e4-7b03-415b-98cc-ae4ce9bf11f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
              "0               1           0                     0             0   \n",
              "1               1           1                     0             0   \n",
              "2               1           4                     7            24   \n",
              "3               1           1                    11             3   \n",
              "4               1           1                     0             0   \n",
              "..            ...         ...                   ...           ...   \n",
              "915             1           0                     0             0   \n",
              "916             3           3                     3             0   \n",
              "917             1           0                     1             0   \n",
              "918             1           0                     0             0   \n",
              "919             1           1                     1             0   \n",
              "\n",
              "     CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  \\\n",
              "0                  0                      1                1.00   \n",
              "1                  0                      1                1.00   \n",
              "2                  0                      1                0.13   \n",
              "3                  0                      1                0.08   \n",
              "4                  0                      1                1.00   \n",
              "..               ...                    ...                 ...   \n",
              "915                0                      1                1.00   \n",
              "916                4                      2                0.50   \n",
              "917                4                      1                0.50   \n",
              "918                0                      1                1.00   \n",
              "919                0                      1                0.50   \n",
              "\n",
              "     DECISION_COUNT  DECISION_DENSITY  DESIGN_COMPLEXITY  ...  NODE_COUNT  \\\n",
              "0                 0               0.0                  1  ...           2   \n",
              "1                 0               0.0                  1  ...           3   \n",
              "2                 0               0.0                  1  ...           7   \n",
              "3                 0               0.0                  1  ...           3   \n",
              "4                 0               0.0                  1  ...           3   \n",
              "..              ...               ...                ...  ...         ...   \n",
              "915               0               0.0                  1  ...           2   \n",
              "916               2               2.0                  2  ...           7   \n",
              "917               2               2.0                  1  ...           2   \n",
              "918               0               0.0                  1  ...           2   \n",
              "919               0               0.0                  1  ...           3   \n",
              "\n",
              "     NORMALIZED_CYLOMATIC_COMPLEXITY  NUM_OPERANDS  NUM_OPERATORS  \\\n",
              "0                               0.50             1              3   \n",
              "1                               1.00             1              0   \n",
              "2                               0.03            13             21   \n",
              "3                               0.06            29             48   \n",
              "4                               0.33             5              4   \n",
              "..                               ...           ...            ...   \n",
              "915                             1.00             2              5   \n",
              "916                             0.29            11             14   \n",
              "917                             0.25             2              6   \n",
              "918                             1.00             2              4   \n",
              "919                             0.20             3              6   \n",
              "\n",
              "     NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  NUMBER_OF_LINES  \\\n",
              "0                      1                     3                2   \n",
              "1                      1                     0                1   \n",
              "2                      7                     8               34   \n",
              "3                     13                     7               17   \n",
              "4                      4                     1                3   \n",
              "..                   ...                   ...              ...   \n",
              "915                    2                     4                1   \n",
              "916                    7                     9                7   \n",
              "917                    2                     6                4   \n",
              "918                    2                     4                1   \n",
              "919                    3                     6                5   \n",
              "\n",
              "     PERCENT_COMMENTS  LOC_TOTAL  defects  \n",
              "0                0.00          0    False  \n",
              "1                0.00          0    False  \n",
              "2               96.88          8    False  \n",
              "3               93.33         12    False  \n",
              "4                0.00          1    False  \n",
              "..                ...        ...      ...  \n",
              "915              0.00          0    False  \n",
              "916             75.00          4    False  \n",
              "917             50.00          2    False  \n",
              "918              0.00          0    False  \n",
              "919             50.00          2    False  \n",
              "\n",
              "[920 rows x 37 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIi-S_sktSlD"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RzKIUqtbU3G",
        "outputId": "7d9e0d4f-f11d-47fd-e0c4-d8d37ff840e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(920, 37)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYCQjGUztSlD",
        "outputId": "8b2ed5c8-6a1a-433c-980b-6f94c515dc78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9975903614457831\n",
            "Test accuracy of best grid search hypers: 0.9782608695652174\n",
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 0.9891304347826086\n",
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.9975903614457831\n",
            "Test accuracy of best grid search hypers: 0.9891304347826086\n",
            "Best CV params {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9963855421686748\n",
            "Test accuracy of best grid search hypers: 0.9891304347826086\n",
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
            "Best CV accuracy 0.996378240233662\n",
            "Test accuracy of best grid search hypers: 1.0\n"
          ]
        }
      ],
      "source": [
        "x= Data_8.iloc[:, 0:36]\n",
        "y= Data_8.iloc[:,36]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk8u5Ux0tS0v"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9DDez5uwj1R"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T8ApoUrwl0J",
        "outputId": "f2652d97-ce84-4074-c44c-c5311fd59d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8405768528660096\n",
            "Test accuracy of best grid search hypers: 0.8695652173913043\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.829689667761957\n",
            "Test accuracy of best grid search hypers: 0.8586956521739131\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8442424242424241\n",
            "Test accuracy of best grid search hypers: 0.8695652173913043\n",
            "Tuned Logistic Regression Parameter: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8357721796276014\n",
            "Test accuracy of best grid search hypers: 0.8586956521739131\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8393793355239139\n",
            "Test accuracy of best grid search hypers: 0.8369565217391305\n",
            "Tuned Logistic Regression Parameter: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8442497261774371\n",
            "Test accuracy of best grid search hypers: 0.8043478260869565\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8393866374589267\n",
            "Test accuracy of best grid search hypers: 0.8478260869565217\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8538444687842279\n",
            "Test accuracy of best grid search hypers: 0.7934782608695652\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8454472435195326\n",
            "Test accuracy of best grid search hypers: 0.8695652173913043\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.8526688572471706\n",
            "Test accuracy of best grid search hypers: 0.8043478260869565\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_8.iloc[:, 0:35]\n",
        "y= Data_8.iloc[:,35]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz3BQz4exuDr"
      },
      "source": [
        "1:26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6guuR4OjGJu",
        "outputId": "90733690-3b27-4924-f15e-3279305867da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM is: 80.43478260869566\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'sag', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.97      1.00      0.98        30\n",
            "           3       1.00      0.83      0.91        12\n",
            "           4       1.00      0.75      0.86         4\n",
            "           5       0.67      1.00      0.80         2\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.25      1.00      0.40         1\n",
            "           9       1.00      0.20      0.33         5\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.50      1.00      0.67         1\n",
            "          12       0.50      0.25      0.33         4\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       1.00      0.50      0.67         2\n",
            "          27       0.00      0.00      0.00         1\n",
            "          42       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.80        92\n",
            "   macro avg       0.42      0.41      0.38        92\n",
            "weighted avg       0.87      0.80      0.81        92\n",
            "\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 10  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  1  1  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  1  0  0  0  0  1  0  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "# Using the model to predict the labels of the test data\n",
        "y_pred = logreg_cv.predict(X_test)\n",
        "\n",
        "# Evaluating the accuracy of the model using the sklearn functions\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dOMgdOctS7D"
      },
      "source": [
        "## Data 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMFy8d37tS7E"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ODLhOVtS7E",
        "outputId": "8b2e09ae-ff7c-4220-f91b-7909ece10d14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(753, 38)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_9.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxHPb9ZZtS7E",
        "outputId": "af4414da-b470-4785-e556-e0d5d22bdba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LOC_BLANK                          0\n",
              "BRANCH_COUNT                       0\n",
              "CALL_PAIRS                         0\n",
              "LOC_CODE_AND_COMMENT               0\n",
              "LOC_COMMENTS                       0\n",
              "CONDITION_COUNT                    0\n",
              "CYCLOMATIC_COMPLEXITY              0\n",
              "CYCLOMATIC_DENSITY                 0\n",
              "DECISION_COUNT                     0\n",
              "DECISION_DENSITY                   0\n",
              "DESIGN_COMPLEXITY                  0\n",
              "DESIGN_DENSITY                     0\n",
              "EDGE_COUNT                         0\n",
              "ESSENTIAL_COMPLEXITY               0\n",
              "ESSENTIAL_DENSITY                  0\n",
              "LOC_EXECUTABLE                     0\n",
              "PARAMETER_COUNT                    0\n",
              "HALSTEAD_CONTENT                   0\n",
              "HALSTEAD_DIFFICULTY                0\n",
              "HALSTEAD_EFFORT                    0\n",
              "HALSTEAD_ERROR_EST                 0\n",
              "HALSTEAD_LENGTH                    0\n",
              "HALSTEAD_LEVEL                     0\n",
              "HALSTEAD_PROG_TIME                 0\n",
              "HALSTEAD_VOLUME                    0\n",
              "MAINTENANCE_SEVERITY               0\n",
              "MODIFIED_CONDITION_COUNT           0\n",
              "MULTIPLE_CONDITION_COUNT           0\n",
              "NODE_COUNT                         0\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    0\n",
              "NUM_OPERANDS                       0\n",
              "NUM_OPERATORS                      0\n",
              "NUM_UNIQUE_OPERANDS                0\n",
              "NUM_UNIQUE_OPERATORS               0\n",
              "NUMBER_OF_LINES                    0\n",
              "PERCENT_COMMENTS                   0\n",
              "LOC_TOTAL                          0\n",
              "defects                            0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_9.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG9UqhXutS7F",
        "outputId": "1e2d727b-b5a4-495a-d623-793e237401be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LOC_BLANK                          False\n",
              "BRANCH_COUNT                       False\n",
              "CALL_PAIRS                         False\n",
              "LOC_CODE_AND_COMMENT               False\n",
              "LOC_COMMENTS                       False\n",
              "CONDITION_COUNT                    False\n",
              "CYCLOMATIC_COMPLEXITY              False\n",
              "CYCLOMATIC_DENSITY                 False\n",
              "DECISION_COUNT                     False\n",
              "DECISION_DENSITY                   False\n",
              "DESIGN_COMPLEXITY                  False\n",
              "DESIGN_DENSITY                     False\n",
              "EDGE_COUNT                         False\n",
              "ESSENTIAL_COMPLEXITY               False\n",
              "ESSENTIAL_DENSITY                  False\n",
              "LOC_EXECUTABLE                     False\n",
              "PARAMETER_COUNT                    False\n",
              "HALSTEAD_CONTENT                   False\n",
              "HALSTEAD_DIFFICULTY                False\n",
              "HALSTEAD_EFFORT                    False\n",
              "HALSTEAD_ERROR_EST                 False\n",
              "HALSTEAD_LENGTH                    False\n",
              "HALSTEAD_LEVEL                     False\n",
              "HALSTEAD_PROG_TIME                 False\n",
              "HALSTEAD_VOLUME                    False\n",
              "MAINTENANCE_SEVERITY               False\n",
              "MODIFIED_CONDITION_COUNT           False\n",
              "MULTIPLE_CONDITION_COUNT           False\n",
              "NODE_COUNT                         False\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    False\n",
              "NUM_OPERANDS                       False\n",
              "NUM_OPERATORS                      False\n",
              "NUM_UNIQUE_OPERANDS                False\n",
              "NUM_UNIQUE_OPERATORS               False\n",
              "NUMBER_OF_LINES                    False\n",
              "PERCENT_COMMENTS                   False\n",
              "LOC_TOTAL                          False\n",
              "defects                            False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_9.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvzPD-CHtS7F",
        "outputId": "3b68d3f0-4898-4aa7-f681-3bdb3b64d8ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e1dd7ac-3953-44e7-a31e-cea26c9d0983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC_BLANK</th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>...</th>\n",
              "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "      <td>753.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.823373</td>\n",
              "      <td>9.495352</td>\n",
              "      <td>2.379814</td>\n",
              "      <td>1.466135</td>\n",
              "      <td>4.523240</td>\n",
              "      <td>14.767596</td>\n",
              "      <td>5.420983</td>\n",
              "      <td>0.291859</td>\n",
              "      <td>6.828685</td>\n",
              "      <td>1.531487</td>\n",
              "      <td>...</td>\n",
              "      <td>7.491368</td>\n",
              "      <td>17.442231</td>\n",
              "      <td>0.216760</td>\n",
              "      <td>55.416999</td>\n",
              "      <td>67.264276</td>\n",
              "      <td>22.073041</td>\n",
              "      <td>12.726428</td>\n",
              "      <td>36.176627</td>\n",
              "      <td>14.443572</td>\n",
              "      <td>23.326693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.458441</td>\n",
              "      <td>16.155833</td>\n",
              "      <td>2.977614</td>\n",
              "      <td>3.206415</td>\n",
              "      <td>9.183114</td>\n",
              "      <td>28.545045</td>\n",
              "      <td>8.355909</td>\n",
              "      <td>0.200183</td>\n",
              "      <td>13.109751</td>\n",
              "      <td>1.036072</td>\n",
              "      <td>...</td>\n",
              "      <td>14.545974</td>\n",
              "      <td>27.689332</td>\n",
              "      <td>0.221254</td>\n",
              "      <td>110.074836</td>\n",
              "      <td>117.746383</td>\n",
              "      <td>31.632384</td>\n",
              "      <td>7.049751</td>\n",
              "      <td>48.580043</td>\n",
              "      <td>19.299858</td>\n",
              "      <td>37.585180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>388.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>391.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1792.000000</td>\n",
              "      <td>1888.000000</td>\n",
              "      <td>459.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>678.000000</td>\n",
              "      <td>93.940000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e1dd7ac-3953-44e7-a31e-cea26c9d0983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e1dd7ac-3953-44e7-a31e-cea26c9d0983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e1dd7ac-3953-44e7-a31e-cea26c9d0983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  \\\n",
              "count  753.000000    753.000000  753.000000            753.000000   \n",
              "mean     6.823373      9.495352    2.379814              1.466135   \n",
              "std      9.458441     16.155833    2.977614              3.206415   \n",
              "min      0.000000      1.000000    0.000000              0.000000   \n",
              "25%      1.000000      1.000000    0.000000              0.000000   \n",
              "50%      3.000000      5.000000    1.000000              0.000000   \n",
              "75%      9.000000     11.000000    3.000000              2.000000   \n",
              "max     71.000000    235.000000   24.000000             31.000000   \n",
              "\n",
              "       LOC_COMMENTS  CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  \\\n",
              "count    753.000000       753.000000             753.000000   \n",
              "mean       4.523240        14.767596               5.420983   \n",
              "std        9.183114        28.545045               8.355909   \n",
              "min        0.000000         0.000000               1.000000   \n",
              "25%        0.000000         0.000000               1.000000   \n",
              "50%        0.000000         8.000000               3.000000   \n",
              "75%        5.000000        16.000000               6.000000   \n",
              "max       78.000000       388.000000             118.000000   \n",
              "\n",
              "       CYCLOMATIC_DENSITY  DECISION_COUNT  DECISION_DENSITY  ...  \\\n",
              "count          753.000000      753.000000        753.000000  ...   \n",
              "mean             0.291859        6.828685          1.531487  ...   \n",
              "std              0.200183       13.109751          1.036072  ...   \n",
              "min              0.010000        0.000000          0.000000  ...   \n",
              "25%              0.170000        0.000000          0.000000  ...   \n",
              "50%              0.250000        4.000000          2.000000  ...   \n",
              "75%              0.330000        8.000000          2.000000  ...   \n",
              "max              1.000000      154.000000          5.000000  ...   \n",
              "\n",
              "       MULTIPLE_CONDITION_COUNT  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
              "count                753.000000  753.000000                       753.000000   \n",
              "mean                   7.491368   17.442231                         0.216760   \n",
              "std                   14.545974   27.689332                         0.221254   \n",
              "min                    0.000000    2.000000                         0.010000   \n",
              "25%                    0.000000    5.000000                         0.100000   \n",
              "50%                    4.000000   10.000000                         0.150000   \n",
              "75%                    8.000000   19.000000                         0.250000   \n",
              "max                  194.000000  391.000000                         2.000000   \n",
              "\n",
              "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
              "count    753.000000     753.000000           753.000000            753.000000   \n",
              "mean      55.416999      67.264276            22.073041             12.726428   \n",
              "std      110.074836     117.746383            31.632384              7.049751   \n",
              "min        0.000000       1.000000             0.000000              1.000000   \n",
              "25%       11.000000      16.000000             7.000000              8.000000   \n",
              "50%       25.000000      32.000000            13.000000             12.000000   \n",
              "75%       62.000000      77.000000            28.000000             16.000000   \n",
              "max     1792.000000    1888.000000           459.000000             50.000000   \n",
              "\n",
              "       NUMBER_OF_LINES  PERCENT_COMMENTS   LOC_TOTAL  \n",
              "count       753.000000        753.000000  753.000000  \n",
              "mean         36.176627         14.443572   23.326693  \n",
              "std          48.580043         19.299858   37.585180  \n",
              "min           1.000000          0.000000    0.000000  \n",
              "25%           9.000000          0.000000    7.000000  \n",
              "50%          20.000000          3.130000   13.000000  \n",
              "75%          45.000000         25.000000   27.000000  \n",
              "max         678.000000         93.940000  627.000000  \n",
              "\n",
              "[8 rows x 37 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_9.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wISi6Xq3tS7G",
        "outputId": "3d3e4d70-1908-440e-dfaf-545046c6c6e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a98977b1-f1dc-42d0-bdb7-74828dbf0ce1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC_BLANK</th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>...</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.06</td>\n",
              "      <td>52</td>\n",
              "      <td>55</td>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>0.26</td>\n",
              "      <td>12</td>\n",
              "      <td>2.17</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.13</td>\n",
              "      <td>58</td>\n",
              "      <td>78</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>83</td>\n",
              "      <td>30.91</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>0.47</td>\n",
              "      <td>8</td>\n",
              "      <td>3.00</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.41</td>\n",
              "      <td>73</td>\n",
              "      <td>81</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "      <td>22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>19</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.06</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>18.18</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6</td>\n",
              "      <td>2.00</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>0.36</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>20.00</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.17</td>\n",
              "      <td>2</td>\n",
              "      <td>2.00</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.15</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.24</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>39</td>\n",
              "      <td>51</td>\n",
              "      <td>25</td>\n",
              "      <td>18</td>\n",
              "      <td>26</td>\n",
              "      <td>20.00</td>\n",
              "      <td>17</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.05</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>42.86</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>753 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a98977b1-f1dc-42d0-bdb7-74828dbf0ce1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a98977b1-f1dc-42d0-bdb7-74828dbf0ce1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a98977b1-f1dc-42d0-bdb7-74828dbf0ce1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
              "0            2             1           0                     0             0   \n",
              "1            1             1           4                     0             0   \n",
              "2           27            19           1                     4            13   \n",
              "3            2            17           2                     0             0   \n",
              "4            6             1           1                     0             2   \n",
              "..         ...           ...         ...                   ...           ...   \n",
              "748          0             7           3                     2             0   \n",
              "749          0             1           0                     0             0   \n",
              "750          0             3           0                     0             0   \n",
              "751          5             7           1                     1             3   \n",
              "752          4             1           3                     0             6   \n",
              "\n",
              "     CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  \\\n",
              "0                  0                      1                0.10   \n",
              "1                  0                      1                0.07   \n",
              "2                 26                     11                0.26   \n",
              "3                 24                      9                0.47   \n",
              "4                  0                      1                0.11   \n",
              "..               ...                    ...                 ...   \n",
              "748               12                      4                0.40   \n",
              "749                0                      1                1.00   \n",
              "750                4                      2                0.17   \n",
              "751               10                      4                0.24   \n",
              "752                0                      1                0.13   \n",
              "\n",
              "     DECISION_COUNT  DECISION_DENSITY  ...  NODE_COUNT  \\\n",
              "0                 0              0.00  ...           2   \n",
              "1                 0              0.00  ...           6   \n",
              "2                12              2.17  ...          25   \n",
              "3                 8              3.00  ...          25   \n",
              "4                 0              0.00  ...           3   \n",
              "..              ...               ...  ...         ...   \n",
              "748               6              2.00  ...          12   \n",
              "749               0              0.00  ...           2   \n",
              "750               2              2.00  ...           6   \n",
              "751               4              2.50  ...          11   \n",
              "752               0              0.00  ...           6   \n",
              "\n",
              "     NORMALIZED_CYLOMATIC_COMPLEXITY  NUM_OPERANDS  NUM_OPERATORS  \\\n",
              "0                               0.08            28             29   \n",
              "1                               0.06            52             55   \n",
              "2                               0.13            58             78   \n",
              "3                               0.41            73             81   \n",
              "4                               0.06            19             23   \n",
              "..                               ...           ...            ...   \n",
              "748                             0.36            12             19   \n",
              "749                             1.00             0              1   \n",
              "750                             0.15            16             21   \n",
              "751                             0.15            39             51   \n",
              "752                             0.05            15             16   \n",
              "\n",
              "     NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  NUMBER_OF_LINES  \\\n",
              "0                      9                     5               13   \n",
              "1                     26                    14               16   \n",
              "2                     30                    24               83   \n",
              "3                     23                    20               22   \n",
              "4                     15                     7               18   \n",
              "..                   ...                   ...              ...   \n",
              "748                   10                     8               11   \n",
              "749                    0                     1                1   \n",
              "750                    8                    10               13   \n",
              "751                   25                    18               26   \n",
              "752                    9                     6               19   \n",
              "\n",
              "     PERCENT_COMMENTS  LOC_TOTAL  defects  \n",
              "0                0.00         10    False  \n",
              "1                0.00         14    False  \n",
              "2               30.91         42    False  \n",
              "3                0.00         19    False  \n",
              "4               18.18          9    False  \n",
              "..                ...        ...      ...  \n",
              "748             20.00         10    False  \n",
              "749              0.00          0    False  \n",
              "750              0.00         12    False  \n",
              "751             20.00         17    False  \n",
              "752             42.86          8    False  \n",
              "\n",
              "[753 rows x 38 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "598AzvRCutgM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV6pVifmtS7G"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTZ9dMlStS7G",
        "outputId": "2a67ce3b-0222-4ad6-b33e-2d1095ce90a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9084422657952069\n",
            "Test accuracy of best grid search hypers: 0.9078947368421053\n",
            "Best CV params {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9084313725490196\n",
            "Test accuracy of best grid search hypers: 0.9210526315789473\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9099128540305012\n",
            "Test accuracy of best grid search hypers: 0.8947368421052632\n",
            "Best CV params {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9071023965141614\n",
            "Test accuracy of best grid search hypers: 0.92\n",
            "Best CV params {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9071023965141614\n",
            "Test accuracy of best grid search hypers: 0.92\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9159259259259258\n",
            "Test accuracy of best grid search hypers: 0.8666666666666667\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9070915032679739\n",
            "Test accuracy of best grid search hypers: 0.9466666666666667\n",
            "Best CV params {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9100435729847494\n",
            "Test accuracy of best grid search hypers: 0.9066666666666666\n",
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.911525054466231\n",
            "Test accuracy of best grid search hypers: 0.8933333333333333\n",
            "Best CV params {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9129956427015251\n",
            "Test accuracy of best grid search hypers: 0.88\n"
          ]
        }
      ],
      "source": [
        "x= Data_9.iloc[:, 0:37]\n",
        "y= Data_9.iloc[:,37]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV-fr56ExFZp"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__NDxil2xH2E",
        "outputId": "0b198afd-c489-4d41-ae76-49afb2ca266b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Tuned Logistic Regression Accuracy: 0.9084313725490196\n",
            "Test accuracy of best grid search hypers: 0.8947368421052632\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'sag', 'saga']})\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0422ec34212c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Classification report for %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlogreg_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [76, 92]"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_9.iloc[:, 0:37]\n",
        "y= Data_9.iloc[:,37]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "  print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "  print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "  print( metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSfhP2SGjRuY"
      },
      "outputs": [],
      "source": [
        "# Using the model to predict the labels of the test data\n",
        "y_pred = logreg_cv.predict(X_test)\n",
        "\n",
        "# Evaluating the accuracy of the model using the sklearn functions\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZt_Odc1tTRG"
      },
      "source": [
        "## Data 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSx4rqUotTRG"
      },
      "source": [
        "### Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKGAG4btTRH",
        "outputId": "96d2f7fe-6657-41c5-f7c2-024234cbf066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(780, 38)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_10.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia7P4prPtTRH",
        "outputId": "b339dc82-1d42-4afe-acb3-75ec0a4eb57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t Null Count\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LOC_BLANK                          0\n",
              "BRANCH_COUNT                       0\n",
              "CALL_PAIRS                         0\n",
              "LOC_CODE_AND_COMMENT               0\n",
              "LOC_COMMENTS                       0\n",
              "CONDITION_COUNT                    0\n",
              "CYCLOMATIC_COMPLEXITY              0\n",
              "CYCLOMATIC_DENSITY                 0\n",
              "DECISION_COUNT                     0\n",
              "DECISION_DENSITY                   0\n",
              "DESIGN_COMPLEXITY                  0\n",
              "DESIGN_DENSITY                     0\n",
              "EDGE_COUNT                         0\n",
              "ESSENTIAL_COMPLEXITY               0\n",
              "ESSENTIAL_DENSITY                  0\n",
              "LOC_EXECUTABLE                     0\n",
              "PARAMETER_COUNT                    0\n",
              "HALSTEAD_CONTENT                   0\n",
              "HALSTEAD_DIFFICULTY                0\n",
              "HALSTEAD_EFFORT                    0\n",
              "HALSTEAD_ERROR_EST                 0\n",
              "HALSTEAD_LENGTH                    0\n",
              "HALSTEAD_LEVEL                     0\n",
              "HALSTEAD_PROG_TIME                 0\n",
              "HALSTEAD_VOLUME                    0\n",
              "MAINTENANCE_SEVERITY               0\n",
              "MODIFIED_CONDITION_COUNT           0\n",
              "MULTIPLE_CONDITION_COUNT           0\n",
              "NODE_COUNT                         0\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    0\n",
              "NUM_OPERANDS                       0\n",
              "NUM_OPERATORS                      0\n",
              "NUM_UNIQUE_OPERANDS                0\n",
              "NUM_UNIQUE_OPERATORS               0\n",
              "NUMBER_OF_LINES                    0\n",
              "PERCENT_COMMENTS                   0\n",
              "LOC_TOTAL                          0\n",
              "defects                            0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t Null Count\")\n",
        "Data_10.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivyO0CsHtTRH",
        "outputId": "92c38497-77c3-4990-bd87-8186f4d9445a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature \t    Is NaN?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LOC_BLANK                          False\n",
              "BRANCH_COUNT                       False\n",
              "CALL_PAIRS                         False\n",
              "LOC_CODE_AND_COMMENT               False\n",
              "LOC_COMMENTS                       False\n",
              "CONDITION_COUNT                    False\n",
              "CYCLOMATIC_COMPLEXITY              False\n",
              "CYCLOMATIC_DENSITY                 False\n",
              "DECISION_COUNT                     False\n",
              "DECISION_DENSITY                   False\n",
              "DESIGN_COMPLEXITY                  False\n",
              "DESIGN_DENSITY                     False\n",
              "EDGE_COUNT                         False\n",
              "ESSENTIAL_COMPLEXITY               False\n",
              "ESSENTIAL_DENSITY                  False\n",
              "LOC_EXECUTABLE                     False\n",
              "PARAMETER_COUNT                    False\n",
              "HALSTEAD_CONTENT                   False\n",
              "HALSTEAD_DIFFICULTY                False\n",
              "HALSTEAD_EFFORT                    False\n",
              "HALSTEAD_ERROR_EST                 False\n",
              "HALSTEAD_LENGTH                    False\n",
              "HALSTEAD_LEVEL                     False\n",
              "HALSTEAD_PROG_TIME                 False\n",
              "HALSTEAD_VOLUME                    False\n",
              "MAINTENANCE_SEVERITY               False\n",
              "MODIFIED_CONDITION_COUNT           False\n",
              "MULTIPLE_CONDITION_COUNT           False\n",
              "NODE_COUNT                         False\n",
              "NORMALIZED_CYLOMATIC_COMPLEXITY    False\n",
              "NUM_OPERANDS                       False\n",
              "NUM_OPERATORS                      False\n",
              "NUM_UNIQUE_OPERANDS                False\n",
              "NUM_UNIQUE_OPERATORS               False\n",
              "NUMBER_OF_LINES                    False\n",
              "PERCENT_COMMENTS                   False\n",
              "LOC_TOTAL                          False\n",
              "defects                            False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Feature \\t    Is NaN?\")\n",
        "Data_10.isna().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohzrt0XStTRH",
        "outputId": "93f09614-7b65-41cb-f666-2546717db28d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9bbd6c58-bae2-41ff-8b9f-bd4a0ae0d5d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC_BLANK</th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>...</th>\n",
              "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>780.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.773077</td>\n",
              "      <td>8.365385</td>\n",
              "      <td>2.325641</td>\n",
              "      <td>2.037179</td>\n",
              "      <td>4.835897</td>\n",
              "      <td>7.320513</td>\n",
              "      <td>4.780769</td>\n",
              "      <td>0.336859</td>\n",
              "      <td>3.343590</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>...</td>\n",
              "      <td>3.741026</td>\n",
              "      <td>15.598718</td>\n",
              "      <td>0.201128</td>\n",
              "      <td>37.826923</td>\n",
              "      <td>61.597436</td>\n",
              "      <td>13.394872</td>\n",
              "      <td>11.692308</td>\n",
              "      <td>37.373077</td>\n",
              "      <td>17.112795</td>\n",
              "      <td>20.169231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.787789</td>\n",
              "      <td>12.913500</td>\n",
              "      <td>2.852670</td>\n",
              "      <td>4.931354</td>\n",
              "      <td>9.823408</td>\n",
              "      <td>18.206767</td>\n",
              "      <td>6.704807</td>\n",
              "      <td>0.389734</td>\n",
              "      <td>8.609032</td>\n",
              "      <td>1.086436</td>\n",
              "      <td>...</td>\n",
              "      <td>9.531226</td>\n",
              "      <td>19.759445</td>\n",
              "      <td>0.232086</td>\n",
              "      <td>71.115174</td>\n",
              "      <td>100.084057</td>\n",
              "      <td>25.183496</td>\n",
              "      <td>6.468265</td>\n",
              "      <td>48.928761</td>\n",
              "      <td>20.791583</td>\n",
              "      <td>24.546298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>8.605000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.232500</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>30.047500</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>372.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>8.550000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>2.290000</td>\n",
              "      <td>1403.000000</td>\n",
              "      <td>1430.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>802.000000</td>\n",
              "      <td>92.590000</td>\n",
              "      <td>210.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bbd6c58-bae2-41ff-8b9f-bd4a0ae0d5d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bbd6c58-bae2-41ff-8b9f-bd4a0ae0d5d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bbd6c58-bae2-41ff-8b9f-bd4a0ae0d5d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  \\\n",
              "count  780.000000    780.000000  780.000000            780.000000   \n",
              "mean     6.773077      8.365385    2.325641              2.037179   \n",
              "std      9.787789     12.913500    2.852670              4.931354   \n",
              "min      0.000000      1.000000    0.000000              0.000000   \n",
              "25%      1.000000      3.000000    1.000000              0.000000   \n",
              "50%      3.000000      5.000000    1.000000              0.000000   \n",
              "75%      9.000000      9.000000    3.000000              2.000000   \n",
              "max     90.000000    187.000000   24.000000             55.000000   \n",
              "\n",
              "       LOC_COMMENTS  CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  \\\n",
              "count    780.000000       780.000000             780.000000   \n",
              "mean       4.835897         7.320513               4.780769   \n",
              "std        9.823408        18.206767               6.704807   \n",
              "min        0.000000         0.000000               1.000000   \n",
              "25%        0.000000         0.000000               1.000000   \n",
              "50%        0.000000         0.000000               3.000000   \n",
              "75%        5.250000         8.000000               5.000000   \n",
              "max       78.000000       372.000000              94.000000   \n",
              "\n",
              "       CYCLOMATIC_DENSITY  DECISION_COUNT  DECISION_DENSITY  ...  \\\n",
              "count          780.000000      780.000000        780.000000  ...   \n",
              "mean             0.336859        3.343590          0.974359  ...   \n",
              "std              0.389734        8.609032          1.086436  ...   \n",
              "min              0.000000        0.000000          0.000000  ...   \n",
              "25%              0.160000        0.000000          0.000000  ...   \n",
              "50%              0.250000        0.000000          0.000000  ...   \n",
              "75%              0.420000        4.000000          2.000000  ...   \n",
              "max              8.550000      186.000000          5.000000  ...   \n",
              "\n",
              "       MULTIPLE_CONDITION_COUNT  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
              "count                780.000000  780.000000                       780.000000   \n",
              "mean                   3.741026   15.598718                         0.201128   \n",
              "std                    9.531226   19.759445                         0.232086   \n",
              "min                    0.000000    2.000000                         0.000000   \n",
              "25%                    0.000000    6.000000                         0.080000   \n",
              "50%                    0.000000   10.000000                         0.140000   \n",
              "75%                    4.000000   18.000000                         0.232500   \n",
              "max                  186.000000  238.000000                         2.290000   \n",
              "\n",
              "       NUM_OPERANDS  NUM_OPERATORS  NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  \\\n",
              "count    780.000000     780.000000           780.000000            780.000000   \n",
              "mean      37.826923      61.597436            13.394872             11.692308   \n",
              "std       71.115174     100.084057            25.183496              6.468265   \n",
              "min        0.000000       0.000000             0.000000              0.000000   \n",
              "25%        9.000000      15.000000             5.000000              7.000000   \n",
              "50%       19.000000      32.500000             9.000000             11.000000   \n",
              "75%       42.000000      73.000000            16.000000             15.000000   \n",
              "max     1403.000000    1430.000000           601.000000             38.000000   \n",
              "\n",
              "       NUMBER_OF_LINES  PERCENT_COMMENTS   LOC_TOTAL  \n",
              "count       780.000000        780.000000  780.000000  \n",
              "mean         37.373077         17.112795   20.169231  \n",
              "std          48.928761         20.791583   24.546298  \n",
              "min           1.000000          0.000000    0.000000  \n",
              "25%          12.000000          0.000000    6.000000  \n",
              "50%          21.000000          8.605000   12.000000  \n",
              "75%          46.000000         30.047500   24.000000  \n",
              "max         802.000000         92.590000  210.000000  \n",
              "\n",
              "[8 rows x 37 columns]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_10.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGFeq6BMtTRH",
        "outputId": "b56d76a4-6991-4bd3-ba57-d247e26d8e7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7220b13-7879-4f4a-b59d-889adfe9bf8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC_BLANK</th>\n",
              "      <th>BRANCH_COUNT</th>\n",
              "      <th>CALL_PAIRS</th>\n",
              "      <th>LOC_CODE_AND_COMMENT</th>\n",
              "      <th>LOC_COMMENTS</th>\n",
              "      <th>CONDITION_COUNT</th>\n",
              "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
              "      <th>CYCLOMATIC_DENSITY</th>\n",
              "      <th>DECISION_COUNT</th>\n",
              "      <th>DECISION_DENSITY</th>\n",
              "      <th>...</th>\n",
              "      <th>NODE_COUNT</th>\n",
              "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
              "      <th>NUM_OPERANDS</th>\n",
              "      <th>NUM_OPERATORS</th>\n",
              "      <th>NUM_UNIQUE_OPERANDS</th>\n",
              "      <th>NUM_UNIQUE_OPERATORS</th>\n",
              "      <th>NUMBER_OF_LINES</th>\n",
              "      <th>PERCENT_COMMENTS</th>\n",
              "      <th>LOC_TOTAL</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.11</td>\n",
              "      <td>53</td>\n",
              "      <td>49</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>31.25</td>\n",
              "      <td>24</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>0.56</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>0.36</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>10.00</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0.17</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.13</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>23</td>\n",
              "      <td>10.53</td>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>26</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>28</td>\n",
              "      <td>15.00</td>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>35</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>39</td>\n",
              "      <td>89</td>\n",
              "      <td>28</td>\n",
              "      <td>25</td>\n",
              "      <td>83</td>\n",
              "      <td>8.51</td>\n",
              "      <td>44</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0.20</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.12</td>\n",
              "      <td>17</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>17.65</td>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>40.00</td>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>0.26</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>26</td>\n",
              "      <td>43</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>39</td>\n",
              "      <td>80.00</td>\n",
              "      <td>23</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>0.18</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>0.16</td>\n",
              "      <td>33</td>\n",
              "      <td>93</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>37</td>\n",
              "      <td>11.76</td>\n",
              "      <td>34</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>780 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7220b13-7879-4f4a-b59d-889adfe9bf8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7220b13-7879-4f4a-b59d-889adfe9bf8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7220b13-7879-4f4a-b59d-889adfe9bf8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     LOC_BLANK  BRANCH_COUNT  CALL_PAIRS  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
              "0           17            11           5                     2             8   \n",
              "1            2             9           3                     0             1   \n",
              "2            2             5           1                     1             1   \n",
              "3            4             5           1                     0             0   \n",
              "4            7             5           1                     3             0   \n",
              "..         ...           ...         ...                   ...           ...   \n",
              "775         35            14          12                     1             3   \n",
              "776          6             5           1                     1             2   \n",
              "777          5             1           0                     0             4   \n",
              "778          7            11           1                    17             7   \n",
              "779          1             9           3                     4             0   \n",
              "\n",
              "     CONDITION_COUNT  CYCLOMATIC_COMPLEXITY  CYCLOMATIC_DENSITY  \\\n",
              "0                 20                      6                0.25   \n",
              "1                 16                      5                0.56   \n",
              "2                  6                      3                0.17   \n",
              "3                  8                      3                0.30   \n",
              "4                  0                      3                0.15   \n",
              "..               ...                    ...                 ...   \n",
              "775                0                     13                0.30   \n",
              "776                8                      3                0.20   \n",
              "777                0                      1                0.17   \n",
              "778               18                      6                0.26   \n",
              "779                8                      6                0.18   \n",
              "\n",
              "     DECISION_COUNT  DECISION_DENSITY  ...  NODE_COUNT  \\\n",
              "0                10                 2  ...          25   \n",
              "1                 6                 2  ...          14   \n",
              "2                 2                 3  ...           7   \n",
              "3                 4                 2  ...          10   \n",
              "4                 0                 0  ...          10   \n",
              "..              ...               ...  ...         ...   \n",
              "775               0                 0  ...          17   \n",
              "776               4                 2  ...          10   \n",
              "777               0                 0  ...           2   \n",
              "778               8                 2  ...          15   \n",
              "779               4                 2  ...          15   \n",
              "\n",
              "     NORMALIZED_CYLOMATIC_COMPLEXITY  NUM_OPERANDS  NUM_OPERATORS  \\\n",
              "0                               0.11            53             49   \n",
              "1                               0.36            13             24   \n",
              "2                               0.13            16             28   \n",
              "3                               0.19            13             16   \n",
              "4                               0.11            26             46   \n",
              "..                               ...           ...            ...   \n",
              "775                             0.16            39             89   \n",
              "776                             0.12            17             25   \n",
              "777                             0.06            10             20   \n",
              "778                             0.15            26             43   \n",
              "779                             0.16            33             93   \n",
              "\n",
              "     NUM_UNIQUE_OPERANDS  NUM_UNIQUE_OPERATORS  NUMBER_OF_LINES  \\\n",
              "0                     23                    12               57   \n",
              "1                      7                    14               14   \n",
              "2                      9                    14               23   \n",
              "3                     10                     9               16   \n",
              "4                      7                     7               28   \n",
              "..                   ...                   ...              ...   \n",
              "775                   28                    25               83   \n",
              "776                    7                    12               25   \n",
              "777                    5                     7               18   \n",
              "778                   14                    14               39   \n",
              "779                   12                    24               37   \n",
              "\n",
              "     PERCENT_COMMENTS  LOC_TOTAL  defects  \n",
              "0               31.25         24    False  \n",
              "1               10.00          9    False  \n",
              "2               10.53         18    False  \n",
              "3                0.00         10    False  \n",
              "4               15.00         20    False  \n",
              "..                ...        ...      ...  \n",
              "775              8.51         44    False  \n",
              "776             17.65         15     True  \n",
              "777             40.00          6    False  \n",
              "778             80.00         23     True  \n",
              "779             11.76         34    False  \n",
              "\n",
              "[780 rows x 38 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyo_RcsdtTRH"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEQ4LYOYtTRI",
        "outputId": "3a5d5ced-70dc-4ad4-eb77-3504f2ec6bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9145187436676798\n",
            "Test accuracy of best grid search hypers: 0.9102564102564102\n",
            "Best CV params {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9102431610942249\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9202127659574467\n",
            "Test accuracy of best grid search hypers: 0.8846153846153846\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9202026342451874\n",
            "Test accuracy of best grid search hypers: 0.8717948717948718\n",
            "Best CV params {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9059371833839919\n",
            "Test accuracy of best grid search hypers: 0.9615384615384616\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9187639311043567\n",
            "Test accuracy of best grid search hypers: 0.8589743589743589\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9130901722391084\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "Best CV accuracy 0.9159067882472138\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9116616008105369\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Best CV params {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.913080040526849\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n"
          ]
        }
      ],
      "source": [
        "x= Data_10.iloc[:, 0:37]\n",
        "y= Data_10.iloc[:,37]\n",
        "\n",
        "\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "  # Instantiate the GridSearchCV object and run the search\n",
        "  parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "  searcher = GridSearchCV(svm, parameters)\n",
        "  searcher.fit(X_train_std, y_train)\n",
        "\n",
        "  # Report the best parameters and the corresponding score\n",
        "  print(\"Best CV params\", searcher.best_params_)\n",
        "  print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJaajtqExLBa"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTYvC3L7xM6A",
        "outputId": "f6d43e0d-1944-42a8-b7fc-6ea3ed073364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9116717325227963\n",
            "Test accuracy of best grid search hypers: 0.8974358974358975\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9087943262411347\n",
            "Test accuracy of best grid search hypers: 0.9230769230769231\n",
            "Tuned Logistic Regression Parameter: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9088348530901722\n",
            "Test accuracy of best grid search hypers: 0.9102564102564102\n",
            "Tuned Logistic Regression Parameter: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9131003039513679\n",
            "Test accuracy of best grid search hypers: 0.8974358974358975\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9073860182370821\n",
            "Test accuracy of best grid search hypers: 0.9358974358974359\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.9187841945288755\n",
            "Test accuracy of best grid search hypers: 0.8461538461538461\n",
            "Tuned Logistic Regression Parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "Tuned Logistic Regression Accuracy: 0.9073860182370821\n",
            "Test accuracy of best grid search hypers: 0.9615384615384616\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7bfa3ea0a6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mlogreg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Fit it to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mlogreg_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Print the optimal parameters and best score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"processes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[1;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             ]\n\u001b[0;32m--> 806\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x= Data_10.iloc[:, 0:37]\n",
        "y= Data_10.iloc[:,37]\n",
        "#x=Data_1.drop(['defects'], axis=1)\n",
        "#y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "#KFold k=10\n",
        "folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "for train_index, test_index in folds.split(x):\n",
        "  X_train=x.iloc[train_index]\n",
        "  X_test=x.iloc[test_index]\n",
        "  #X_test=x.loc[test_index]\n",
        "  y_train=y.iloc[train_index]\n",
        "  y_test=y.iloc[test_index]\n",
        "  logreg = LogisticRegression()\n",
        "  # Create the hyperparameter grid\n",
        "  \n",
        "  c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "  param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "  logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "  # Fit it to the training data\n",
        "  logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "  # Print the optimal parameters and best score\n",
        "  print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "  print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "  # Report the test accuracy using these best parameters\n",
        "  print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYDYwNFYjYPZ"
      },
      "outputs": [],
      "source": [
        "# Using the model to predict the labels of the test data\n",
        "y_pred = logreg_cv.predict(X_test)\n",
        "\n",
        "# Evaluating the accuracy of the model using the sklearn functions\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "print( \"Classification report for %s\" % logreg_cv)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45DkjFOgMiNZ"
      },
      "source": [
        "# Que 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2llBdUaMmn3"
      },
      "source": [
        "Q2) What is the impact of class imbalance on your results, and which is the best evaluation measure should be used in this case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btdNKkhhMtjz"
      },
      "outputs": [],
      "source": [
        "#i can't correctly identify the accuracy   -- > can evaliatuion using f measure "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOO7ejRWgtCz",
        "outputId": "8d7896b9-8570-415a-c026-b0fd7c0a8774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data 1 imbalance -- > class :True = 9 and False = 112\n",
            "Data 2 imbalance -- > class :True = 8 and False = 55\n",
            "Data 3 imbalance -- > class :True = 20 and False = 87\n",
            "Data 4 imbalance -- > class :True = 8 and False = 28\n",
            "Data 5 imbalance -- > class :True = 15 and False = 86\n",
            "Data 6 imbalance -- > class :True = 49 and False = 449\n",
            "Data 7 imbalance -- > class :True = 77 and False = 959\n",
            "Data 8 imbalance -- > class :True = 4 and False = 916\n",
            "Data 9 imbalance -- > class :True = 70 and False = 683\n",
            "Data 10 imbalance -- > class :True = 87 and False = 693\n"
          ]
        }
      ],
      "source": [
        "print(\"Data 1 imbalance -- > class :True =\",sum(Data_1['defects']==True) ,\"and False =\",sum(Data_1['defects']==False))\n",
        "print(\"Data 2 imbalance -- > class :True =\",sum(Data_2['defects']==True) ,\"and False =\",sum(Data_2['defects']==False))\n",
        "print(\"Data 3 imbalance -- > class :True =\",sum(Data_3['defects']==True) ,\"and False =\",sum(Data_3['defects']==False))\n",
        "print(\"Data 4 imbalance -- > class :True =\",sum(Data_4['defects']==True) ,\"and False =\",sum(Data_4['defects']==False))\n",
        "print(\"Data 5 imbalance -- > class :True =\",sum(Data_5['defects']==True) ,\"and False =\",sum(Data_5['defects']==False))\n",
        "print(\"Data 6 imbalance -- > class :True =\",sum(Data_6['defects']==True) ,\"and False =\",sum(Data_6['defects']==False))\n",
        "print(\"Data 7 imbalance -- > class :True =\",sum(Data_7['defects']==True) ,\"and False =\",sum(Data_7['defects']==False))\n",
        "print(\"Data 8 imbalance -- > class :True =\",sum(Data_8['defects']==True) ,\"and False =\",sum(Data_8['defects']==False))\n",
        "print(\"Data 9 imbalance -- > class :True =\",sum(Data_9['defects']==True) ,\"and False =\",sum(Data_9['defects']==False))\n",
        "print(\"Data 10 imbalance -- > class :True =\",sum(Data_10['defects']==True) ,\"and False =\",sum(Data_10['defects']==False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlHqwNlKiX41",
        "outputId": "a4068b07-2916-4ad1-f149-4986d328c256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM is: 89.1891891891892\n",
            "Classification report for SVC(C=1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.97      0.94        34\n",
            "        True       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.89        37\n",
            "   macro avg       0.46      0.49      0.47        37\n",
            "weighted avg       0.84      0.89      0.87        37\n",
            "\n",
            "[[33  1]\n",
            " [ 3  0]]\n"
          ]
        }
      ],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "# Making the SVM Classifer\n",
        "Classifier = SVC(C=1)\n",
        "\n",
        "# Training the model on the training data and labels\n",
        "Classifier.fit(X_train, y_train)\n",
        "\n",
        "# Using the model to predict the labels of the test data\n",
        "y_pred = Classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the accuracy of the model using the sklearn functions\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "# performance\n",
        "print( \"Classification report for %s\" % Classifier)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqvuwnoLkUvi"
      },
      "outputs": [],
      "source": [
        "#accuracy = 0.89 , f1= 0.47 (macro avg of f1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5WUqLRVNrsU"
      },
      "source": [
        "# Que 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ym-I9nNwdn"
      },
      "source": [
        "Q3) Which class imbalance learning technique could work efficiently with these datasets? Show your evidence from the experiments?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u7OG37GIc2d",
        "outputId": "9dcb7db8-6eaf-4a84-d756-f24120f8f4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False, True]\n",
            "Number labels equal True : (8, 30) Number labels equal False : (55, 30)\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(Data_2[list(Data_2.columns)[-1]])))\n",
        "label_one=Data_2[Data_2[list(Data_2.columns)[-1]]==True]\n",
        "label_two=Data_2[Data_2[list(Data_2.columns)[-1]]==False]\n",
        "print(\"Number labels equal True :\",label_one.shape,\"Number labels equal False :\",label_two.shape)\n",
        "col = list(Data_2.columns)[-1]\n",
        "x= Data_2.loc[:, Data_2.columns != col]\n",
        "y= Data_2.iloc[:,-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgOFQZ1u9rAK"
      },
      "outputs": [],
      "source": [
        "Datasets=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrTrq3Sw---i"
      },
      "outputs": [],
      "source": [
        "dic_LR={ \n",
        " 1:[ 0.001,  'l1',  'saga' ],\n",
        " 2:[ 0.001, 'l1',  'liblinear'],   \n",
        " 3:[ 0.01, 'l1',  'liblinear'],\n",
        " 4:[ 0.1,  'l2',  'liblinear'],\n",
        " 5:[ 0.001, 'l2',  'liblinear'],\n",
        " 6:[ 0.001, 'l1',  'liblinear'],\n",
        " 7:[ 0.001,  'l2', 'newton-cg'],\n",
        " 8:[ 0.001, 'l1',  'liblinear'],\n",
        " 9:[ 0.01,  'l2',  'newton-cg'],\n",
        " 10:[ 0.01,  'l2',  'newton-cg']}\n",
        "\n",
        "\n",
        "\n",
        "dic_svm={  \n",
        " 1:[0.01,  0.001,  'linear'],\n",
        " 2:[ 0.1,  0.1,  'poly'],  \n",
        "  3:[ 0.1,  0.1,  'poly'], \n",
        "  4:[ 100,  0.01,  'rbf'],\n",
        " 5:[ 1,  0.001,  'linear'],\n",
        "  6:[ 0.1,  0.01,  'sigmoid'],\n",
        "  7:[ 10,  10,  'rbf'],\n",
        "  8:[ 10,  0.01,  'sigmoid'],\n",
        "  9:[ 10,  0.1,  'rbf'],\n",
        "  10:[10,  0.01, 'rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UP97G7ub-xc"
      },
      "outputs": [],
      "source": [
        "def check(Data):\n",
        "  print(sorted(Counter(Data[list(Data.columns)[-1]])))\n",
        "  label_one=Data[Data[list(Data.columns)[-1]]==True]\n",
        "  label_two=Data[Data[list(Data.columns)[-1]]==False]\n",
        "  print(\"Number labels equal True :\",label_one.shape,\"Number labels equal False :\",label_two.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWAr6GQ5aRA0"
      },
      "outputs": [],
      "source": [
        "def UnderOver_sampling(Data):   \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "  rus=RandomUnderSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay undersampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)\n",
        "  ros=RandomOverSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay oversampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoQ5rsGj_l9b"
      },
      "outputs": [],
      "source": [
        "def UnderOver_sampling(Data,i):  \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "\n",
        "  rus=RandomUnderSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay undersampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)\n",
        "\n",
        "  ros=RandomOverSampler(random_state=0)\n",
        "  x_resampled_over,y_resampled_over = rus.fit_resample(x,y)\n",
        "  print(\" when applay oversampling =\",sorted(Counter(y_resampled_over).items()),y_resampled_over.shape)\n",
        "\n",
        "  print(\" when applay undersampling on SVM =\")\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x_resampled,y_resampled )\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel = dic_svm[i][2])\n",
        "  s=svm.fit(X_train_std , y_train)\n",
        "  y_hat=s.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogReg(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train, y_train)\n",
        "  y_hat=l.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztRsWDr3GJDR"
      },
      "outputs": [],
      "source": [
        "\n",
        "  \n",
        "  print(\" when applay Oversampling on SVM =\")\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x_resampled_over,y_resampled_over )\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  X_train_smote , y_train_smote = oversample.fit_resample(X_train,y_train)\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel = dic_svm[i][2])\n",
        "  s=svm.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogReg(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "RTNpNarGDUyw",
        "outputId": "1a474aa6-7b20-4073-a520-2e7dc74fc26c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Data 1\n",
            " when applay undersampling = [(False, 9), (True, 9)] (18,)\n",
            " when applay oversampling = [(False, 9), (True, 9)] (18,)\n",
            " when applay undersampling on SVM =\n",
            "Accuracy for SVM is: 0.0\n",
            "Classification report for SVC(C=0.01, gamma=0.001, kernel='linear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.00      0.00      0.00       5.0\n",
            "        True       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       5.0\n",
            "   macro avg       0.00      0.00      0.00       5.0\n",
            "weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "Logistic Regression in Balance data\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-b890fe767f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Data {c}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mUnderOver_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-177076db0806>\u001b[0m in \u001b[0;36mUnderOver_sampling\u001b[0;34m(Data, i)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression in Balance data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mLR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0my_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LogReg() got an unexpected keyword argument 'C'"
          ]
        }
      ],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  UnderOver_sampling(i,c)\n",
        "  c+=1\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "Tr7PMzKbBfH2",
        "outputId": "955a6675-b785-4129-da30-288ccd92463a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Data 1\n",
            "[False, True]\n",
            "Number labels equal True : (9, 30) Number labels equal False : (112, 30)\n",
            "After apply under and over sampling :\n",
            " when applay undersampling = [(False, 9), (True, 9)] (18,)\n",
            " when applay oversampling = [(False, 9), (True, 9)] (18,)\n",
            " when applay undersampling on SVM =\n",
            "Accuracy for SVM is: 0.0\n",
            "Classification report for SVC(C=0.01, gamma=0.001, kernel='linear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.00      0.00      0.00       3.0\n",
            "        True       0.00      0.00      0.00       2.0\n",
            "\n",
            "    accuracy                           0.00       5.0\n",
            "   macro avg       0.00      0.00      0.00       5.0\n",
            "weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "Logistic Regression in Balance data\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-f509586e2731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After apply under and over sampling :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mUnderOver_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After applay SMOTE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-445d0183dd8d>\u001b[0m in \u001b[0;36mUnderOver_sampling\u001b[0;34m(Data, i)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression in Balance data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mLR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdic_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_smote\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0my_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LogReg() got an unexpected keyword argument 'C'"
          ]
        }
      ],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  check(i)\n",
        "  print(\"After apply under and over sampling :\")\n",
        "  UnderOver_sampling(i,c)\n",
        "  print(\"After applay SMOTE\")\n",
        " \n",
        "  c+=1 \n",
        "\n",
        "\n",
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  UnderOver_sampling((i,c)\n",
        "\n",
        " \n",
        "  c+=1   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsucwfIepT7E"
      },
      "outputs": [],
      "source": [
        "smote=SMOTE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jShh4Fbrx5Oj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoQ7SIJgyZEh"
      },
      "outputs": [],
      "source": [
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "CjwhRw3zE9pE",
        "outputId": "b5281a97-3338-4c7e-8ff0-505607afe021"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-290a43437e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdic_svm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernal = dic_svm[i][2]\n",
        "C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaMiiFeY7p25"
      },
      "outputs": [],
      "source": [
        "def Over_smote(Data,i):  \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x,y)\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  X_train_smote , y_train_smote = oversample.fit_resample(X_train_std,y_train)\n",
        "  print('Befor SMOTE :',Counter(y_train))\n",
        "  print('After SMOTE :',Counter(y_train_smote))\n",
        "  print('SVM in Balance data')\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel= dic_svm[i][2])\n",
        "  s=svm.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogisticRegression(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=l.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression  is:\",accuracy)\n",
        "  print(\"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JL---gjJFQ0"
      },
      "outputs": [],
      "source": [
        "oversample = SMOTE(k_neighbors=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcK6eHRh8t6W"
      },
      "outputs": [],
      "source": [
        "Datasets=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L7niy4S9w8W",
        "outputId": "3c14bbf4-9f4f-41b6-a775-886fb8c3ab04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JpAMyJVa8NeW",
        "outputId": "1ca8086c-139c-4100-f915-1e40b44d4aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Data 1\n",
            "Befor SMOTE : Counter({False: 84, True: 6})\n",
            "After SMOTE : Counter({False: 84, True: 84})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 64.51612903225806\n",
            "Classification report for SVC(C=0.01, gamma=0.001, kernel='linear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      0.71      0.78        28\n",
            "        True       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.65        31\n",
            "   macro avg       0.43      0.36      0.39        31\n",
            "weighted avg       0.79      0.65      0.71        31\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 9.67741935483871\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='saga')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.00      0.00      0.00        28\n",
            "        True       0.10      1.00      0.18         3\n",
            "\n",
            "    accuracy                           0.10        31\n",
            "   macro avg       0.05      0.50      0.09        31\n",
            "weighted avg       0.01      0.10      0.02        31\n",
            "\n",
            "\n",
            " Data 2\n",
            "Befor SMOTE : Counter({False: 40, True: 7})\n",
            "After SMOTE : Counter({False: 40, True: 40})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 93.75\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.93      0.97        15\n",
            "        True       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.75      0.97      0.82        16\n",
            "weighted avg       0.97      0.94      0.95        16\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 93.75\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.94      1.00      0.97        15\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.94        16\n",
            "   macro avg       0.47      0.50      0.48        16\n",
            "weighted avg       0.88      0.94      0.91        16\n",
            "\n",
            "\n",
            " Data 3\n",
            "Befor SMOTE : Counter({False: 67, True: 13})\n",
            "After SMOTE : Counter({True: 67, False: 67})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 77.77777777777779\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.77      1.00      0.87        20\n",
            "        True       1.00      0.14      0.25         7\n",
            "\n",
            "    accuracy                           0.78        27\n",
            "   macro avg       0.88      0.57      0.56        27\n",
            "weighted avg       0.83      0.78      0.71        27\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 74.07407407407408\n",
            "Classification report for LogisticRegression(C=0.01, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.74      1.00      0.85        20\n",
            "        True       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.74        27\n",
            "   macro avg       0.37      0.50      0.43        27\n",
            "weighted avg       0.55      0.74      0.63        27\n",
            "\n",
            "\n",
            " Data 4\n",
            "Befor SMOTE : Counter({False: 22, True: 5})\n",
            "After SMOTE : Counter({True: 22, False: 22})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 88.88888888888889\n",
            "Classification report for SVC(C=100, gamma=0.01)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      1.00      0.92         6\n",
            "        True       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.93      0.83      0.86         9\n",
            "weighted avg       0.90      0.89      0.88         9\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 88.88888888888889\n",
            "Classification report for LogisticRegression(C=0.1, solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.83      0.91         6\n",
            "        True       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.88      0.92      0.88         9\n",
            "weighted avg       0.92      0.89      0.89         9\n",
            "\n",
            "\n",
            " Data 5\n",
            "Befor SMOTE : Counter({False: 65, True: 10})\n",
            "After SMOTE : Counter({False: 65, True: 65})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 80.76923076923077\n",
            "Classification report for SVC(C=1, gamma=0.001, kernel='linear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.90      0.88        21\n",
            "        True       0.50      0.40      0.44         5\n",
            "\n",
            "    accuracy                           0.81        26\n",
            "   macro avg       0.68      0.65      0.66        26\n",
            "weighted avg       0.79      0.81      0.80        26\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 73.07692307692307\n",
            "Classification report for LogisticRegression(C=0.001, solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.89      0.76      0.82        21\n",
            "        True       0.38      0.60      0.46         5\n",
            "\n",
            "    accuracy                           0.73        26\n",
            "   macro avg       0.63      0.68      0.64        26\n",
            "weighted avg       0.79      0.73      0.75        26\n",
            "\n",
            "\n",
            " Data 6\n",
            "Befor SMOTE : Counter({False: 337, True: 36})\n",
            "After SMOTE : Counter({False: 337, True: 337})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 85.6\n",
            "Classification report for SVC(C=0.1, gamma=0.01, kernel='sigmoid')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.91      0.92       112\n",
            "        True       0.33      0.38      0.36        13\n",
            "\n",
            "    accuracy                           0.86       125\n",
            "   macro avg       0.63      0.65      0.64       125\n",
            "weighted avg       0.87      0.86      0.86       125\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 89.60000000000001\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95       112\n",
            "        True       0.00      0.00      0.00        13\n",
            "\n",
            "    accuracy                           0.90       125\n",
            "   macro avg       0.45      0.50      0.47       125\n",
            "weighted avg       0.80      0.90      0.85       125\n",
            "\n",
            "\n",
            " Data 7\n",
            "Befor SMOTE : Counter({False: 718, True: 59})\n",
            "After SMOTE : Counter({False: 718, True: 718})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 93.05019305019306\n",
            "Classification report for SVC(C=10, gamma=10)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      1.00      0.96       241\n",
            "        True       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.93       259\n",
            "   macro avg       0.47      0.50      0.48       259\n",
            "weighted avg       0.87      0.93      0.90       259\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 77.60617760617761\n",
            "Classification report for LogisticRegression(C=0.001, solver='newton-cg')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.95      0.80      0.87       241\n",
            "        True       0.14      0.44      0.22        18\n",
            "\n",
            "    accuracy                           0.78       259\n",
            "   macro avg       0.55      0.62      0.54       259\n",
            "weighted avg       0.89      0.78      0.82       259\n",
            "\n",
            "\n",
            " Data 8\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-0cf534299f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Data {c}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mOver_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-f196f4cf09a6>\u001b[0m in \u001b[0;36mOver_smote\u001b[0;34m(Data, i)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mX_train_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mX_test_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mX_train_smote\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Befor SMOTE :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After SMOTE :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    311\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 3"
          ]
        }
      ],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  Over_smote(i,c)\n",
        "\n",
        " \n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keQIUrs9J_Ih",
        "outputId": "a5c0b4df-8e53-481b-a9ff-16e06c90b501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Befor SMOTE : Counter({False: 42, True: 5})\n",
            "After SMOTE : Counter({False: 42, True: 42})\n",
            "SVM in balance data\n",
            "Accuracy for SVM is: 87.5\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        13\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.93      0.67      0.71        16\n",
            "weighted avg       0.89      0.88      0.85        16\n",
            "\n",
            "Accuracy for SVM is: 87.5\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        13\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.93      0.67      0.71        16\n",
            "weighted avg       0.89      0.88      0.85        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "col = list(Data_2.columns)[-1]\n",
        "x= Data_2.loc[:, Data_2.columns != col]\n",
        "y= Data_2.iloc[:,-1]\n",
        "X_train ,X_test ,y_train , y_test =train_test_split(x,y)\n",
        "sc=StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std=sc.transform(X_train)\n",
        "X_test_std=sc.transform(X_test)\n",
        "X_train_smote , y_train_smote = oversample.fit_resample(X_train_std,y_train)\n",
        "print('Befor SMOTE :',Counter(y_train))\n",
        "print('After SMOTE :',Counter(y_train_smote))\n",
        "print('SVM in balance data')\n",
        "svm =SVC(C=dic_svm[2][0], gamma=dic_svm[2][1] ,kernel= dic_svm[2][2])\n",
        "s=svm.fit(X_train_smote , y_train_smote)\n",
        "y_hat=s.predict(X_test_std)\n",
        "accuracy = accuracy_score(y_test,y_hat )*100\n",
        "confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "print( \"Classification report for %s\" % s)\n",
        "print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "LR=LogisticRegression(C=dic_LR[2][0], penalty=dic_LR[2][1], solver =dic_LR[2][2])\n",
        "l=LR.fit(X_train_smote , y_train_smote)\n",
        "y_hat=s.predict(X_test_std)\n",
        "accuracy = accuracy_score(y_test,y_hat )*100\n",
        "confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "print( \"Classification report for %s\" % l)\n",
        "print(metrics.classification_report(y_test,y_hat ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beSPPxA2IX2C",
        "outputId": "bb5266c7-c88a-4b2c-c019-a4029b065100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Befor SMOTE : Counter({False: 41, True: 6})\n",
            "After SMOTE : Counter({False: 41, True: 41})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 100.0\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        14\n",
            "        True       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 100.0\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        14\n",
            "        True       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Over_smote(Data_2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMcCYJSUkyBv"
      },
      "outputs": [],
      "source": [
        "c = 2\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  check(i)\n",
        "  print(\"After apply under and over sampling :\")\n",
        "  UnderOver_sampling(i)\n",
        "  print(\"After applay SMOTE\")\n",
        " \n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I_dhf6KNzse"
      },
      "source": [
        "# Que 4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noUCRBMNN2j8"
      },
      "source": [
        "Q4) Is there improvement when apply feature selection? Which features do you think are the most predictive ones? Explain the way you have decided to select the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML-pCVcRqqXI"
      },
      "outputs": [],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7mps7gTqyhL",
        "outputId": "0a8364cd-780c-4578-a8fc-9bfacd8d9a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_udNxErqrim",
        "outputId": "27d9cd0c-427b-4c5a-8433-bd2c909a0d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['total_loc', 'blank_loc', 'comment_loc', 'code_and_comment_loc',\n",
              "       'executable_loc', 'unique_operands', 'unique_operators',\n",
              "       'total_operands', 'total_operators', 'halstead_vocabulary',\n",
              "       'halstead_length', 'halstead_volume', 'halstead_level',\n",
              "       'halstead_difficulty', 'halstead_effort', 'halstead_error',\n",
              "       'halstead_time', 'branch_count', 'decision_count', 'call_pairs',\n",
              "       'condition_count', 'multiple_condition_count', 'cyclomatic_complexity',\n",
              "       'cyclomatic_density', 'decision_density', 'design_complexity',\n",
              "       'design_density', 'normalized_cyclomatic_complexity',\n",
              "       'formal_parameters'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features= x.columns\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERPOweLMO6oI",
        "outputId": "6cf594cb-2369-4b5e-f3c7-b4f59eabd6ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaaqcoP1XQKq"
      },
      "source": [
        "Forward Selection Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y9jDRleBc3J",
        "outputId": "0393c01c-ce71-4f5c-b2e3-81ab53173569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxfCQrxkVXCU",
        "outputId": "d18db9c3-a599-4010-f258-278882179570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# I changed this part\n",
        "!pip install mlxtend\n",
        "import joblib\n",
        "import sys\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKDzFHQUBu7M"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNfELQXTSWp-"
      },
      "outputs": [],
      "source": [
        "sfs1 = SFS(RandomForestRegressor(), \n",
        "           k_features=10, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(np.array(X_train), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXvrM1K1tgBe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9tNv58ATQ-K",
        "outputId": "11704987-f20b-47b2-c585-6ec85a9fd1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correlated features:  19\n"
          ]
        }
      ],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "# find and remove correlated features\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', len(set(corr_features)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RNavqLu_Vqp"
      },
      "outputs": [],
      "source": [
        "def correlation(dataset, threshold):   \n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "    X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', len(set(corr_features)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atcO6AJrTYMQ",
        "outputId": "129a86cb-96bf-4af1-8785-c135b89ae3b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((84, 10), (37, 10))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removed correlated  features\n",
        "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHT2ruuyTyCi",
        "outputId": "6b35eda1-5fb2-4c00-cdf8-93bea98e2b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 1/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 2/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 3/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 4/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 5/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 6/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 7/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 8/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 9/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 10/10 -- score: nan"
          ]
        }
      ],
      "source": [
        "# step forward feature selection\n",
        "\n",
        "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "def fetureSelection():\n",
        "  sfs1 = SFS(SVC(), \n",
        "            k_features=10, \n",
        "            forward=True, \n",
        "            floating=False, \n",
        "            verbose=2,\n",
        "            scoring='r2',\n",
        "            cv=3)\n",
        "\n",
        "  sfs1 = sfs1.fit(np.array(X_train), y_train)\n",
        "  print(sfs1.k_feature_idx_)\n",
        "  print(X_train.columns[list(sfs1.k_feature_idx_)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJRlHNx4V3sY",
        "outputId": "4c52775d-0802-4b23-b32c-13e9d1baff96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sfs1.k_feature_idx_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxj80A1cV8SS",
        "outputId": "16ca8965-4d98-4c65-b661-12f445c2bdf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['total_loc', 'blank_loc', 'code_and_comment_loc', 'unique_operators',\n",
              "       'halstead_level', 'call_pairs', 'cyclomatic_density',\n",
              "       'decision_density', 'design_density', 'formal_parameters'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.columns[list(sfs1.k_feature_idx_)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtPYZ1tWAiy",
        "outputId": "b7c2d3b3-3d54-4d96-e334-ff15bebdbec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 0.01, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9051470588235293\n",
            "Test accuracy of best grid search hypers: 0.972972972972973\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instantiate an RBF SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "#param={'C':[1, 10, 100, 1000], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma': [0.001, 0.0001] }# when choose kernal they need a lot of time\n",
        "parameters = {'C':[0.01 ,0.1,1, 10, 100],'kernel': ['rbf'],'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
        "searcher = GridSearchCV(svm, parameters)\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters and the corresponding score\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSLZ7mLuZcWM",
        "outputId": "d2b0ab11-0473-4aa9-c267-ef4d940196ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:55] Features: 1/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:55] Features: 2/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 3/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 4/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 5/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 6/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 7/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 8/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 9/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 10/10 -- score: nan"
          ]
        }
      ],
      "source": [
        "# step forward feature selection\n",
        "\n",
        "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "sfs1 = SFS(LogisticRegression(), \n",
        "           k_features=10, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(np.array(X_train), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHmfvrMVZnZP",
        "outputId": "342662b8-e8da-4df4-97d5-40359948677f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9051470588235293\n",
            "Test accuracy of best grid search hypers: 0.972972972972973\n"
          ]
        }
      ],
      "source": [
        "\n",
        "logreg = LogisticRegression()\n",
        "# Create the hyperparameter grid\n",
        "\n",
        "c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "# Fit it to the training data\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "# Print the optimal parameters and best score\n",
        "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m_h1J7nAq8YE",
        "outputId": "0dbdb822-63d7-4a47-f009-2d406acda81b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>halstead_level</th>\n",
              "      <th>halstead_difficulty</th>\n",
              "      <th>halstead_effort</th>\n",
              "      <th>halstead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>0.27</td>\n",
              "      <td>3.70</td>\n",
              "      <td>214.81</td>\n",
              "      <td>11.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>0.12</td>\n",
              "      <td>8.33</td>\n",
              "      <td>783.33</td>\n",
              "      <td>43.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>8.33</td>\n",
              "      <td>1558.33</td>\n",
              "      <td>86.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>0.04</td>\n",
              "      <td>25.00</td>\n",
              "      <td>10575.00</td>\n",
              "      <td>587.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.32</td>\n",
              "      <td>3.13</td>\n",
              "      <td>100.00</td>\n",
              "      <td>5.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>11.11</td>\n",
              "      <td>3255.56</td>\n",
              "      <td>180.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>4.17</td>\n",
              "      <td>137.50</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>6</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.03</td>\n",
              "      <td>127.27</td>\n",
              "      <td>7.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>9</td>\n",
              "      <td>0.14</td>\n",
              "      <td>7.14</td>\n",
              "      <td>1607.14</td>\n",
              "      <td>89.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.67</td>\n",
              "      <td>9500.00</td>\n",
              "      <td>527.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     unique_operators  halstead_level  halstead_difficulty  halstead_effort  \\\n",
              "0                   6            0.27                 3.70           214.81   \n",
              "1                   8            0.12                 8.33           783.33   \n",
              "2                  12            0.12                 8.33          1558.33   \n",
              "3                  18            0.04                25.00         10575.00   \n",
              "4                   5            0.32                 3.13           100.00   \n",
              "..                ...             ...                  ...              ...   \n",
              "116                11            0.09                11.11          3255.56   \n",
              "117                 5            0.24                 4.17           137.50   \n",
              "118                 6            0.33                 3.03           127.27   \n",
              "119                 9            0.14                 7.14          1607.14   \n",
              "120                17            0.06                16.67          9500.00   \n",
              "\n",
              "     halstead_time  \n",
              "0            11.93  \n",
              "1            43.52  \n",
              "2            86.57  \n",
              "3           587.50  \n",
              "4             5.56  \n",
              "..             ...  \n",
              "116         180.86  \n",
              "117           7.64  \n",
              "118           7.07  \n",
              "119          89.29  \n",
              "120         527.78  \n",
              "\n",
              "[121 rows x 5 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from sklearn.feature_selection import mutual_info_classif\n",
        "# fs=SelectKBest(k=5, score_func=mutual_info_classif)\n",
        "# fs.fit(x,y)\n",
        "# mask=fs.get_support()\n",
        "# names=features[mask]\n",
        "# names\n",
        "# X_reduced=x[names]\n",
        "# X_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ9Cv3qxN_n4"
      },
      "source": [
        "# Que 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us2WgJoGOFNJ"
      },
      "source": [
        "Q5) For Datasets with multiple versions, does the accuracy improve when we use pre-release as training and pos-release as testing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UniSlRXB0RUZ",
        "outputId": "f4e3da60-f072-4203-eda6-6fe4bc45915a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(121, 30) (63, 30)\n"
          ]
        }
      ],
      "source": [
        "print(Data_1.shape,Data_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfniPge1GpyP",
        "outputId": "de51850b-a125-4d30-dff1-a76141ee84a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = Data_1\n",
        "test = Data_2\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypuclSRbG6iL"
      },
      "outputs": [],
      "source": [
        "x= train.iloc[:, 0:29]\n",
        "y= train.iloc[:,29]\n",
        "xt= test.iloc[:, 0:29]\n",
        "yt= test.iloc[:,29]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iqENOfEIFaN"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm =SVC(C=0.1, kernel='poly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baeKJNEqKXK5",
        "outputId": "e7e90b2c-dc4d-44b4-f325-b7046cfaf6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(121, 30) (63, 30) (107, 30) (36, 30) (101, 30) (498, 22)\n"
          ]
        }
      ],
      "source": [
        "print(Data_1.shape,Data_2.shape,Data_3.shape,Data_4.shape,Data_5.shape,Data_6.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfMZx0ttKHs-",
        "outputId": "99f571ba-e43f-41e9-9f13-361f08af67ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1036, 22) (920, 37) (753, 38) (780, 38)\n"
          ]
        }
      ],
      "source": [
        "print(Data_7.shape,Data_8.shape,Data_9.shape,Data_10.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "WHxB5UVmFQLy",
        "outputId": "6121f07e-e5d1-4dfc-bc1f-1b73c45bf39b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6b4d8d13309b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2421\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m     ):\n\u001b[0;32m-> 2043\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2044\u001b[0m             \u001b[0;34m\"test_size={0} should be either positive and smaller\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m             \u001b[0;34m\" than the number of samples {1} or a float in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: test_size=0 should be either positive and smaller than the number of samples 121 or a float in the (0, 1) range"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNsri_gnLrjd"
      },
      "outputs": [],
      "source": [
        "def readfiles(files, index, length):\n",
        "  for file1 in range(0,index):\n",
        "    if(file1 == index):\n",
        "      break;\n",
        "    train = pd.read_csv(files[file1])\n",
        "    test = pd.read_csv(files[file1 + 1])\n",
        "    X_train = train.iloc[:,:-1].values\n",
        "    y_train = train.iloc[:,length].values\n",
        "    X_test = test.iloc[:,:-1].values\n",
        "    y_test = test.iloc[:,length].values\n",
        "    \n",
        "    sc = StandardScaler()\n",
        "    sc.fit(X_train)\n",
        "    X_train_std = sc.transform(X_train)\n",
        "    X_test_std = sc.transform(X_test)\n",
        "    grid = LogisticRegression(C = 0.001,penalty='l1', solver='liblinear')\n",
        "    grid.fit(X_train_std, y_train)\n",
        "    y_pred = grid.predict(X_test_std)\n",
        "    print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GT_xWqGShjp"
      },
      "outputs": [],
      "source": [
        "arr_files = ['ar1.csv','ar3.csv', 'ar4.csv', 'ar5.csv', 'ar6.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2RHSyJhMCmG"
      },
      "outputs": [],
      "source": [
        "Datas=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ucKUw0RLt7w",
        "outputId": "a1ab9270-2935-4690-c9a4-6e78be84c876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        55\n",
            "        True       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.87        63\n",
            "   macro avg       0.44      0.50      0.47        63\n",
            "weighted avg       0.76      0.87      0.81        63\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.81      1.00      0.90        87\n",
            "        True       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.81       107\n",
            "   macro avg       0.41      0.50      0.45       107\n",
            "weighted avg       0.66      0.81      0.73       107\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      1.00      0.88        28\n",
            "        True       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.78        36\n",
            "   macro avg       0.39      0.50      0.44        36\n",
            "weighted avg       0.60      0.78      0.68        36\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      1.00      0.92        86\n",
            "        True       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.85       101\n",
            "   macro avg       0.43      0.50      0.46       101\n",
            "weighted avg       0.73      0.85      0.78       101\n",
            "\n"
          ]
        }
      ],
      "source": [
        "readfiles(arr_files,4,29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-UKwXnOP1O"
      },
      "source": [
        "# Que 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ntPvyCoOTzm"
      },
      "source": [
        "Q6) what are the necessary steps that you should take care when avoiding overfitting for both logistic regression and SVC?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie1tbCWLjBBk"
      },
      "outputs": [],
      "source": [
        "#soft margin where allow to slake variable to avoid overtfitting \n",
        "#c in LR reduce var so reduce overfitting on trining data and incrase bias"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v9wZkMplOeYn",
        "xzwMWM9xqUvb",
        "-aVpYCDMqeBi",
        "R4IA-bpiedFV",
        "oCV6UCctz0oC",
        "mfh_8nN7rsx4",
        "pxFKQxxcrsx5",
        "0RyrsDy3rsx-",
        "xoLy5a2krx2F",
        "Hb96igfhrx2G",
        "6Ndn1nuRrx2H",
        "1FOrmp49dv6V",
        "8ef9UGjItQyD",
        "xZycVLlntQyE",
        "hyjDzza-tQyF",
        "mvVVQr9UtRdY",
        "8yB2l1eTtRda",
        "iBbSe54ltRdd",
        "pRkLHSXPtR3E",
        "HDbT3vYvtR3F",
        "I8x4aXCJtR3H",
        "u1M6tPgmtSNo",
        "BnLmhNbqtSNo",
        "BuEouHmrtSNq",
        "WgMKSkvgvAtK",
        "NVxYq4gVtSk-",
        "FHlKIlU8tSk-",
        "PIi-S_sktSlD",
        "j9DDez5uwj1R",
        "2dOMgdOctS7D",
        "yMFy8d37tS7E",
        "EV6pVifmtS7G",
        "fZt_Odc1tTRG",
        "MSx4rqUotTRG",
        "Xyo_RcsdtTRH",
        "yJaajtqExLBa",
        "45DkjFOgMiNZ",
        "3I_dhf6KNzse",
        "bJ9Cv3qxN_n4",
        "5W-UKwXnOP1O"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}