{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viDuQA-anfNa"
      },
      "source": [
        "Problem 1 [50%]: Software defects datasets contain information about bugs in software modules (functions). Each dataset represents one software project with multiple modules. There are some datasets that are different releases for the same project. The features in the datasets describe the static code metrics in software modules where the output will be binary variable called defect (1= defected, 0=none-defected)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynh15kyvHNNk"
      },
      "outputs": [],
      "source": [
        "!pip install collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9HVZiwys2nxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.svm import SVC # search library of svm time smaal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection  import SelectKBest \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter\n",
        "from imblearn import over_sampling ,under_sampling\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "99MlDpWW2kUY"
      },
      "outputs": [],
      "source": [
        "Data_1= pd.read_csv('ar1.csv')\n",
        "Data_2= pd.read_csv('ar3.csv')\n",
        "Data_3= pd.read_csv('ar4.csv')\n",
        "Data_4= pd.read_csv('ar5.csv')\n",
        "Data_5= pd.read_csv('ar6.csv')\n",
        "Data_6= pd.read_csv('cm1.csv')\n",
        "Data_7= pd.read_csv('pc1.csv')\n",
        "Data_8= pd.read_csv('pc2.csv')\n",
        "Data_9= pd.read_csv('pc3.csv')\n",
        "Data_10= pd.read_csv('pc4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bGMZCDyQpvR"
      },
      "source": [
        "### QUE 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fisNTK3Qzeg1"
      },
      "outputs": [],
      "source": [
        "def SVM(Data):\n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "\n",
        "    #KFold k=10\n",
        "    folds=KFold(n_splits=10, shuffle=False) #10 Folds CV\n",
        "\n",
        "    for train_index, test_index in folds.split(x):\n",
        "      X_train=x.iloc[train_index]\n",
        "      X_test=x.iloc[test_index]\n",
        "      y_train=y.iloc[train_index]\n",
        "      y_test=y.iloc[test_index]\n",
        "      sc=StandardScaler()\n",
        "      sc.fit(X_train)\n",
        "      X_train_std=sc.transform(X_train)\n",
        "      X_test_std=sc.transform(X_test)\n",
        "      svm =SVC()#LibSVM()          #NuSVC()#SVC() # not have parameter c\n",
        "      # Instantiate the GridSearchCV object and run the search\n",
        "      parameters = {'C':[0.01 ,0.1,1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma':[ 0.001, 0.01, 0.1,1,10,100]}\n",
        "      searcher = GridSearchCV(svm, parameters)\n",
        "      s = searcher.fit(X_train_std, y_train)\n",
        "      \n",
        "      # Report the best parameters and the corresponding score\n",
        "      # print(\"Best CV params\", searcher.best_params_)\n",
        "      # print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "      # # Report the test accuracy using these best parameters\n",
        "    y_hat =s.predict(X_test_std) \n",
        "    print(y_hat.shape) \n",
        "    #print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test_std, y_test))\n",
        "    #print(\"Test accuracy of best grid search hypers:\", searcher.score(y_testy_hat, ))\n",
        "\n",
        "    # summarize results\n",
        "    print(\"\\n**** Best: %f using %s ****\\n\" % (s.best_score_, searcher.best_params_))\n",
        "    # Evaluating the accuracy of the model using the sklearn functions\n",
        "    accuracy = accuracy_score(y_test,y_hat )*100\n",
        "    confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "\n",
        "    # Printing the results\n",
        "    print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "    print( \"Classification report for %s\" % s)\n",
        "\n",
        "    print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "    print( metrics.confusion_matrix(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsI2Z-P8vR7"
      },
      "outputs": [],
      "source": [
        "def LogReg(Data): \n",
        "    col = list(Data.columns)[-1]\n",
        "    # x= Data.loc[:, Data.columns != col]\n",
        "    # y= Data.iloc[:,-1]\n",
        "    # x=Data.drop([col], axis=1)\n",
        "    # y=Data_1[col]\n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "    #KFold k=10\n",
        "    folds=KFold(n_splits=10, shuffle=True) #10 Folds CV\n",
        "    for train_index, test_index in folds.split(x):\n",
        "      X_train=x.iloc[train_index]\n",
        "      X_test=x.iloc[test_index]\n",
        "      #X_test=x.loc[test_index]\n",
        "      y_train=y.iloc[train_index]\n",
        "      y_test=y.iloc[test_index]\n",
        "      logreg = LogisticRegression()\n",
        "      # Create the hyperparameter grid\n",
        "      \n",
        "      c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "      param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "      logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "      # Fit it to the training data\n",
        "      l=logreg_cv.fit(X_train,y_train)\n",
        " \n",
        "      # # Report the test accuracy using these best parameters\n",
        "    y_hat =l.predict(X_test) \n",
        "    print(y_hat.shape) \n",
        "\n",
        "\n",
        "    # summarize results\n",
        "    print(\"\\n**** Best: %f using %s ****\\n\" % (l.best_score_, l.best_params_))\n",
        "    # Evaluating the accuracy of the model using the sklearn functions\n",
        "    accuracy = accuracy_score(y_test,y_hat )*100\n",
        "    confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "\n",
        "    # Printing the results\n",
        "    print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print( \"Classification report for %s\" % l)\n",
        "\n",
        "    print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "    print( metrics.confusion_matrix(y_test,y_hat ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7vXK6pMC1dG",
        "outputId": "4b961359-82e0-49e4-ce8b-551cb636e7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Data 2\n",
            "Support Vector Classifier \n",
            "(6,)\n",
            "\n",
            "**** Best: 0.930303 using {'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'} ****\n",
            "\n",
            "Accuracy for SVM is: 66.66666666666666\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.60      1.00      0.75         3\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.80      0.67      0.62         6\n",
            "weighted avg       0.80      0.67      0.62         6\n",
            "\n",
            "[[3 0]\n",
            " [2 1]]\n",
            "Logistic Regression\n",
            "(6,)\n",
            "\n",
            "**** Best: 0.898485 using {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00         5\n",
            "        True       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "[[5 0]\n",
            " [0 1]]\n",
            "\n",
            " Data 3\n",
            "Support Vector Classifier \n",
            "(10,)\n",
            "\n",
            "**** Best: 0.876842 using {'C': 1, 'gamma': 0.1, 'kernel': 'poly'} ****\n",
            "\n",
            "Accuracy for SVM is: 90.0\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95         9\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.45      0.50      0.47        10\n",
            "weighted avg       0.81      0.90      0.85        10\n",
            "\n",
            "[[9 0]\n",
            " [1 0]]\n",
            "Logistic Regression\n",
            "(10,)\n",
            "\n",
            "**** Best: 0.866316 using {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "[[10]]\n",
            "\n",
            " Data 4\n",
            "Support Vector Classifier \n",
            "(3,)\n",
            "\n",
            "**** Best: 0.938095 using {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'} ****\n",
            "\n",
            "Accuracy for SVM is: 33.33333333333333\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.33      1.00      0.50         1\n",
            "        True       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "[[1 0]\n",
            " [2 0]]\n",
            "Logistic Regression\n",
            "(3,)\n",
            "\n",
            "**** Best: 0.900000 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'} ****\n",
            "\n",
            "Accuracy for Logistic is: 100.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "[[3]]\n",
            "\n",
            " Data 5\n",
            "Support Vector Classifier \n",
            "(10,)\n",
            "\n",
            "**** Best: 0.901754 using {'C': 1, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 100.0\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "[[10]]\n",
            "Logistic Regression\n",
            "(10,)\n",
            "\n",
            "**** Best: 0.890643 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} ****\n",
            "\n",
            "Accuracy for Logistic is: 80.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.88      0.88         8\n",
            "        True       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.80        10\n",
            "   macro avg       0.69      0.69      0.69        10\n",
            "weighted avg       0.80      0.80      0.80        10\n",
            "\n",
            "[[7 1]\n",
            " [1 1]]\n",
            "\n",
            " Data 6\n",
            "Support Vector Classifier \n",
            "(49,)\n",
            "\n",
            "**** Best: nan using {'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 2.0408163265306123\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.02      1.00      0.04         1\n",
            "        True       0.00      0.00      0.00        48\n",
            "\n",
            "    accuracy                           0.02        49\n",
            "   macro avg       0.01      0.50      0.02        49\n",
            "weighted avg       0.00      0.02      0.00        49\n",
            "\n",
            "[[ 1  0]\n",
            " [48  0]]\n",
            "Logistic Regression\n",
            "(49,)\n",
            "\n",
            "**** Best: 0.899775 using {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 91.83673469387756\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      1.00      0.96        45\n",
            "        True       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.92        49\n",
            "   macro avg       0.46      0.50      0.48        49\n",
            "weighted avg       0.84      0.92      0.88        49\n",
            "\n",
            "[[45  0]\n",
            " [ 4  0]]\n",
            "\n",
            " Data 7\n",
            "Support Vector Classifier \n",
            "(92,)\n",
            "\n",
            "**** Best: 0.996386 using {'C': 0.01, 'gamma': 0.01, 'kernel': 'linear'} ****\n",
            "\n",
            "Accuracy for SVM is: 98.91304347826086\n",
            "Classification report for GridSearchCV(estimator=SVC(),\n",
            "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
            "                         'gamma': [0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      0.99        91\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        92\n",
            "   macro avg       0.49      0.50      0.50        92\n",
            "weighted avg       0.98      0.99      0.98        92\n",
            "\n",
            "[[91  0]\n",
            " [ 1  0]]\n",
            "Logistic Regression\n",
            "(92,)\n",
            "\n",
            "**** Best: 0.996378 using {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'} ****\n",
            "\n",
            "Accuracy for Logistic is: 98.91304347826086\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      0.99        91\n",
            "        True       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99        92\n",
            "   macro avg       0.49      0.50      0.50        92\n",
            "weighted avg       0.98      0.99      0.98        92\n",
            "\n",
            "[[91  0]\n",
            " [ 1  0]]\n",
            "\n",
            " Data 8\n",
            "Support Vector Classifier \n"
          ]
        }
      ],
      "source": [
        "Datasets=[Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]\n",
        "c = 2\n",
        "for i in Datastes:\n",
        " \n",
        "  print(f\"\\n Data {c}\")\n",
        "  print(\"Support Vector Classifier \")\n",
        "  SVM(i)\n",
        "  print(\"Logistic Regression\")\n",
        "  LogReg(i)\n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIsC6yHaoPfE"
      },
      "outputs": [],
      "source": [
        "SVM(Data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uasTD_Rq9ISP",
        "outputId": "d15b6004-eb75-4553-d23c-668d8c690856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12,)\n",
            "\n",
            "**** Best: 0.945022 using {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'} ****\n",
            "\n",
            "Accuracy for SVM is: 75.0\n",
            "Classification report for GridSearchCV(estimator=LogisticRegression(),\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
            "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
            "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
            "                                    'newton-cholesky', 'sag', 'saga']})\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.75      1.00      0.86         9\n",
            "        True       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.75        12\n",
            "   macro avg       0.38      0.50      0.43        12\n",
            "weighted avg       0.56      0.75      0.64        12\n",
            "\n",
            "[[9 0]\n",
            " [3 0]]\n"
          ]
        }
      ],
      "source": [
        "LogReg(Data_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9wZkMplOeYn"
      },
      "source": [
        "# *Problem 1*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9r-rzEeIqD9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.svm import SVC # search library of svm time smaal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection  import SelectKBest \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfjGU1yKIbNR"
      },
      "outputs": [],
      "source": [
        "# Problem 1 [50%]: Software defects datasets contain information about bugs in software\n",
        "# modules (functions). Each dataset represents one software project with multiple modules.\n",
        "# There are some datasets that are different releases for the same project. The features in\n",
        "# the datasets describe the static code metrics in software modules where the output will\n",
        "# be binary variable called defect (1= defected, 0=none-defected)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8RZ6YzpndUN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjR_Cb-SItbl"
      },
      "outputs": [],
      "source": [
        "Data_1= pd.read_csv('ar1.csv')\n",
        "Data_2= pd.read_csv('ar3.csv')\n",
        "Data_3= pd.read_csv('ar4.csv')\n",
        "Data_4= pd.read_csv('ar5.csv')\n",
        "Data_5= pd.read_csv('ar6.csv')\n",
        "Data_6= pd.read_csv('cm1.csv')\n",
        "Data_7= pd.read_csv('pc1.csv')\n",
        "Data_8= pd.read_csv('pc2.csv')\n",
        "Data_9= pd.read_csv('pc3.csv')\n",
        "Data_10= pd.read_csv('pc4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXdWKjj8EcoU"
      },
      "outputs": [],
      "source": [
        "col = list(Data_1.columns)[-1]\n",
        "x= Data_1.loc[:, Data_1.columns != col]\n",
        "y= Data_1.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60NBuOUYFNy5",
        "outputId": "8524c0cb-e22b-48a6-cb00-f87a64cab5b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 29)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G9a4Ce6FPOb",
        "outputId": "9287e987-5231-4118-d4d2-5585f50d85e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121,)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tadXCcoMJrTn",
        "outputId": "7f0089ce-5831-4771-d03f-f188360378d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      True\n",
              "1     False\n",
              "2     False\n",
              "3     False\n",
              "4     False\n",
              "      ...  \n",
              "58     True\n",
              "59    False\n",
              "60    False\n",
              "61    False\n",
              "62     True\n",
              "Name: defects, Length: 63, dtype: bool"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3G5XnOc32bFN",
        "outputId": "a86ab9b5-8ddf-4d15-b9fb-89be56caea39"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_loc</th>\n",
              "      <th>blank_loc</th>\n",
              "      <th>comment_loc</th>\n",
              "      <th>code_and_comment_loc</th>\n",
              "      <th>executable_loc</th>\n",
              "      <th>unique_operands</th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>total_operands</th>\n",
              "      <th>total_operators</th>\n",
              "      <th>halstead_vocabulary</th>\n",
              "      <th>...</th>\n",
              "      <th>call_pairs</th>\n",
              "      <th>condition_count</th>\n",
              "      <th>multiple_condition_count</th>\n",
              "      <th>cyclomatic_complexity</th>\n",
              "      <th>cyclomatic_density</th>\n",
              "      <th>decision_density</th>\n",
              "      <th>design_complexity</th>\n",
              "      <th>design_density</th>\n",
              "      <th>normalized_cyclomatic_complexity</th>\n",
              "      <th>formal_parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.47</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>33</td>\n",
              "      <td>56</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>44</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>58</td>\n",
              "      <td>91</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bbb731e-64cc-43ee-9bc8-e0ad31babf41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     total_loc  blank_loc  comment_loc  code_and_comment_loc  executable_loc  \\\n",
              "0            7          0            4                     0               3   \n",
              "1            9          0            1                     0               8   \n",
              "2           21          0           14                     1               7   \n",
              "3           30          0           11                     0              19   \n",
              "4            8          0            2                     0               6   \n",
              "..         ...        ...          ...                   ...             ...   \n",
              "116         32          0            5                     0              27   \n",
              "117          6          0            0                     0               6   \n",
              "118          6          0            0                     0               6   \n",
              "119         27          0            3                     0              24   \n",
              "120         51          2           12                     0              37   \n",
              "\n",
              "     unique_operands  unique_operators  total_operands  total_operators  \\\n",
              "0                  8                 6              10               12   \n",
              "1                  7                 8              15               20   \n",
              "2                 15                12              21               36   \n",
              "3                 16                18              50               70   \n",
              "4                  4                 5               5               10   \n",
              "..               ...               ...             ...              ...   \n",
              "116               16                11              33               56   \n",
              "117                3                 5               5               11   \n",
              "118                6                 6               6               11   \n",
              "119               16                 9              26               44   \n",
              "120               29                17              58               91   \n",
              "\n",
              "     halstead_vocabulary  ...  call_pairs  condition_count  \\\n",
              "0                     14  ...           0                0   \n",
              "1                     15  ...           0                0   \n",
              "2                     27  ...           1                4   \n",
              "3                     34  ...           1                9   \n",
              "4                      9  ...           1                1   \n",
              "..                   ...  ...         ...              ...   \n",
              "116                   27  ...           0                9   \n",
              "117                    8  ...           0                2   \n",
              "118                   12  ...           1                2   \n",
              "119                   25  ...           1                8   \n",
              "120                   46  ...           4               17   \n",
              "\n",
              "     multiple_condition_count  cyclomatic_complexity  cyclomatic_density  \\\n",
              "0                           0                      1                0.33   \n",
              "1                           0                      2                0.25   \n",
              "2                           1                      4                0.57   \n",
              "3                           2                      9                0.47   \n",
              "4                           0                      2                0.33   \n",
              "..                        ...                    ...                 ...   \n",
              "116                         1                      8                0.30   \n",
              "117                         0                      3                0.50   \n",
              "118                         1                      2                0.33   \n",
              "119                         3                      6                0.25   \n",
              "120                         3                     14                0.38   \n",
              "\n",
              "     decision_density  design_complexity  design_density  \\\n",
              "0                0.00                  0            0.00   \n",
              "1                0.00                  0            0.00   \n",
              "2                1.00                  1            0.25   \n",
              "3                1.11                  1            0.11   \n",
              "4                1.00                  1            0.50   \n",
              "..                ...                ...             ...   \n",
              "116              1.00                  0            0.00   \n",
              "117              1.00                  0            0.00   \n",
              "118              1.00                  1            0.50   \n",
              "119              1.00                  1            0.17   \n",
              "120              1.00                  4            0.29   \n",
              "\n",
              "     normalized_cyclomatic_complexity  formal_parameters  \n",
              "0                                0.14                  0  \n",
              "1                                0.22                  0  \n",
              "2                                0.19                  0  \n",
              "3                                0.30                  0  \n",
              "4                                0.25                  0  \n",
              "..                                ...                ...  \n",
              "116                              0.25                  0  \n",
              "117                              0.50                  0  \n",
              "118                              0.33                  0  \n",
              "119                              0.22                  0  \n",
              "120                              0.27                  1  \n",
              "\n",
              "[121 rows x 29 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col = list(Data_1.columns)[-1]\n",
        "x= Data_1.loc[:, Data_1.columns != col]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c40cTu7zJpNB"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance of Support Vector Classifier and Logistic Regression, using\n",
        "# 10-Folds cross validation on each single dataset? Describe the best parameters for both\n",
        "# algorithms and what is the impact of other parameters? Do all datasets share the same\n",
        "# configuration settings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwyvvZL21-9z"
      },
      "outputs": [],
      "source": [
        "# Paramerter C:\n",
        "\n",
        "# Large Value of parameter C => small margin\n",
        "\n",
        "# Small Value of paramerter C => Large margin\n",
        "\n",
        "# Gamma:\n",
        "\n",
        "# Gamma high means more curvature.\n",
        "\n",
        "# Gamma low means less curvature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45DkjFOgMiNZ"
      },
      "source": [
        "# Que 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2llBdUaMmn3"
      },
      "source": [
        "Q2) What is the impact of class imbalance on your results, and which is the best evaluation measure should be used in this case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btdNKkhhMtjz"
      },
      "outputs": [],
      "source": [
        "#i can't correctly identify the accuracy   -- > can evaliatuion using f measure "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOO7ejRWgtCz",
        "outputId": "8d7896b9-8570-415a-c026-b0fd7c0a8774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data 1 imbalance -- > class :True = 9 and False = 112\n",
            "Data 2 imbalance -- > class :True = 8 and False = 55\n",
            "Data 3 imbalance -- > class :True = 20 and False = 87\n",
            "Data 4 imbalance -- > class :True = 8 and False = 28\n",
            "Data 5 imbalance -- > class :True = 15 and False = 86\n",
            "Data 6 imbalance -- > class :True = 49 and False = 449\n",
            "Data 7 imbalance -- > class :True = 77 and False = 959\n",
            "Data 8 imbalance -- > class :True = 4 and False = 916\n",
            "Data 9 imbalance -- > class :True = 70 and False = 683\n",
            "Data 10 imbalance -- > class :True = 87 and False = 693\n"
          ]
        }
      ],
      "source": [
        "print(\"Data 1 imbalance -- > class :True =\",sum(Data_1['defects']==True) ,\"and False =\",sum(Data_1['defects']==False))\n",
        "print(\"Data 2 imbalance -- > class :True =\",sum(Data_2['defects']==True) ,\"and False =\",sum(Data_2['defects']==False))\n",
        "print(\"Data 3 imbalance -- > class :True =\",sum(Data_3['defects']==True) ,\"and False =\",sum(Data_3['defects']==False))\n",
        "print(\"Data 4 imbalance -- > class :True =\",sum(Data_4['defects']==True) ,\"and False =\",sum(Data_4['defects']==False))\n",
        "print(\"Data 5 imbalance -- > class :True =\",sum(Data_5['defects']==True) ,\"and False =\",sum(Data_5['defects']==False))\n",
        "print(\"Data 6 imbalance -- > class :True =\",sum(Data_6['defects']==True) ,\"and False =\",sum(Data_6['defects']==False))\n",
        "print(\"Data 7 imbalance -- > class :True =\",sum(Data_7['defects']==True) ,\"and False =\",sum(Data_7['defects']==False))\n",
        "print(\"Data 8 imbalance -- > class :True =\",sum(Data_8['defects']==True) ,\"and False =\",sum(Data_8['defects']==False))\n",
        "print(\"Data 9 imbalance -- > class :True =\",sum(Data_9['defects']==True) ,\"and False =\",sum(Data_9['defects']==False))\n",
        "print(\"Data 10 imbalance -- > class :True =\",sum(Data_10['defects']==True) ,\"and False =\",sum(Data_10['defects']==False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlHqwNlKiX41",
        "outputId": "a4068b07-2916-4ad1-f149-4986d328c256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM is: 89.1891891891892\n",
            "Classification report for SVC(C=1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.97      0.94        34\n",
            "        True       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.89        37\n",
            "   macro avg       0.46      0.49      0.47        37\n",
            "weighted avg       0.84      0.89      0.87        37\n",
            "\n",
            "[[33  1]\n",
            " [ 3  0]]\n"
          ]
        }
      ],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "# Making the SVM Classifer\n",
        "Classifier = SVC(C=1)\n",
        "\n",
        "# Training the model on the training data and labels\n",
        "Classifier.fit(X_train, y_train)\n",
        "\n",
        "# Using the model to predict the labels of the test data\n",
        "y_pred = Classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the accuracy of the model using the sklearn functions\n",
        "accuracy = accuracy_score(y_test,y_pred)*100\n",
        "confusion_mat = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "\n",
        "\n",
        "# performance\n",
        "print( \"Classification report for %s\" % Classifier)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "print( metrics.confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqvuwnoLkUvi"
      },
      "outputs": [],
      "source": [
        "#accuracy = 0.89 , f1= 0.47 (macro avg of f1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5WUqLRVNrsU"
      },
      "source": [
        "# Que 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ym-I9nNwdn"
      },
      "source": [
        "Q3) Which class imbalance learning technique could work efficiently with these datasets? Show your evidence from the experiments?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u7OG37GIc2d",
        "outputId": "9dcb7db8-6eaf-4a84-d756-f24120f8f4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False, True]\n",
            "Number labels equal True : (8, 30) Number labels equal False : (55, 30)\n"
          ]
        }
      ],
      "source": [
        "print(sorted(Counter(Data_2[list(Data_2.columns)[-1]])))\n",
        "label_one=Data_2[Data_2[list(Data_2.columns)[-1]]==True]\n",
        "label_two=Data_2[Data_2[list(Data_2.columns)[-1]]==False]\n",
        "print(\"Number labels equal True :\",label_one.shape,\"Number labels equal False :\",label_two.shape)\n",
        "col = list(Data_2.columns)[-1]\n",
        "x= Data_2.loc[:, Data_2.columns != col]\n",
        "y= Data_2.iloc[:,-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgOFQZ1u9rAK"
      },
      "outputs": [],
      "source": [
        "Datasets=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrTrq3Sw---i"
      },
      "outputs": [],
      "source": [
        "dic_LR={ \n",
        " 1:[ 0.001,  'l1',  'saga' ],\n",
        " 2:[ 0.001, 'l1',  'liblinear'],   \n",
        " 3:[ 0.01, 'l1',  'liblinear'],\n",
        " 4:[ 0.1,  'l2',  'liblinear'],\n",
        " 5:[ 0.001, 'l2',  'liblinear'],\n",
        " 6:[ 0.001, 'l1',  'liblinear'],\n",
        " 7:[ 0.001,  'l2', 'newton-cg'],\n",
        " 8:[ 0.001, 'l1',  'liblinear'],\n",
        " 9:[ 0.01,  'l2',  'newton-cg'],\n",
        " 10:[ 0.01,  'l2',  'newton-cg']}\n",
        "\n",
        "\n",
        "\n",
        "dic_svm={  \n",
        " 1:[0.01,  0.001,  'linear'],\n",
        " 2:[ 0.1,  0.1,  'poly'],  \n",
        "  3:[ 0.1,  0.1,  'poly'], \n",
        "  4:[ 100,  0.01,  'rbf'],\n",
        " 5:[ 1,  0.001,  'linear'],\n",
        "  6:[ 0.1,  0.01,  'sigmoid'],\n",
        "  7:[ 10,  10,  'rbf'],\n",
        "  8:[ 10,  0.01,  'sigmoid'],\n",
        "  9:[ 10,  0.1,  'rbf'],\n",
        "  10:[10,  0.01, 'rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UP97G7ub-xc"
      },
      "outputs": [],
      "source": [
        "def check(Data):\n",
        "  print(sorted(Counter(Data[list(Data.columns)[-1]])))\n",
        "  label_one=Data[Data[list(Data.columns)[-1]]==True]\n",
        "  label_two=Data[Data[list(Data.columns)[-1]]==False]\n",
        "  print(\"Number labels equal True :\",label_one.shape,\"Number labels equal False :\",label_two.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWAr6GQ5aRA0"
      },
      "outputs": [],
      "source": [
        "def UnderOver_sampling(Data):   \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "  rus=RandomUnderSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay undersampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)\n",
        "  ros=RandomOverSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay oversampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoQ5rsGj_l9b"
      },
      "outputs": [],
      "source": [
        "def UnderOver_sampling(Data,i):  \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "\n",
        "  rus=RandomUnderSampler(random_state=0)\n",
        "  x_resampled,y_resampled = rus.fit_resample(x,y)\n",
        "  print(\" when applay undersampling =\",sorted(Counter(y_resampled).items()),y_resampled.shape)\n",
        "\n",
        "  ros=RandomOverSampler(random_state=0)\n",
        "  x_resampled_over,y_resampled_over = rus.fit_resample(x,y)\n",
        "  print(\" when applay oversampling =\",sorted(Counter(y_resampled_over).items()),y_resampled_over.shape)\n",
        "\n",
        "  print(\" when applay undersampling on SVM =\")\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x_resampled,y_resampled )\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel = dic_svm[i][2])\n",
        "  s=svm.fit(X_train_std , y_train)\n",
        "  y_hat=s.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogReg(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train, y_train)\n",
        "  y_hat=l.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztRsWDr3GJDR"
      },
      "outputs": [],
      "source": [
        "\n",
        "  \n",
        "  print(\" when applay Oversampling on SVM =\")\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x_resampled_over,y_resampled_over )\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  X_train_smote , y_train_smote = oversample.fit_resample(X_train,y_train)\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel = dic_svm[i][2])\n",
        "  s=svm.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogReg(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTNpNarGDUyw"
      },
      "outputs": [],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  UnderOver_sampling(i,c)\n",
        "  c+=1\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr7PMzKbBfH2"
      },
      "outputs": [],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  check(i)\n",
        "  print(\"After apply under and over sampling :\")\n",
        "  UnderOver_sampling(i,c)\n",
        "  print(\"After applay SMOTE\")\n",
        " \n",
        "  c+=1 \n",
        "\n",
        "\n",
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  UnderOver_sampling((i,c)\n",
        "\n",
        " \n",
        "  c+=1   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsucwfIepT7E"
      },
      "outputs": [],
      "source": [
        "smote=SMOTE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jShh4Fbrx5Oj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoQ7SIJgyZEh"
      },
      "outputs": [],
      "source": [
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjwhRw3zE9pE"
      },
      "outputs": [],
      "source": [
        "C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernal = dic_svm[i][2]\n",
        "C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaMiiFeY7p25"
      },
      "outputs": [],
      "source": [
        "def Over_smote(Data,i):  \n",
        "  col = list(Data.columns)[-1]\n",
        "  x= Data.loc[:, Data.columns != col]\n",
        "  y= Data.iloc[:,-1]\n",
        "  X_train ,X_test ,y_train , y_test =train_test_split(x,y)\n",
        "  sc=StandardScaler()\n",
        "  sc.fit(X_train)\n",
        "  X_train_std=sc.transform(X_train)\n",
        "  X_test_std=sc.transform(X_test)\n",
        "  X_train_smote , y_train_smote = oversample.fit_resample(X_train_std,y_train)\n",
        "  print('Befor SMOTE :',Counter(y_train))\n",
        "  print('After SMOTE :',Counter(y_train_smote))\n",
        "  print('SVM in Balance data')\n",
        "  svm =SVC(C=dic_svm[i][0], gamma=dic_svm[i][1] ,kernel= dic_svm[i][2])\n",
        "  s=svm.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=s.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for SVM is:\",accuracy)\n",
        "  print( \"Classification report for %s\" % s)\n",
        "  print(metrics.classification_report(y_test,y_hat ))\n",
        "  print('Logistic Regression in Balance data')\n",
        "  LR=LogisticRegression(C=dic_LR[i][0], penalty=dic_LR[i][1], solver =dic_LR[i][2])\n",
        "  l=LR.fit(X_train_smote , y_train_smote)\n",
        "  y_hat=l.predict(X_test_std)\n",
        "  accuracy = accuracy_score(y_test,y_hat )*100\n",
        "  confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "  # Printing the results\n",
        "  print(\"Accuracy for Logistic Regression  is:\",accuracy)\n",
        "  print(\"Classification report for %s\" % l)\n",
        "  print(metrics.classification_report(y_test,y_hat ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JL---gjJFQ0"
      },
      "outputs": [],
      "source": [
        "oversample = SMOTE(k_neighbors=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcK6eHRh8t6W"
      },
      "outputs": [],
      "source": [
        "Datasets=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6,Data_7,Data_8,Data_9,Data_10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L7niy4S9w8W",
        "outputId": "3c14bbf4-9f4f-41b6-a775-886fb8c3ab04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpAMyJVa8NeW"
      },
      "outputs": [],
      "source": [
        "c = 1\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  Over_smote(i,c)\n",
        "\n",
        " \n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keQIUrs9J_Ih",
        "outputId": "a5c0b4df-8e53-481b-a9ff-16e06c90b501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Befor SMOTE : Counter({False: 42, True: 5})\n",
            "After SMOTE : Counter({False: 42, True: 42})\n",
            "SVM in balance data\n",
            "Accuracy for SVM is: 87.5\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        13\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.93      0.67      0.71        16\n",
            "weighted avg       0.89      0.88      0.85        16\n",
            "\n",
            "Accuracy for SVM is: 87.5\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        13\n",
            "        True       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.93      0.67      0.71        16\n",
            "weighted avg       0.89      0.88      0.85        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "col = list(Data_2.columns)[-1]\n",
        "x= Data_2.loc[:, Data_2.columns != col]\n",
        "y= Data_2.iloc[:,-1]\n",
        "X_train ,X_test ,y_train , y_test =train_test_split(x,y)\n",
        "sc=StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std=sc.transform(X_train)\n",
        "X_test_std=sc.transform(X_test)\n",
        "X_train_smote , y_train_smote = oversample.fit_resample(X_train_std,y_train)\n",
        "print('Befor SMOTE :',Counter(y_train))\n",
        "print('After SMOTE :',Counter(y_train_smote))\n",
        "print('SVM in balance data')\n",
        "svm =SVC(C=dic_svm[2][0], gamma=dic_svm[2][1] ,kernel= dic_svm[2][2])\n",
        "s=svm.fit(X_train_smote , y_train_smote)\n",
        "y_hat=s.predict(X_test_std)\n",
        "accuracy = accuracy_score(y_test,y_hat )*100\n",
        "confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "print( \"Classification report for %s\" % s)\n",
        "print(metrics.classification_report(y_test,y_hat ))\n",
        "\n",
        "LR=LogisticRegression(C=dic_LR[2][0], penalty=dic_LR[2][1], solver =dic_LR[2][2])\n",
        "l=LR.fit(X_train_smote , y_train_smote)\n",
        "y_hat=s.predict(X_test_std)\n",
        "accuracy = accuracy_score(y_test,y_hat )*100\n",
        "confusion_mat = confusion_matrix(y_test,y_hat )\n",
        "# Printing the results\n",
        "print(\"Accuracy for SVM is:\",accuracy)\n",
        "print( \"Classification report for %s\" % l)\n",
        "print(metrics.classification_report(y_test,y_hat ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beSPPxA2IX2C",
        "outputId": "bb5266c7-c88a-4b2c-c019-a4029b065100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Befor SMOTE : Counter({False: 41, True: 6})\n",
            "After SMOTE : Counter({False: 41, True: 41})\n",
            "SVM in Balance data\n",
            "Accuracy for SVM is: 100.0\n",
            "Classification report for SVC(C=0.1, gamma=0.1, kernel='poly')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        14\n",
            "        True       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n",
            "Logistic Regression in Balance data\n",
            "Accuracy for Logistic Regression  is: 100.0\n",
            "Classification report for LogisticRegression(C=0.001, penalty='l1', solver='liblinear')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00        14\n",
            "        True       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Over_smote(Data_2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMcCYJSUkyBv"
      },
      "outputs": [],
      "source": [
        "c = 2\n",
        "for i in Datasets:\n",
        "  print(f\"\\n Data {c}\")\n",
        "  check(i)\n",
        "  print(\"After apply under and over sampling :\")\n",
        "  UnderOver_sampling(i)\n",
        "  print(\"After applay SMOTE\")\n",
        " \n",
        "  c+=1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I_dhf6KNzse"
      },
      "source": [
        "# Que 4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noUCRBMNN2j8"
      },
      "source": [
        "Q4) Is there improvement when apply feature selection? Which features do you think are the most predictive ones? Explain the way you have decided to select the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML-pCVcRqqXI"
      },
      "outputs": [],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7mps7gTqyhL",
        "outputId": "0a8364cd-780c-4578-a8fc-9bfacd8d9a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_udNxErqrim",
        "outputId": "27d9cd0c-427b-4c5a-8433-bd2c909a0d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['total_loc', 'blank_loc', 'comment_loc', 'code_and_comment_loc',\n",
              "       'executable_loc', 'unique_operands', 'unique_operators',\n",
              "       'total_operands', 'total_operators', 'halstead_vocabulary',\n",
              "       'halstead_length', 'halstead_volume', 'halstead_level',\n",
              "       'halstead_difficulty', 'halstead_effort', 'halstead_error',\n",
              "       'halstead_time', 'branch_count', 'decision_count', 'call_pairs',\n",
              "       'condition_count', 'multiple_condition_count', 'cyclomatic_complexity',\n",
              "       'cyclomatic_density', 'decision_density', 'design_complexity',\n",
              "       'design_density', 'normalized_cyclomatic_complexity',\n",
              "       'formal_parameters'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features= x.columns\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERPOweLMO6oI",
        "outputId": "6cf594cb-2369-4b5e-f3c7-b4f59eabd6ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaaqcoP1XQKq"
      },
      "source": [
        "Forward Selection Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y9jDRleBc3J",
        "outputId": "0393c01c-ce71-4f5c-b2e3-81ab53173569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxfCQrxkVXCU",
        "outputId": "d18db9c3-a599-4010-f258-278882179570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# I changed this part\n",
        "!pip install mlxtend\n",
        "import joblib\n",
        "import sys\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKDzFHQUBu7M"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNfELQXTSWp-"
      },
      "outputs": [],
      "source": [
        "sfs1 = SFS(RandomForestRegressor(), \n",
        "           k_features=10, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(np.array(X_train), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXvrM1K1tgBe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9tNv58ATQ-K",
        "outputId": "11704987-f20b-47b2-c585-6ec85a9fd1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correlated features:  19\n"
          ]
        }
      ],
      "source": [
        "x=Data_1.drop(['defects'], axis=1)\n",
        "y=Data_1['defects']\n",
        "X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "# find and remove correlated features\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', len(set(corr_features)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RNavqLu_Vqp"
      },
      "outputs": [],
      "source": [
        "def correlation(dataset, threshold):   \n",
        "    col = list(Data.columns)[-1]\n",
        "    x= Data.loc[:, Data.columns != col]\n",
        "    y= Data.iloc[:,-1]\n",
        "    X_train, X_test, y_train, y_test= train_test_split(x,y,test_size=0.3)\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', len(set(corr_features)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atcO6AJrTYMQ",
        "outputId": "129a86cb-96bf-4af1-8785-c135b89ae3b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((84, 10), (37, 10))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removed correlated  features\n",
        "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHT2ruuyTyCi",
        "outputId": "6b35eda1-5fb2-4c00-cdf8-93bea98e2b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 1/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 2/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 3/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:18] Features: 4/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 5/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 6/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 7/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 8/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 9/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "\n",
            "[2023-01-02 21:31:19] Features: 10/10 -- score: nan"
          ]
        }
      ],
      "source": [
        "# step forward feature selection\n",
        "\n",
        "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "def fetureSelection():\n",
        "  sfs1 = SFS(SVC(), \n",
        "            k_features=10, \n",
        "            forward=True, \n",
        "            floating=False, \n",
        "            verbose=2,\n",
        "            scoring='r2',\n",
        "            cv=3)\n",
        "\n",
        "  sfs1 = sfs1.fit(np.array(X_train), y_train)\n",
        "  print(sfs1.k_feature_idx_)\n",
        "  print(X_train.columns[list(sfs1.k_feature_idx_)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJRlHNx4V3sY",
        "outputId": "4c52775d-0802-4b23-b32c-13e9d1baff96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sfs1.k_feature_idx_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxj80A1cV8SS",
        "outputId": "16ca8965-4d98-4c65-b661-12f445c2bdf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['total_loc', 'blank_loc', 'code_and_comment_loc', 'unique_operators',\n",
              "       'halstead_level', 'call_pairs', 'cyclomatic_density',\n",
              "       'decision_density', 'design_density', 'formal_parameters'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.columns[list(sfs1.k_feature_idx_)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtPYZ1tWAiy",
        "outputId": "b7c2d3b3-3d54-4d96-e334-ff15bebdbec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV params {'C': 0.01, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
            "Best CV accuracy 0.9051470588235293\n",
            "Test accuracy of best grid search hypers: 0.972972972972973\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instantiate an RBF SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Instantiate the GridSearchCV object and run the search\n",
        "#param={'C':[1, 10, 100, 1000], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'gamma': [0.001, 0.0001] }# when choose kernal they need a lot of time\n",
        "parameters = {'C':[0.01 ,0.1,1, 10, 100],'kernel': ['rbf'],'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
        "searcher = GridSearchCV(svm, parameters)\n",
        "searcher.fit(X_train, y_train)\n",
        "\n",
        "# Report the best parameters and the corresponding score\n",
        "print(\"Best CV params\", searcher.best_params_)\n",
        "print(\"Best CV accuracy\", searcher.best_score_)\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSLZ7mLuZcWM",
        "outputId": "d2b0ab11-0473-4aa9-c267-ef4d940196ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:55] Features: 1/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:55] Features: 2/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 3/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 4/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 5/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 6/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:56] Features: 7/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 8/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 9/10 -- score: nan[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
            "\n",
            "[2023-01-02 21:31:57] Features: 10/10 -- score: nan"
          ]
        }
      ],
      "source": [
        "# step forward feature selection\n",
        "\n",
        "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "sfs1 = SFS(LogisticRegression(), \n",
        "           k_features=10, \n",
        "           forward=True, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='r2',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(np.array(X_train), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHmfvrMVZnZP",
        "outputId": "342662b8-e8da-4df4-97d5-40359948677f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameter: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Tuned Logistic Regression Accuracy: 0.9051470588235293\n",
            "Test accuracy of best grid search hypers: 0.972972972972973\n"
          ]
        }
      ],
      "source": [
        "\n",
        "logreg = LogisticRegression()\n",
        "# Create the hyperparameter grid\n",
        "\n",
        "c_space = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "param_grid = {'C':c_space, 'penalty': ['l1', 'l2','elasticnet', None],'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']}\n",
        "logreg_cv = GridSearchCV(logreg,param_grid)\n",
        "# Fit it to the training data\n",
        "logreg_cv.fit(X_train,y_train)\n",
        "\n",
        "# Print the optimal parameters and best score\n",
        "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "# Report the test accuracy using these best parameters\n",
        "print(\"Test accuracy of best grid search hypers:\", logreg_cv.score(X_test, y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m_h1J7nAq8YE",
        "outputId": "0dbdb822-63d7-4a47-f009-2d406acda81b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_operators</th>\n",
              "      <th>halstead_level</th>\n",
              "      <th>halstead_difficulty</th>\n",
              "      <th>halstead_effort</th>\n",
              "      <th>halstead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>0.27</td>\n",
              "      <td>3.70</td>\n",
              "      <td>214.81</td>\n",
              "      <td>11.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>0.12</td>\n",
              "      <td>8.33</td>\n",
              "      <td>783.33</td>\n",
              "      <td>43.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>8.33</td>\n",
              "      <td>1558.33</td>\n",
              "      <td>86.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>0.04</td>\n",
              "      <td>25.00</td>\n",
              "      <td>10575.00</td>\n",
              "      <td>587.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.32</td>\n",
              "      <td>3.13</td>\n",
              "      <td>100.00</td>\n",
              "      <td>5.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>11.11</td>\n",
              "      <td>3255.56</td>\n",
              "      <td>180.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>4.17</td>\n",
              "      <td>137.50</td>\n",
              "      <td>7.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>6</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.03</td>\n",
              "      <td>127.27</td>\n",
              "      <td>7.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>9</td>\n",
              "      <td>0.14</td>\n",
              "      <td>7.14</td>\n",
              "      <td>1607.14</td>\n",
              "      <td>89.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>16.67</td>\n",
              "      <td>9500.00</td>\n",
              "      <td>527.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9a0f9af-67a9-4bac-bb2f-ef1f76671d8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     unique_operators  halstead_level  halstead_difficulty  halstead_effort  \\\n",
              "0                   6            0.27                 3.70           214.81   \n",
              "1                   8            0.12                 8.33           783.33   \n",
              "2                  12            0.12                 8.33          1558.33   \n",
              "3                  18            0.04                25.00         10575.00   \n",
              "4                   5            0.32                 3.13           100.00   \n",
              "..                ...             ...                  ...              ...   \n",
              "116                11            0.09                11.11          3255.56   \n",
              "117                 5            0.24                 4.17           137.50   \n",
              "118                 6            0.33                 3.03           127.27   \n",
              "119                 9            0.14                 7.14          1607.14   \n",
              "120                17            0.06                16.67          9500.00   \n",
              "\n",
              "     halstead_time  \n",
              "0            11.93  \n",
              "1            43.52  \n",
              "2            86.57  \n",
              "3           587.50  \n",
              "4             5.56  \n",
              "..             ...  \n",
              "116         180.86  \n",
              "117           7.64  \n",
              "118           7.07  \n",
              "119          89.29  \n",
              "120         527.78  \n",
              "\n",
              "[121 rows x 5 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from sklearn.feature_selection import mutual_info_classif\n",
        "# fs=SelectKBest(k=5, score_func=mutual_info_classif)\n",
        "# fs.fit(x,y)\n",
        "# mask=fs.get_support()\n",
        "# names=features[mask]\n",
        "# names\n",
        "# X_reduced=x[names]\n",
        "# X_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ9Cv3qxN_n4"
      },
      "source": [
        "# Que 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us2WgJoGOFNJ"
      },
      "source": [
        "Q5) For Datasets with multiple versions, does the accuracy improve when we use pre-release as training and pos-release as testing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UniSlRXB0RUZ",
        "outputId": "f4e3da60-f072-4203-eda6-6fe4bc45915a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(121, 30) (63, 30)\n"
          ]
        }
      ],
      "source": [
        "print(Data_1.shape,Data_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfniPge1GpyP",
        "outputId": "de51850b-a125-4d30-dff1-a76141ee84a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(121, 30)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = Data_1\n",
        "test = Data_2\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypuclSRbG6iL"
      },
      "outputs": [],
      "source": [
        "x= train.iloc[:, 0:29]\n",
        "y= train.iloc[:,29]\n",
        "xt= test.iloc[:, 0:29]\n",
        "yt= test.iloc[:,29]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iqENOfEIFaN"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm =SVC(C=0.1, kernel='poly')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baeKJNEqKXK5",
        "outputId": "e7e90b2c-dc4d-44b4-f325-b7046cfaf6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(121, 30) (63, 30) (107, 30) (36, 30) (101, 30) (498, 22)\n"
          ]
        }
      ],
      "source": [
        "print(Data_1.shape,Data_2.shape,Data_3.shape,Data_4.shape,Data_5.shape,Data_6.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfMZx0ttKHs-",
        "outputId": "99f571ba-e43f-41e9-9f13-361f08af67ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1036, 22) (920, 37) (753, 38) (780, 38)\n"
          ]
        }
      ],
      "source": [
        "print(Data_7.shape,Data_8.shape,Data_9.shape,Data_10.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNsri_gnLrjd"
      },
      "outputs": [],
      "source": [
        "def readfiles(files, index, length):\n",
        "  for file1 in range(0,index):\n",
        "    if(file1 == index):\n",
        "      break;\n",
        "    train = pd.read_csv(files[file1])\n",
        "    test = pd.read_csv(files[file1 + 1])\n",
        "    X_train = train.iloc[:,:-1].values\n",
        "    y_train = train.iloc[:,length].values\n",
        "    X_test = test.iloc[:,:-1].values\n",
        "    y_test = test.iloc[:,length].values\n",
        "    \n",
        "    sc = StandardScaler()\n",
        "    sc.fit(X_train)\n",
        "    X_train_std = sc.transform(X_train)\n",
        "    X_test_std = sc.transform(X_test)\n",
        "    grid = LogisticRegression(C = 0.001,penalty='l1', solver='liblinear')\n",
        "    grid.fit(X_train_std, y_train)\n",
        "    y_pred = grid.predict(X_test_std)\n",
        "    print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GT_xWqGShjp"
      },
      "outputs": [],
      "source": [
        "arr_files = ['ar1.csv','ar3.csv', 'ar4.csv', 'ar5.csv', 'ar6.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2RHSyJhMCmG"
      },
      "outputs": [],
      "source": [
        "Datas=[Data_1,Data_2,Data_3,Data_4,Data_5,Data_6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ucKUw0RLt7w",
        "outputId": "a1ab9270-2935-4690-c9a4-6e78be84c876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.87      1.00      0.93        55\n",
            "        True       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.87        63\n",
            "   macro avg       0.44      0.50      0.47        63\n",
            "weighted avg       0.76      0.87      0.81        63\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.81      1.00      0.90        87\n",
            "        True       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.81       107\n",
            "   macro avg       0.41      0.50      0.45       107\n",
            "weighted avg       0.66      0.81      0.73       107\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      1.00      0.88        28\n",
            "        True       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.78        36\n",
            "   macro avg       0.39      0.50      0.44        36\n",
            "weighted avg       0.60      0.78      0.68        36\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      1.00      0.92        86\n",
            "        True       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.85       101\n",
            "   macro avg       0.43      0.50      0.46       101\n",
            "weighted avg       0.73      0.85      0.78       101\n",
            "\n"
          ]
        }
      ],
      "source": [
        "readfiles(arr_files,4,29)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v9wZkMplOeYn",
        "xzwMWM9xqUvb",
        "-aVpYCDMqeBi",
        "R4IA-bpiedFV",
        "oCV6UCctz0oC",
        "mfh_8nN7rsx4",
        "pxFKQxxcrsx5",
        "0RyrsDy3rsx-",
        "xoLy5a2krx2F",
        "Hb96igfhrx2G",
        "6Ndn1nuRrx2H",
        "1FOrmp49dv6V",
        "8ef9UGjItQyD",
        "xZycVLlntQyE",
        "hyjDzza-tQyF",
        "mvVVQr9UtRdY",
        "8yB2l1eTtRda",
        "iBbSe54ltRdd",
        "pRkLHSXPtR3E",
        "HDbT3vYvtR3F",
        "I8x4aXCJtR3H",
        "u1M6tPgmtSNo",
        "BnLmhNbqtSNo",
        "BuEouHmrtSNq",
        "WgMKSkvgvAtK",
        "NVxYq4gVtSk-",
        "FHlKIlU8tSk-",
        "PIi-S_sktSlD",
        "j9DDez5uwj1R",
        "2dOMgdOctS7D",
        "yMFy8d37tS7E",
        "EV6pVifmtS7G",
        "fZt_Odc1tTRG",
        "MSx4rqUotTRG",
        "Xyo_RcsdtTRH",
        "yJaajtqExLBa",
        "45DkjFOgMiNZ",
        "3I_dhf6KNzse",
        "bJ9Cv3qxN_n4",
        "5W-UKwXnOP1O"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}